{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n",
      "Requirement already satisfied: einops in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (0.6.0)\n",
      "Collecting pyyaml==5.4.1\n",
      "  Using cached PyYAML-5.4.1-cp310-cp310-macosx_11_0_arm64.whl\n",
      "Installing collected packages: pyyaml\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "Successfully installed pyyaml-5.4.1\n",
      "Requirement already satisfied: transformers in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: filelock in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Collecting git+https://github.com/neelnanda-io/Easy-Transformer.git\n",
      "  Cloning https://github.com/neelnanda-io/Easy-Transformer.git to /private/var/folders/yj/gj5_5c_j1399_7h47zvzddtc0000gn/T/pip-req-build-rtmu0yxb\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/Easy-Transformer.git /private/var/folders/yj/gj5_5c_j1399_7h47zvzddtc0000gn/T/pip-req-build-rtmu0yxb\n",
      "  Resolved https://github.com/neelnanda-io/Easy-Transformer.git to commit 99e8a599f244dcdd70a5cf7005b47c7a057f4681\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformer-lens==0.0.0) (1.23.5)\n",
      "Requirement already satisfied: einops>=0.6.0 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.6.0)\n",
      "Collecting jaxtyping>=0.2.11\n",
      "  Using cached jaxtyping-0.2.14-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformer-lens==0.0.0) (4.64.1)\n",
      "Collecting rich>=12.6.0\n",
      "  Using cached rich-13.3.3-py3-none-any.whl (238 kB)\n",
      "Requirement already satisfied: torch>=1.10 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformer-lens==0.0.0) (2.0.0.dev20230124)\n",
      "Collecting transformers>=4.25.1\n",
      "  Using cached transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
      "Collecting pandas>=1.1.5\n",
      "  Using cached pandas-2.0.0-cp310-cp310-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Collecting wandb>=0.13.5\n",
      "  Using cached wandb-0.14.2-py3-none-any.whl (2.0 MB)\n",
      "Collecting datasets>=2.7.1\n",
      "  Using cached datasets-2.11.0-py3-none-any.whl (468 kB)\n",
      "Requirement already satisfied: fancy-einsum>=0.0.3 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformer-lens==0.0.0) (0.0.3)\n",
      "Collecting fsspec[http]>=2021.11.1\n",
      "  Using cached fsspec-2023.4.0-py3-none-any.whl (153 kB)\n",
      "Collecting responses<0.19\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.28.1)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.2.0-cp310-cp310-macosx_11_0_arm64.whl (31 kB)\n",
      "Requirement already satisfied: packaging in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.0)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
      "Collecting dill<0.3.7,>=0.3.0\n",
      "  Using cached dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Using cached pyarrow-11.0.0-cp310-cp310-macosx_11_0_arm64.whl (22.4 MB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-macosx_11_0_arm64.whl (336 kB)\n",
      "Collecting huggingface-hub<1.0.0,>=0.11.0\n",
      "  Using cached huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.4.0)\n",
      "Collecting typeguard>=2.13.3\n",
      "  Using cached typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
      "Collecting markdown-it-py<3.0.0,>=2.2.0\n",
      "  Using cached markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.14.0)\n",
      "Requirement already satisfied: sympy in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from torch>=1.10->transformer-lens==0.0.0) (1.11.1)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (0.11.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (3.9.0)\n",
      "Collecting setproctitle\n",
      "  Using cached setproctitle-1.3.2-cp310-cp310-macosx_10_9_universal2.whl (16 kB)\n",
      "Requirement already satisfied: setuptools in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (65.6.3)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting Click!=8.0.0,>=7.0\n",
      "  Using cached click-8.1.3-py3-none-any.whl (96 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Using cached sentry_sdk-1.19.1-py2.py3-none-any.whl (199 kB)\n",
      "Collecting pathtools\n",
      "  Using cached pathtools-0.1.2-py3-none-any.whl\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0\n",
      "  Using cached protobuf-4.22.1-cp37-abi3-macosx_10_9_universal2.whl (397 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.0)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0\n",
      "  Using cached GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (22.2.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-macosx_11_0_arm64.whl (34 kB)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (2.0.4)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.8.2-cp310-cp310-macosx_11_0_arm64.whl (57 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2022.12.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/lbg/miniconda3/envs/torch-gpu/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.10->transformer-lens==0.0.0) (1.2.1)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: transformer-lens\n",
      "  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=85581 sha256=616321d7cffe2d543efc6be910eae9dda7b6732745c0b3b34417a592778b8c06\n",
      "  Stored in directory: /private/var/folders/yj/gj5_5c_j1399_7h47zvzddtc0000gn/T/pip-ephem-wheel-cache-9xcfvxv0/wheels/4e/73/bc/ef945055d6b29743c2a3cf4f890eb6c28423dccb1703f7ab06\n",
      "Successfully built transformer-lens\n",
      "Installing collected packages: pathtools, appdirs, xxhash, tzdata, typeguard, smmap, setproctitle, sentry-sdk, pyarrow, protobuf, networkx, multidict, mdurl, fsspec, frozenlist, docker-pycreds, dill, Click, async-timeout, yarl, responses, pandas, multiprocess, markdown-it-py, jaxtyping, huggingface-hub, gitdb, aiosignal, transformers, rich, GitPython, aiohttp, wandb, datasets, transformer-lens\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.10.1\n",
      "    Uninstalling huggingface-hub-0.10.1:\n",
      "      Successfully uninstalled huggingface-hub-0.10.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.24.0\n",
      "    Uninstalling transformers-4.24.0:\n",
      "      Successfully uninstalled transformers-4.24.0\n",
      "Successfully installed Click-8.1.3 GitPython-3.1.31 aiohttp-3.8.4 aiosignal-1.3.1 appdirs-1.4.4 async-timeout-4.0.2 datasets-2.11.0 dill-0.3.6 docker-pycreds-0.4.0 frozenlist-1.3.3 fsspec-2023.4.0 gitdb-4.0.10 huggingface-hub-0.13.4 jaxtyping-0.2.14 markdown-it-py-2.2.0 mdurl-0.1.2 multidict-6.0.4 multiprocess-0.70.14 networkx-3.1 pandas-2.0.0 pathtools-0.1.2 protobuf-4.22.1 pyarrow-11.0.0 responses-0.18.0 rich-13.3.3 sentry-sdk-1.19.1 setproctitle-1.3.2 smmap-5.0.0 transformer-lens-0.0.0 transformers-4.27.4 typeguard-3.0.2 tzdata-2023.3 wandb-0.14.2 xxhash-3.2.0 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "# !nvidia-smi\n",
    "# !pip install einops\n",
    "# !pip install pyyaml==5.4.1\n",
    "# !pip install transformers\n",
    "# !pip install git+https://github.com/neelnanda-io/Easy-Transformer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "#pio.renderers.default = \"colab\"\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from functools import *\n",
    "import pandas as pd\n",
    "import gc\n",
    "import collections\n",
    "import copy\n",
    "\n",
    "# import comet_ml\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OV',\n",
       " 'QK',\n",
       " 'T_destination',\n",
       " 'W_E',\n",
       " 'W_E_pos',\n",
       " 'W_K',\n",
       " 'W_O',\n",
       " 'W_Q',\n",
       " 'W_U',\n",
       " 'W_V',\n",
       " 'W_in',\n",
       " 'W_out',\n",
       " 'W_pos',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_call_impl',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_load_from_state_dict',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_named_members',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_version',\n",
       " 'accumulated_bias',\n",
       " 'add_caching_hooks',\n",
       " 'add_hook',\n",
       " 'add_module',\n",
       " 'add_perma_hook',\n",
       " 'all_composition_scores',\n",
       " 'all_head_labels',\n",
       " 'apply',\n",
       " 'b_K',\n",
       " 'b_O',\n",
       " 'b_Q',\n",
       " 'b_U',\n",
       " 'b_V',\n",
       " 'b_in',\n",
       " 'b_out',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'cache_all',\n",
       " 'cache_some',\n",
       " 'center_unembed',\n",
       " 'center_writing_weights',\n",
       " 'check_and_add_hook',\n",
       " 'check_hooks_to_add',\n",
       " 'children',\n",
       " 'clear_contexts',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'fill_missing_keys',\n",
       " 'float',\n",
       " 'fold_layer_norm',\n",
       " 'fold_value_biases',\n",
       " 'forward',\n",
       " 'from_pretrained',\n",
       " 'from_pretrained_no_processing',\n",
       " 'generate',\n",
       " 'get_buffer',\n",
       " 'get_caching_hooks',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'get_token_position',\n",
       " 'half',\n",
       " 'hook_points',\n",
       " 'hooks',\n",
       " 'init_weights',\n",
       " 'ipu',\n",
       " 'load_and_process_state_dict',\n",
       " 'load_sample_training_dataset',\n",
       " 'load_state_dict',\n",
       " 'loss_fn',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'process_weights_',\n",
       " 'refactor_factored_attn_matrices',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'remove_all_hook_fns',\n",
       " 'requires_grad_',\n",
       " 'reset_hooks',\n",
       " 'run_with_cache',\n",
       " 'run_with_hooks',\n",
       " 'sample_datapoint',\n",
       " 'set_extra_state',\n",
       " 'set_tokenizer',\n",
       " 'set_use_attn_result',\n",
       " 'set_use_split_qkv_input',\n",
       " 'setup',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'to_single_token',\n",
       " 'to_str_tokens',\n",
       " 'to_string',\n",
       " 'to_tokens',\n",
       " 'tokens_to_residual_directions',\n",
       " 'train',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pretty sure easy_transformer was obsolete, so needed to reformat things a bit from Neel's demo\n",
    "import transformer_lens as tl\n",
    "from transformer_lens.utils import gelu_new, to_numpy, get_corner #helper functions\n",
    "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
    "#from transformer_lens import EasyTransformer \n",
    "#from transformer_lens.EasyTransformer import TransformerBlock, MLP, Attention, LayerNormPre, PosEmbed, Unembed, Embed\n",
    "# from easy_transformer.experiments import ExperimentMetric, AblationConfig, EasyAblation, EasyPatching, PatchingConfig\n",
    "dir(transformer_lens.EasyTransformer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOOK POINTS\n",
    "wrap around the activation in a network, using PyTorch hooks to access and edit them.\n",
    "- The root module is the model we want to study\n",
    "- The HookedRootModule class is inherited by the model\n",
    "- using \"run_with_hooks\" function, you can pass a list of [hook, layer] through the model (forward pass)\n",
    "- each hook is a function of the activation and the hookpoint class attached to that function (I don't understand this yet)\n",
    "\n",
    "As an example, they look at a toy, two-layer network, where each layer consists of: \n",
    "input (x) ->  square (x**2) -> translate (+=const) = output\n",
    "- Hook points are wrapped around the input, square, and output parts of each layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SquareThenAdd(nn.Module):\n",
    "    def __init__(self, offset):\n",
    "        super().__init__()\n",
    "        self.offset = nn.Parameter(torch.tensor(offset))\n",
    "        self.hook_square = HookPoint()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # The hook_square doesn't change the value, but lets us access it\n",
    "        square = self.hook_square(x * x)\n",
    "        return self.offset + square\n",
    "    \n",
    "class TwoLayerModel(HookedRootModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = SquareThenAdd(3.)\n",
    "        self.layer2 = SquareThenAdd(-4.)\n",
    "        self.hook_in = HookPoint()\n",
    "        self.hook_mid = HookPoint()\n",
    "        self.hook_out = HookPoint()\n",
    "\n",
    "        # We need to call the setup function of HookedRootModule to build an \n",
    "        # internal dictionary of modules and hooks, and to give each hook a name\n",
    "        super().setup()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # We wrap the input and each layer's output in a hook - they leave the \n",
    "        # value unchanged (unless there's a hook added to explicitly change it), \n",
    "        # but allow us to access it.\n",
    "        x_in = self.hook_in(x)\n",
    "        x_mid = self.hook_mid(self.layer1(x_in))\n",
    "        x_out = self.hook_out(self.layer2(x_mid))\n",
    "        return x_out\n",
    "model = TwoLayerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output: 780.0\n",
      "Value cached at hook hook_in 5.0\n",
      "Value cached at hook layer1.hook_square 25.0\n",
      "Value cached at hook hook_mid 28.0\n",
      "Value cached at hook layer2.hook_square 784.0\n",
      "Value cached at hook hook_out 780.0\n"
     ]
    }
   ],
   "source": [
    "## save the activations at each hook point in a cache\n",
    "\n",
    "#### figure out how run_with_cache works ... I think we can just do it later when getting the logits\n",
    "\n",
    "cache = {}\n",
    "model.cache_all(cache)\n",
    "#model.run_with_cache(cache)\n",
    "print('Model output:', model(torch.tensor(5.)).item())\n",
    "for key in cache:\n",
    "    print(f\"Value cached at hook {key}\", cache[key].item())\n",
    "model.reset_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer2.hook_square\n",
      "Output after intervening on layer2.hook_scaled -4.0\n",
      "layer2.hook_square\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hook_in': tensor(5.),\n",
       " 'layer1.hook_square': tensor(25.),\n",
       " 'hook_mid': tensor(28.),\n",
       " 'layer2.hook_square': tensor(0.),\n",
       " 'hook_out': tensor(-4.)}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### make a function to set the square value of layer2 to 0, and show the output\n",
    "model.reset_hooks()\n",
    "def set_to_zero_hook(tensor, hook):\n",
    "    print(hook.name)\n",
    "    return torch.tensor(0.)\n",
    "print('Output after intervening on layer2.hook_scaled', \n",
    "      model.run_with_hooks(torch.tensor(5.),\n",
    "                           fwd_hooks = [('layer2.hook_square', set_to_zero_hook)], reset_hooks_end = False).item())\n",
    "## A better way to do the cache, but there's no way to insert the hooks here and run it all at the same time? \n",
    "### I think what this does is calls \"get_caching_hooks\" on the model. I think this could be streamlined, or I'm missing something \n",
    "### Workaround, set \"reset_hooks_end = False\" in above and then run. The hooks will reset by default after \"run_with_cache\"\n",
    "\n",
    "\n",
    "out, cache2 = model.run_with_cache(torch.tensor(5.))\n",
    "cache2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRANSFORMER MODELS: \n",
    "Instead of the toy model, use a gpt-2 transformer. There are many currently accessible by easy transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# Load GPT-2 small \n",
    "\n",
    "model_name = 'gpt2' #@param ['gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl', 'facebook/opt-125m', 'facebook/opt-1.3b', 'facebook/opt-2.7b', 'facebook/opt-6.7b', 'facebook/opt-13b', 'facebook/opt-30b', 'facebook/opt-66b', 'EleutherAI/gpt-neo-125M', 'EleutherAI/gpt-neo-1.3B', 'EleutherAI/gpt-neo-2.7B', 'EleutherAI/gpt-j-6B', 'EleutherAI/gpt-neox-20b']\n",
    "model = tl.HookedTransformer.from_pretrained(model_name)\n",
    "#model = tl.EasyTransformer(model_name) #deprecated based on model defined above \n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>|Inter|pret|ability| is| great\n",
      "<|endoftext|>|AI| Al|ignment| is| great\n"
     ]
    }
   ],
   "source": [
    "## still confused as to when and why we should use prepend_bos = False \n",
    "prompt = 'Interpretability is great'\n",
    "tokens = model.to_tokens(prompt)\n",
    "#tokens = model.to_tokens(prompt,prepend_bos=False)\n",
    "\n",
    "prompt_2 = 'AI Alignment is great'\n",
    "tokens_2 = model.to_tokens(prompt_2)\n",
    "#tokens_2 = model.to_tokens(prompt_2,prepend_bos=False)\n",
    "def show_tokens(tokens):\n",
    "    # Prints the tokens as text, separated by |\n",
    "    if type(tokens)==str:\n",
    "        # If we input text, tokenize first\n",
    "        tokens = model.to_tokens(tokens,prepend_bos=False)\n",
    "    text_tokens = [model.tokenizer.decode(t) for t in tokens.squeeze()]\n",
    "    print('|'.join(text_tokens))\n",
    "show_tokens(tokens)\n",
    "show_tokens(tokens_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top corner of logits\n",
      "tensor([[[ 7.5261, 11.1214,  7.8919,  8.1297,  7.4282],\n",
      "         [ 4.5895,  4.6344,  3.1930,  3.0397,  4.7588],\n",
      "         [ 6.0709,  6.6744,  2.5337,  0.9526,  3.9620],\n",
      "         [ 7.8493,  9.2531,  5.9004,  2.1225,  3.5641],\n",
      "         [ 4.2368,  4.4603,  1.5758, -0.1628,  2.1362]]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# reset the hooks from the last example! This is already done, but just in case?\n",
    "model.reset_hooks()\n",
    "# try running with cache \n",
    "original_logits = model(tokens)\n",
    "### get_corner (in utils) gets top corner of logits up to specified dim (could print all of it)\n",
    "print('Top corner of logits')\n",
    "print(get_corner(original_logits, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference: Hyperparameters for the model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_layers': 12,\n",
       " 'd_model': 768,\n",
       " 'n_ctx': 1024,\n",
       " 'd_head': 64,\n",
       " 'model_name': 'gpt2',\n",
       " 'n_heads': 12,\n",
       " 'd_mlp': 3072,\n",
       " 'act_fn': 'gelu_new',\n",
       " 'd_vocab': 50257,\n",
       " 'eps': 1e-05,\n",
       " 'use_attn_result': False,\n",
       " 'use_attn_scale': True,\n",
       " 'use_split_qkv_input': False,\n",
       " 'use_local_attn': False,\n",
       " 'original_architecture': 'GPT2LMHeadModel',\n",
       " 'from_checkpoint': False,\n",
       " 'checkpoint_index': None,\n",
       " 'checkpoint_label_type': None,\n",
       " 'checkpoint_value': None,\n",
       " 'tokenizer_name': 'gpt2',\n",
       " 'window_size': None,\n",
       " 'attn_types': None,\n",
       " 'init_mode': 'gpt2',\n",
       " 'normalization_type': 'LNPre',\n",
       " 'device': 'cpu',\n",
       " 'attention_dir': 'causal',\n",
       " 'attn_only': False,\n",
       " 'seed': None,\n",
       " 'initializer_range': 0.02886751345948129,\n",
       " 'init_weights': False,\n",
       " 'scale_attn_by_inverse_layer_idx': False,\n",
       " 'positional_embedding_type': 'standard',\n",
       " 'final_rms': False,\n",
       " 'd_vocab_out': 50257,\n",
       " 'parallel_attn_mlp': False,\n",
       " 'rotary_dim': None,\n",
       " 'n_params': 84934656,\n",
       " 'use_hook_tokens': False}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Reference: Hyperparameters for the model')\n",
    "dataclasses.asdict(model.cfg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING THE MODEL \n",
    "- can input either tokens or text, which is converted to tokens\n",
    "- This one differs from the hugging face model because it lacks the bias term in the unembedding. This cancels out after taking the softmax, so while the logits are different the log probs are (largely) the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of log probs the same between easy model and original model:\n",
      "tensor(0.9996)\n",
      "Fraction of logits the same between easy model and original model:\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "logits_tokens = model(tokens)\n",
    "logits_text = model(prompt)\n",
    "\n",
    "original_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# easy_logits = model(tokens).cpu()\n",
    "original_model_logits = original_model(tokens).logits\n",
    "\n",
    "easy_logits = model(prompt).cpu()\n",
    "\n",
    "easy_log_probs = F.log_softmax(easy_logits, dim=-1)\n",
    "original_model_log_probs = F.log_softmax(original_model_logits, dim=-1)\n",
    "\n",
    "print('Fraction of log probs the same between easy model and original model:')\n",
    "print(torch.isclose(original_model_log_probs, easy_log_probs).sum()/easy_log_probs.numel())\n",
    "print('Fraction of logits the same between easy model and original model:')\n",
    "print(torch.isclose(original_model_logits, easy_logits).sum()/easy_logits.numel())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shapes of all activations (that are accessible by each hook)\n",
    "- A useful reference for creating hooks\n",
    "- The shapes of each activation should be (batch, position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 50])\n",
      "Activation at hook hook_embed has shape torch.Size([4, 50, 768])\n",
      "Activation at hook hook_pos_embed has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.0.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.0.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.0.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.0.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.0.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.0.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.0.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.0.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.0.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.0.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.0.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.0.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.0.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.0.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.0.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.0.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.0.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.0.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.0.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.0.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.0.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.1.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.1.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.1.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.1.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.1.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.1.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.1.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.1.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.1.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.1.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.1.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.1.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.1.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.1.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.1.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.1.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.1.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.1.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.1.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.1.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.1.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.2.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.2.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.2.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.2.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.2.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.2.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.2.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.2.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.2.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.2.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.2.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.2.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.2.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.2.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.2.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.2.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.2.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.2.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.2.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.2.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.2.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.3.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.3.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.3.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.3.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.3.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.3.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.3.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.3.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.3.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.3.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.3.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.3.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.3.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.3.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.3.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.3.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.3.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.3.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.3.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.3.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.3.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.4.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.4.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.4.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.4.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.4.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.4.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.4.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.4.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.4.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.4.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.4.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.4.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.4.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.4.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.4.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.4.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.4.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.4.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.4.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.4.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.4.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.5.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.5.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.5.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.5.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.5.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.5.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.5.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.5.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.5.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.5.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.5.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.5.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.5.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.5.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.5.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.5.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.5.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.5.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.5.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.5.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.5.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.6.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.6.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.6.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.6.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.6.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.6.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.6.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.6.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.6.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.6.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.6.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.6.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.6.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.6.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.6.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.6.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.6.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.6.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.6.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.6.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.6.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.7.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.7.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.7.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.7.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.7.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.7.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.7.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.7.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.7.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.7.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.7.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.7.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.7.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.7.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.7.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.7.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.7.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.7.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.7.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.7.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.7.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.8.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.8.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.8.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.8.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.8.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.8.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.8.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.8.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.8.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.8.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.8.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.8.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.8.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.8.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.8.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.8.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.8.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.8.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.8.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.8.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.8.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.9.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.9.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.9.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.9.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.9.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.9.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.9.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.9.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.9.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.9.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.9.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.9.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.9.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.9.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.9.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.9.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.9.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.9.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.9.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.9.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.9.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.10.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.10.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.10.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.10.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.10.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.10.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.10.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.10.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.10.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.10.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.10.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.10.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.10.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.10.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.10.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.10.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.10.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.10.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.10.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.10.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.10.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.11.hook_resid_pre has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.11.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.11.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.11.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.11.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.11.ln1.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.11.ln1.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.11.attn.hook_q has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.11.attn.hook_k has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.11.attn.hook_v has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.11.attn.hook_attn_scores has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.11.attn.hook_pattern has shape torch.Size([4, 12, 50, 50])\n",
      "Activation at hook blocks.11.attn.hook_z has shape torch.Size([4, 50, 12, 64])\n",
      "Activation at hook blocks.11.hook_attn_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.11.hook_resid_mid has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.11.ln2.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook blocks.11.ln2.hook_normalized has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.11.mlp.hook_pre has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.11.mlp.hook_post has shape torch.Size([4, 50, 3072])\n",
      "Activation at hook blocks.11.hook_mlp_out has shape torch.Size([4, 50, 768])\n",
      "Activation at hook blocks.11.hook_resid_post has shape torch.Size([4, 50, 768])\n",
      "Activation at hook ln_final.hook_scale has shape torch.Size([4, 50, 1])\n",
      "Activation at hook ln_final.hook_normalized has shape torch.Size([4, 50, 768])\n"
     ]
    }
   ],
   "source": [
    "# make a function that grabs the activation of that name (to grab all hooks)\n",
    "all_hooks_fn = lambda name: True\n",
    "## make a function that shows what to do with the hooks (in this case, display)\n",
    "def print_shape(tensor, hook):\n",
    "    print(f\"Activation at hook {hook.name} has shape {tensor.shape}\")\n",
    "# Is there any reason why they chose such high token numbers? \n",
    "rand_toks = torch.randint(1000,10000,(4,50)) #(batch size, seq length)\n",
    "print(rand_toks.shape)\n",
    "logits = model.run_with_hooks(rand_toks, fwd_hooks = [(all_hooks_fn, print_shape)])\n",
    "\n",
    "## can use this to check the dimensions of each activation in the network (very useful!)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the top corner of activations: \n",
    "- Can use these to compare any altered activations to the original ones, without looking through the full matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed\n",
      "tensor([[[-0.1213,  0.0433,  0.1574],\n",
      "         [-0.0957,  0.0820,  0.1314],\n",
      "         [ 0.0227, -0.0485,  0.1109]],\n",
      "\n",
      "        [[ 0.2166, -0.1912, -0.0205],\n",
      "         [ 0.0187, -0.1366,  0.0230],\n",
      "         [-0.0300, -0.0031,  0.1593]],\n",
      "\n",
      "        [[ 0.0905,  0.0264,  0.1115],\n",
      "         [ 0.1901, -0.0444,  0.0603],\n",
      "         [ 0.1749, -0.1153,  0.2472]]], grad_fn=<SliceBackward0>)\n",
      "hook_pos_embed\n",
      "tensor([[[-0.0134, -0.1920,  0.0095],\n",
      "         [ 0.0250, -0.0528, -0.0939],\n",
      "         [ 0.0065, -0.0825,  0.0568]],\n",
      "\n",
      "        [[-0.0134, -0.1920,  0.0095],\n",
      "         [ 0.0250, -0.0528, -0.0939],\n",
      "         [ 0.0065, -0.0825,  0.0568]],\n",
      "\n",
      "        [[-0.0134, -0.1920,  0.0095],\n",
      "         [ 0.0250, -0.0528, -0.0939],\n",
      "         [ 0.0065, -0.0825,  0.0568]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.hook_resid_pre\n",
      "tensor([[[-0.1347, -0.1487,  0.1669],\n",
      "         [-0.0707,  0.0292,  0.0375],\n",
      "         [ 0.0291, -0.1310,  0.1676]],\n",
      "\n",
      "        [[ 0.2032, -0.3832, -0.0110],\n",
      "         [ 0.0437, -0.1894, -0.0708],\n",
      "         [-0.0235, -0.0856,  0.2160]],\n",
      "\n",
      "        [[ 0.0771, -0.1656,  0.1210],\n",
      "         [ 0.2151, -0.0972, -0.0336],\n",
      "         [ 0.1814, -0.1978,  0.3039]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.ln1.hook_scale\n",
      "tensor([[[0.3740],\n",
      "         [0.2247],\n",
      "         [0.2080]],\n",
      "\n",
      "        [[0.3756],\n",
      "         [0.2250],\n",
      "         [0.2029]],\n",
      "\n",
      "        [[0.3705],\n",
      "         [0.2266],\n",
      "         [0.2023]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.ln1.hook_normalized\n",
      "tensor([[[-0.3601, -0.3975,  0.4463],\n",
      "         [-0.3148,  0.1301,  0.1669],\n",
      "         [ 0.1399, -0.6296,  0.8058]],\n",
      "\n",
      "        [[ 0.5411, -1.0202, -0.0293],\n",
      "         [ 0.1942, -0.8416, -0.3148],\n",
      "         [-0.1158, -0.4220,  1.0648]],\n",
      "\n",
      "        [[ 0.2081, -0.4468,  0.3266],\n",
      "         [ 0.9493, -0.4291, -0.1481],\n",
      "         [ 0.8966, -0.9781,  1.5026]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.ln1.hook_scale\n",
      "tensor([[[0.3740],\n",
      "         [0.2247],\n",
      "         [0.2080]],\n",
      "\n",
      "        [[0.3756],\n",
      "         [0.2250],\n",
      "         [0.2029]],\n",
      "\n",
      "        [[0.3705],\n",
      "         [0.2266],\n",
      "         [0.2023]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.ln1.hook_normalized\n",
      "tensor([[[-0.3601, -0.3975,  0.4463],\n",
      "         [-0.3148,  0.1301,  0.1669],\n",
      "         [ 0.1399, -0.6296,  0.8058]],\n",
      "\n",
      "        [[ 0.5411, -1.0202, -0.0293],\n",
      "         [ 0.1942, -0.8416, -0.3148],\n",
      "         [-0.1158, -0.4220,  1.0648]],\n",
      "\n",
      "        [[ 0.2081, -0.4468,  0.3266],\n",
      "         [ 0.9493, -0.4291, -0.1481],\n",
      "         [ 0.8966, -0.9781,  1.5026]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.ln1.hook_scale\n",
      "tensor([[[0.3740],\n",
      "         [0.2247],\n",
      "         [0.2080]],\n",
      "\n",
      "        [[0.3756],\n",
      "         [0.2250],\n",
      "         [0.2029]],\n",
      "\n",
      "        [[0.3705],\n",
      "         [0.2266],\n",
      "         [0.2023]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.ln1.hook_normalized\n",
      "tensor([[[-0.3601, -0.3975,  0.4463],\n",
      "         [-0.3148,  0.1301,  0.1669],\n",
      "         [ 0.1399, -0.6296,  0.8058]],\n",
      "\n",
      "        [[ 0.5411, -1.0202, -0.0293],\n",
      "         [ 0.1942, -0.8416, -0.3148],\n",
      "         [-0.1158, -0.4220,  1.0648]],\n",
      "\n",
      "        [[ 0.2081, -0.4468,  0.3266],\n",
      "         [ 0.9493, -0.4291, -0.1481],\n",
      "         [ 0.8966, -0.9781,  1.5026]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.attn.hook_q\n",
      "tensor([[[[ 0.1391, -0.6157,  0.3708],\n",
      "          [-0.4260,  1.1646, -0.3336],\n",
      "          [ 0.2352,  0.6161,  0.5625]],\n",
      "\n",
      "         [[ 0.3879,  2.0486, -0.3982],\n",
      "          [ 0.4942, -0.1939, -1.6965],\n",
      "          [-0.7555,  0.4443, -0.0946]],\n",
      "\n",
      "         [[ 0.5264, -0.2767, -0.0378],\n",
      "          [ 1.7370, -1.7571, -1.0787],\n",
      "          [-0.6163,  0.7843,  1.0277]]],\n",
      "\n",
      "\n",
      "        [[[-0.2173, -0.0841, -0.1244],\n",
      "          [ 0.1893, -0.0442, -1.6512],\n",
      "          [-0.8570,  0.6916,  0.5236]],\n",
      "\n",
      "         [[ 0.6884,  1.8671,  0.7873],\n",
      "          [-1.4994, -0.0841, -0.9689],\n",
      "          [-0.3339,  0.1333,  0.5505]],\n",
      "\n",
      "         [[ 1.5492,  1.2927, -0.9174],\n",
      "          [-0.2287, -0.9335, -2.7537],\n",
      "          [-0.5446,  0.5035, -1.2649]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8582,  0.6138, -1.1292],\n",
      "          [-0.5509, -0.3023, -0.8824],\n",
      "          [ 0.2813,  0.0348,  0.2203]],\n",
      "\n",
      "         [[ 0.7012,  0.7291, -0.8558],\n",
      "          [ 1.2476,  0.1711, -2.4083],\n",
      "          [-0.6238,  0.3842, -0.0807]],\n",
      "\n",
      "         [[-0.3311,  0.5410,  0.3049],\n",
      "          [ 0.3416,  0.8320, -3.5943],\n",
      "          [ 0.6699,  0.7048,  0.0753]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.attn.hook_k\n",
      "tensor([[[[-1.3139,  2.3688,  0.7696],\n",
      "          [ 0.7277,  1.2253,  0.5248],\n",
      "          [ 0.2153,  0.3496,  1.4283]],\n",
      "\n",
      "         [[-2.6553,  2.8625,  1.4955],\n",
      "          [ 0.0669, -1.5155, -0.8967],\n",
      "          [ 0.5655,  0.3262,  1.6875]],\n",
      "\n",
      "         [[-1.5635,  2.7175,  0.7443],\n",
      "          [ 1.3711, -2.1793, -0.8371],\n",
      "          [ 1.0802,  1.2253,  0.8802]]],\n",
      "\n",
      "\n",
      "        [[[-0.5632,  2.4269,  0.8992],\n",
      "          [ 0.9492,  0.4151, -0.2195],\n",
      "          [ 1.4424, -1.2333,  0.4825]],\n",
      "\n",
      "         [[-1.8789,  3.7750,  1.0969],\n",
      "          [-1.0743, -0.5283,  0.1887],\n",
      "          [ 0.8332, -1.9901,  0.6945]],\n",
      "\n",
      "         [[-3.5583,  2.3657,  1.5948],\n",
      "          [-0.2203, -2.5318, -2.9503],\n",
      "          [-0.2073, -0.2767, -1.1126]]],\n",
      "\n",
      "\n",
      "        [[[-1.6841,  2.6615,  0.7954],\n",
      "          [ 0.2909, -0.4335, -0.0653],\n",
      "          [ 0.0758, -0.0374,  0.5648]],\n",
      "\n",
      "         [[-1.4037,  2.5498,  1.1747],\n",
      "          [ 0.5884, -1.4500, -2.0145],\n",
      "          [ 0.5288,  0.0578,  0.1641]],\n",
      "\n",
      "         [[-2.5077,  2.3853,  1.9798],\n",
      "          [-0.1588,  0.2011, -3.9015],\n",
      "          [ 0.1589, -0.7692, -0.6644]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.attn.hook_v\n",
      "tensor([[[[-0.0155, -0.0749, -0.0112],\n",
      "          [-0.0020,  0.1701, -0.3065],\n",
      "          [ 0.1289, -0.1556,  0.2885]],\n",
      "\n",
      "         [[-0.2035,  0.0659,  0.1654],\n",
      "          [-0.1564,  0.2146,  0.0226],\n",
      "          [ 0.1784, -0.3392,  0.3516]],\n",
      "\n",
      "         [[ 0.0857, -0.1428,  0.3833],\n",
      "          [ 0.0593,  0.1823, -0.1247],\n",
      "          [-0.0773, -0.4185,  0.1390]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0741, -0.0500,  0.2825],\n",
      "          [ 0.1777,  0.2276, -0.4224],\n",
      "          [ 0.0593, -0.2068,  0.2146]],\n",
      "\n",
      "         [[ 0.0450, -0.0159,  0.1323],\n",
      "          [-0.1508,  0.0174, -0.1269],\n",
      "          [-0.1439,  0.0314,  0.0867]],\n",
      "\n",
      "         [[-0.1809,  0.1700, -0.0280],\n",
      "          [ 0.0157, -0.1706,  0.1451],\n",
      "          [ 0.1268, -0.0636, -0.0679]]],\n",
      "\n",
      "\n",
      "        [[[-0.0439, -0.0368,  0.1037],\n",
      "          [-0.0039,  0.2283, -0.2145],\n",
      "          [ 0.0508, -0.0353,  0.0304]],\n",
      "\n",
      "         [[-0.2366, -0.1728,  0.1769],\n",
      "          [-0.0502,  0.0598,  0.1776],\n",
      "          [-0.0082, -0.1247, -0.0964]],\n",
      "\n",
      "         [[ 0.1383, -0.0817,  0.0056],\n",
      "          [ 0.1744, -0.0685, -0.2206],\n",
      "          [ 0.1867, -0.0603, -0.0393]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.attn.hook_attn_scores\n",
      "tensor([[[[-3.5405e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.5973e-01, -1.2965e+00, -1.0000e+05],\n",
      "          [-5.9449e-01, -1.9089e+00, -1.8107e+00]],\n",
      "\n",
      "         [[ 5.1512e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.7606e+00,  1.1824e+01, -1.0000e+05],\n",
      "          [ 2.7186e+00,  3.9370e+00,  1.0566e+01]],\n",
      "\n",
      "         [[-1.6216e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 7.7644e-01, -1.3210e+00, -1.0000e+05],\n",
      "          [ 4.4773e-01, -1.4212e+00, -2.2145e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1378e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 6.6207e-01, -6.0583e-01, -1.0000e+05],\n",
      "          [-3.0112e-02, -4.2589e-01, -2.0979e+00]],\n",
      "\n",
      "         [[ 5.9582e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.5093e+00,  1.4221e+01, -1.0000e+05],\n",
      "          [ 3.1968e+00,  4.0739e+00,  1.2404e+01]],\n",
      "\n",
      "         [[-8.0371e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.6509e-01, -1.5974e+00, -1.0000e+05],\n",
      "          [ 2.0472e-01, -1.4860e+00, -1.4641e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.9002e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.3361e-02, -1.5620e+00, -1.0000e+05],\n",
      "          [ 3.2871e-01, -1.2973e+00,  4.4338e-01]],\n",
      "\n",
      "         [[ 3.1731e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.7431e+00,  9.8064e+00, -1.0000e+05],\n",
      "          [ 2.0113e+00,  4.5249e+00,  1.1363e+01]],\n",
      "\n",
      "         [[-6.1481e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-6.6096e-01, -2.3376e+00, -1.0000e+05],\n",
      "          [-3.7507e-01, -1.9429e+00, -1.6609e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.attn.hook_pattern\n",
      "tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [8.1096e-01, 1.8904e-01, 0.0000e+00],\n",
      "          [6.3899e-01, 1.7165e-01, 1.8936e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [3.1461e-04, 9.9969e-01, 0.0000e+00],\n",
      "          [3.9012e-04, 1.3194e-03, 9.9829e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [8.9066e-01, 1.0934e-01, 0.0000e+00],\n",
      "          [8.1694e-01, 1.2605e-01, 5.7017e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [7.8038e-01, 2.1962e-01, 0.0000e+00],\n",
      "          [5.5567e-01, 3.7405e-01, 7.0274e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [6.0570e-05, 9.9994e-01, 0.0000e+00],\n",
      "          [1.0029e-04, 2.4109e-04, 9.9966e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [7.9123e-01, 2.0877e-01, 0.0000e+00],\n",
      "          [5.2958e-01, 9.7648e-02, 3.7277e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [8.2327e-01, 1.7673e-01, 0.0000e+00],\n",
      "          [4.3137e-01, 8.4857e-02, 4.8378e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [8.5522e-04, 9.9914e-01, 0.0000e+00],\n",
      "          [8.6691e-05, 1.0705e-03, 9.9884e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [8.4247e-01, 1.5753e-01, 0.0000e+00],\n",
      "          [6.7344e-01, 1.4041e-01, 1.8615e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.attn.hook_z\n",
      "tensor([[[[-1.5461e-02, -7.4897e-02, -1.1152e-02],\n",
      "          [-2.0421e-03,  1.7012e-01, -3.0655e-01],\n",
      "          [ 1.2887e-01, -1.5558e-01,  2.8853e-01]],\n",
      "\n",
      "         [[-5.1015e-02, -4.8273e-02,  2.2230e-02],\n",
      "          [-1.5632e-01,  2.1455e-01,  2.2525e-02],\n",
      "          [ 1.3429e-01, -1.7565e-01,  2.9543e-01]],\n",
      "\n",
      "         [[-2.8582e-02, -6.3580e-02,  9.3853e-02],\n",
      "          [ 5.8977e-02,  1.8237e-01, -1.2459e-01],\n",
      "          [ 1.2337e-01, -1.9371e-01,  2.8796e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.4074e-02, -5.0004e-02,  2.8252e-01],\n",
      "          [ 1.7772e-01,  2.2764e-01, -4.2241e-01],\n",
      "          [ 5.9347e-02, -2.0683e-01,  2.1457e-01]],\n",
      "\n",
      "         [[ 6.7689e-02, -4.2510e-02,  2.4952e-01],\n",
      "          [-1.5075e-01,  1.7396e-02, -1.2691e-01],\n",
      "          [ 1.6914e-02, -1.5711e-01,  1.8787e-01]],\n",
      "\n",
      "         [[ 4.5285e-02, -2.1779e-02,  2.0449e-01],\n",
      "          [ 1.5661e-02, -1.7052e-01,  1.4500e-01],\n",
      "          [ 6.4639e-02, -1.3020e-01,  9.6798e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.3933e-02, -3.6757e-02,  1.0370e-01],\n",
      "          [-3.8661e-03,  2.2833e-01, -2.1453e-01],\n",
      "          [ 5.0789e-02, -3.5310e-02,  3.0420e-02]],\n",
      "\n",
      "         [[-7.7983e-02, -6.0806e-02,  1.1664e-01],\n",
      "          [-5.0138e-02,  5.9913e-02,  1.7731e-01],\n",
      "          [ 4.1498e-02, -4.9392e-02,  1.0442e-02]],\n",
      "\n",
      "         [[ 2.7878e-02, -7.0051e-02,  6.2457e-02],\n",
      "          [ 1.7410e-01, -6.8347e-02, -2.2014e-01],\n",
      "          [ 6.7802e-02, -5.2513e-02, -3.6066e-04]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.hook_attn_out\n",
      "tensor([[[-0.0230, -0.1679, -0.7162],\n",
      "         [-0.1422,  0.2201, -0.6704],\n",
      "         [ 0.3734,  0.3287, -0.8130]],\n",
      "\n",
      "        [[-0.1641,  0.3221, -0.0690],\n",
      "         [ 0.3740,  0.4101, -0.5169],\n",
      "         [ 0.0506,  0.6846, -0.6861]],\n",
      "\n",
      "        [[ 0.3166,  0.3846,  0.2552],\n",
      "         [-0.5958,  0.3912, -0.0682],\n",
      "         [ 1.3594,  0.3926,  0.4269]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.hook_resid_mid\n",
      "tensor([[[-0.1576, -0.3165, -0.5493],\n",
      "         [-0.2129,  0.2494, -0.6329],\n",
      "         [ 0.4025,  0.1977, -0.6454]],\n",
      "\n",
      "        [[ 0.0392, -0.0610, -0.0800],\n",
      "         [ 0.4177,  0.2207, -0.5877],\n",
      "         [ 0.0271,  0.5990, -0.4700]],\n",
      "\n",
      "        [[ 0.3937,  0.2190,  0.3762],\n",
      "         [-0.3807,  0.2940, -0.1017],\n",
      "         [ 1.5408,  0.1948,  0.7309]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.ln2.hook_scale\n",
      "tensor([[[1.1584],\n",
      "         [1.4530],\n",
      "         [1.2845]],\n",
      "\n",
      "        [[1.1975],\n",
      "         [1.3435],\n",
      "         [1.3066]],\n",
      "\n",
      "        [[1.1593],\n",
      "         [1.3022],\n",
      "         [1.2597]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.ln2.hook_normalized\n",
      "tensor([[[-0.1361, -0.2732, -0.4742],\n",
      "         [-0.1465,  0.1716, -0.4356],\n",
      "         [ 0.3133,  0.1539, -0.5024]],\n",
      "\n",
      "        [[ 0.0327, -0.0510, -0.0668],\n",
      "         [ 0.3109,  0.1643, -0.4375],\n",
      "         [ 0.0207,  0.4584, -0.3597]],\n",
      "\n",
      "        [[ 0.3396,  0.1889,  0.3245],\n",
      "         [-0.2924,  0.2258, -0.0781],\n",
      "         [ 1.2232,  0.1546,  0.5802]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.mlp.hook_pre\n",
      "tensor([[[-0.0757, -0.2831, -2.0388],\n",
      "         [ 0.4848,  0.5232,  0.2076],\n",
      "         [ 0.3331, -0.1031, -1.0612]],\n",
      "\n",
      "        [[-0.3523, -1.2955, -0.4799],\n",
      "         [ 0.3403,  0.6629, -0.6577],\n",
      "         [ 0.4147,  0.5098, -0.8148]],\n",
      "\n",
      "        [[ 0.2215, -0.4145, -1.3399],\n",
      "         [ 0.2693,  0.6479,  0.0207],\n",
      "         [ 0.4621, -0.4274, -0.6103]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.mlp.hook_post\n",
      "tensor([[[-0.0356, -0.1100, -0.0421],\n",
      "         [ 0.3326,  0.3660,  0.1209],\n",
      "         [ 0.2100, -0.0473, -0.1533]],\n",
      "\n",
      "        [[-0.1276, -0.1266, -0.1515],\n",
      "         [ 0.2155,  0.4947, -0.1680],\n",
      "         [ 0.2741,  0.3542, -0.1692]],\n",
      "\n",
      "        [[ 0.1301, -0.1406, -0.1210],\n",
      "         [ 0.1633,  0.4804,  0.0105],\n",
      "         [ 0.3133, -0.1430, -0.1653]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.hook_mlp_out\n",
      "tensor([[[-0.0600,  1.3658,  0.5076],\n",
      "         [-0.9755,  0.9831, -0.0983],\n",
      "         [-0.0554,  0.6146, -1.0457]],\n",
      "\n",
      "        [[-0.1786, -0.4632, -0.1447],\n",
      "         [ 0.0128, -0.3829, -1.9348],\n",
      "         [-0.4157, -0.1766, -1.4531]],\n",
      "\n",
      "        [[-0.0783,  0.2843, -0.5885],\n",
      "         [-0.3159,  0.7319,  0.6529],\n",
      "         [ 0.9991,  1.0248,  0.7865]]], grad_fn=<SliceBackward0>)\n",
      "blocks.0.hook_resid_post\n",
      "tensor([[[-0.2177,  1.0492, -0.0417],\n",
      "         [-1.1884,  1.2324, -0.7312],\n",
      "         [ 0.3471,  0.8123, -1.6910]],\n",
      "\n",
      "        [[-0.1394, -0.5242, -0.2247],\n",
      "         [ 0.4305, -0.1622, -2.5225],\n",
      "         [-0.3886,  0.4223, -1.9231]],\n",
      "\n",
      "        [[ 0.3154,  0.5033, -0.2122],\n",
      "         [-0.6967,  1.0259,  0.5512],\n",
      "         [ 2.5398,  1.2196,  1.5173]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.hook_resid_pre\n",
      "tensor([[[-0.2177,  1.0492, -0.0417],\n",
      "         [-1.1884,  1.2324, -0.7312],\n",
      "         [ 0.3471,  0.8123, -1.6910]],\n",
      "\n",
      "        [[-0.1394, -0.5242, -0.2247],\n",
      "         [ 0.4305, -0.1622, -2.5225],\n",
      "         [-0.3886,  0.4223, -1.9231]],\n",
      "\n",
      "        [[ 0.3154,  0.5033, -0.2122],\n",
      "         [-0.6967,  1.0259,  0.5512],\n",
      "         [ 2.5398,  1.2196,  1.5173]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.ln1.hook_scale\n",
      "tensor([[[4.7029],\n",
      "         [2.2181],\n",
      "         [2.1036]],\n",
      "\n",
      "        [[4.3227],\n",
      "         [2.0090],\n",
      "         [2.1998]],\n",
      "\n",
      "        [[4.9118],\n",
      "         [2.0020],\n",
      "         [2.2004]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.ln1.hook_normalized\n",
      "tensor([[[-0.0463,  0.2231, -0.0089],\n",
      "         [-0.5358,  0.5556, -0.3296],\n",
      "         [ 0.1650,  0.3861, -0.8039]],\n",
      "\n",
      "        [[-0.0322, -0.1213, -0.0520],\n",
      "         [ 0.2143, -0.0807, -1.2556],\n",
      "         [-0.1767,  0.1920, -0.8742]],\n",
      "\n",
      "        [[ 0.0642,  0.1025, -0.0432],\n",
      "         [-0.3480,  0.5124,  0.2753],\n",
      "         [ 1.1543,  0.5543,  0.6896]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.ln1.hook_scale\n",
      "tensor([[[4.7029],\n",
      "         [2.2181],\n",
      "         [2.1036]],\n",
      "\n",
      "        [[4.3227],\n",
      "         [2.0090],\n",
      "         [2.1998]],\n",
      "\n",
      "        [[4.9118],\n",
      "         [2.0020],\n",
      "         [2.2004]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.ln1.hook_normalized\n",
      "tensor([[[-0.0463,  0.2231, -0.0089],\n",
      "         [-0.5358,  0.5556, -0.3296],\n",
      "         [ 0.1650,  0.3861, -0.8039]],\n",
      "\n",
      "        [[-0.0322, -0.1213, -0.0520],\n",
      "         [ 0.2143, -0.0807, -1.2556],\n",
      "         [-0.1767,  0.1920, -0.8742]],\n",
      "\n",
      "        [[ 0.0642,  0.1025, -0.0432],\n",
      "         [-0.3480,  0.5124,  0.2753],\n",
      "         [ 1.1543,  0.5543,  0.6896]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.ln1.hook_scale\n",
      "tensor([[[4.7029],\n",
      "         [2.2181],\n",
      "         [2.1036]],\n",
      "\n",
      "        [[4.3227],\n",
      "         [2.0090],\n",
      "         [2.1998]],\n",
      "\n",
      "        [[4.9118],\n",
      "         [2.0020],\n",
      "         [2.2004]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.ln1.hook_normalized\n",
      "tensor([[[-0.0463,  0.2231, -0.0089],\n",
      "         [-0.5358,  0.5556, -0.3296],\n",
      "         [ 0.1650,  0.3861, -0.8039]],\n",
      "\n",
      "        [[-0.0322, -0.1213, -0.0520],\n",
      "         [ 0.2143, -0.0807, -1.2556],\n",
      "         [-0.1767,  0.1920, -0.8742]],\n",
      "\n",
      "        [[ 0.0642,  0.1025, -0.0432],\n",
      "         [-0.3480,  0.5124,  0.2753],\n",
      "         [ 1.1543,  0.5543,  0.6896]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.attn.hook_q\n",
      "tensor([[[[-0.1871, -0.2223,  1.0324],\n",
      "          [-0.2269, -0.2392, -0.3365],\n",
      "          [-0.1768, -0.2171,  0.4541]],\n",
      "\n",
      "         [[-0.5674, -1.1630,  1.7533],\n",
      "          [ 1.3283,  0.6936,  0.4308],\n",
      "          [ 0.2903, -0.9949,  0.4981]],\n",
      "\n",
      "         [[-1.3146, -1.0076,  1.0360],\n",
      "          [ 0.6542,  0.9696,  1.2036],\n",
      "          [ 0.1521, -0.8506,  0.5421]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1553,  0.1126,  1.2610],\n",
      "          [ 0.1260, -0.5991, -0.4024],\n",
      "          [-0.1838, -0.3256,  0.3625]],\n",
      "\n",
      "         [[-0.4977, -0.5166,  1.0814],\n",
      "          [ 0.7481,  0.8875,  0.8410],\n",
      "          [ 0.0827, -1.1185,  0.3373]],\n",
      "\n",
      "         [[-1.3207, -0.0572,  2.5683],\n",
      "          [ 0.2937,  0.8867,  1.1633],\n",
      "          [ 0.0326, -1.1207,  0.5559]]],\n",
      "\n",
      "\n",
      "        [[[-0.0305, -0.4081,  0.9326],\n",
      "          [-0.0141, -0.3008, -0.1992],\n",
      "          [-0.2029, -0.3494,  0.3958]],\n",
      "\n",
      "         [[-1.0428, -0.0420,  2.1662],\n",
      "          [-0.3273,  1.3479,  1.0159],\n",
      "          [ 0.1604, -1.0405,  0.0755]],\n",
      "\n",
      "         [[-2.5224,  0.7761,  1.1418],\n",
      "          [-0.4961,  1.1807,  0.6275],\n",
      "          [ 0.0591, -0.7778,  0.5099]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.attn.hook_k\n",
      "tensor([[[[-0.1990,  1.6914, -1.6610],\n",
      "          [-0.7282, -0.7517, -0.5477],\n",
      "          [ 0.2710,  0.0852,  0.0247]],\n",
      "\n",
      "         [[ 0.6793,  1.0616, -1.1084],\n",
      "          [-0.7243, -0.1234, -1.2858],\n",
      "          [ 0.1869,  0.2215, -0.5798]],\n",
      "\n",
      "         [[ 0.4725,  1.9260,  0.2325],\n",
      "          [ 0.1328, -0.0561, -1.2033],\n",
      "          [-0.0499,  0.0752, -0.0350]]],\n",
      "\n",
      "\n",
      "        [[[-0.3592,  1.4627, -1.9380],\n",
      "          [-1.6417, -0.6039, -0.7972],\n",
      "          [ 0.1013,  0.1038,  0.0427]],\n",
      "\n",
      "         [[ 1.0763,  1.1612, -0.1926],\n",
      "          [-1.0352,  0.0995, -1.0508],\n",
      "          [-0.3206,  0.1611, -0.0119]],\n",
      "\n",
      "         [[ 0.4891,  1.8057,  0.0793],\n",
      "          [-0.1673,  0.0753, -1.7876],\n",
      "          [ 0.2929, -0.1336, -0.1354]]],\n",
      "\n",
      "\n",
      "        [[[-0.1096,  1.6444, -1.5696],\n",
      "          [-1.0550, -0.8118, -0.7719],\n",
      "          [ 0.3559,  0.1754, -0.1576]],\n",
      "\n",
      "         [[ 0.9794,  1.8985, -1.3108],\n",
      "          [-0.2306, -0.2519, -1.6464],\n",
      "          [ 0.0670,  0.5043, -0.5631]],\n",
      "\n",
      "         [[-0.4826,  2.3663, -0.9217],\n",
      "          [ 0.1015, -0.1943, -1.2021],\n",
      "          [-0.2240,  0.0912, -0.2042]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.attn.hook_v\n",
      "tensor([[[[ 0.0652, -0.0953, -0.0149],\n",
      "          [ 0.1866, -0.3324,  0.0118],\n",
      "          [ 0.4400, -0.0597, -0.1174]],\n",
      "\n",
      "         [[-0.4323,  0.1672, -0.0357],\n",
      "          [ 0.1812, -0.1340,  0.0409],\n",
      "          [ 1.2321, -0.0516,  0.0182]],\n",
      "\n",
      "         [[-0.1721, -0.0513, -0.0676],\n",
      "          [ 0.0073, -0.2760, -0.0784],\n",
      "          [ 1.1191,  0.7298, -0.0800]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2192,  0.1067,  0.0640],\n",
      "          [ 0.4375,  0.0041, -0.0906],\n",
      "          [ 0.3577, -0.0653, -0.0602]],\n",
      "\n",
      "         [[-0.3339, -0.9877, -0.0567],\n",
      "          [ 1.0294, -0.6365,  0.8617],\n",
      "          [ 1.1766, -0.0961,  0.3047]],\n",
      "\n",
      "         [[-0.1221,  0.1566, -0.3135],\n",
      "          [ 0.0058, -0.1004, -0.0726],\n",
      "          [ 1.0614, -0.0158, -0.1102]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1564,  0.1969, -0.0704],\n",
      "          [ 0.2999,  0.1452, -0.2370],\n",
      "          [ 0.3337,  0.0245, -0.0576]],\n",
      "\n",
      "         [[-0.4426, -0.0251, -0.2383],\n",
      "          [ 0.2370,  0.4207,  0.2759],\n",
      "          [ 0.8490,  0.3902,  0.6493]],\n",
      "\n",
      "         [[ 0.4468, -0.3420,  0.3183],\n",
      "          [-0.0127,  0.2066,  0.6341],\n",
      "          [ 0.8253,  0.1714, -0.1773]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.attn.hook_attn_scores\n",
      "tensor([[[[ 4.3663e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.7886e+00, -2.5764e+00, -1.0000e+05],\n",
      "          [ 6.4302e-01, -9.9753e-01, -5.3856e-01]],\n",
      "\n",
      "         [[ 8.1043e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.4432e+00, -1.8832e+00, -1.0000e+05],\n",
      "          [ 3.3161e-01, -1.4427e+00, -1.4199e+00]],\n",
      "\n",
      "         [[-9.2828e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-1.0098e+00, -4.5437e+00, -1.0000e+05],\n",
      "          [-1.4956e+00, -4.1853e+00, -2.9479e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7720e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 8.9333e-01, -2.4334e+00, -1.0000e+05],\n",
      "          [-9.8761e-01, -1.8983e+00, -1.3976e+00]],\n",
      "\n",
      "         [[ 7.0216e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-1.7899e-01, -2.9374e+00, -1.0000e+05],\n",
      "          [-6.2064e-01, -2.3543e+00, -2.3055e+00]],\n",
      "\n",
      "         [[-9.9059e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-9.1649e-01, -4.0440e+00, -1.0000e+05],\n",
      "          [-1.4090e+00, -3.7194e+00, -2.8924e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6450e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.5337e+00, -3.5051e+00, -1.0000e+05],\n",
      "          [ 2.7282e+00,  3.8924e-01,  1.3988e+00]],\n",
      "\n",
      "         [[ 7.6784e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.4575e+00, -1.4033e+00, -1.0000e+05],\n",
      "          [-1.4027e-01, -1.4177e+00, -2.1446e+00]],\n",
      "\n",
      "         [[-1.0319e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [-8.3180e-01, -4.4699e+00, -1.0000e+05],\n",
      "          [-1.2652e+00, -4.0297e+00, -2.9955e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.attn.hook_pattern\n",
      "tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9874, 0.0126, 0.0000],\n",
      "          [0.6664, 0.1292, 0.2044]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9653, 0.0347, 0.0000],\n",
      "          [0.7445, 0.1263, 0.1292]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9716, 0.0284, 0.0000],\n",
      "          [0.7681, 0.0522, 0.1798]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9653, 0.0347, 0.0000],\n",
      "          [0.4840, 0.1947, 0.3212]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9404, 0.0596, 0.0000],\n",
      "          [0.7342, 0.1297, 0.1362]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9580, 0.0420, 0.0000],\n",
      "          [0.7541, 0.0748, 0.1711]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9936, 0.0064, 0.0000],\n",
      "          [0.7347, 0.0708, 0.1944]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9459, 0.0541, 0.0000],\n",
      "          [0.7075, 0.1972, 0.0953]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9744, 0.0256, 0.0000],\n",
      "          [0.8063, 0.0508, 0.1429]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.attn.hook_z\n",
      "tensor([[[[ 0.0652, -0.0953, -0.0149],\n",
      "          [ 0.1866, -0.3324,  0.0118],\n",
      "          [ 0.4400, -0.0597, -0.1174]],\n",
      "\n",
      "         [[ 0.0589, -0.0920, -0.0152],\n",
      "          [ 0.1864, -0.3256,  0.0128],\n",
      "          [ 0.4625, -0.0595, -0.1136]],\n",
      "\n",
      "         [[-0.0476, -0.0524, -0.0284],\n",
      "          [ 0.1628, -0.3001,  0.0038],\n",
      "          [ 0.6034,  0.0827, -0.1036]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2192,  0.1067,  0.0640],\n",
      "          [ 0.4375,  0.0041, -0.0906],\n",
      "          [ 0.3577, -0.0653, -0.0602]],\n",
      "\n",
      "         [[ 0.2000,  0.0687,  0.0598],\n",
      "          [ 0.4728, -0.0341, -0.0338],\n",
      "          [ 0.3921, -0.0666, -0.0448]],\n",
      "\n",
      "         [[ 0.0019, -0.0904, -0.0808],\n",
      "          [ 0.4555, -0.0932,  0.0354],\n",
      "          [ 0.5394, -0.0591, -0.0414]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1564,  0.1969, -0.0704],\n",
      "          [ 0.2999,  0.1452, -0.2370],\n",
      "          [ 0.3337,  0.0245, -0.0576]],\n",
      "\n",
      "         [[ 0.1526,  0.1955, -0.0715],\n",
      "          [ 0.2965,  0.1601, -0.2092],\n",
      "          [ 0.3469,  0.0339, -0.0395]],\n",
      "\n",
      "         [[ 0.1704,  0.0764, -0.0067],\n",
      "          [ 0.2577,  0.2054, -0.0528],\n",
      "          [ 0.4301,  0.0641, -0.0388]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.hook_attn_out\n",
      "tensor([[[-0.2078,  0.3971, -0.5746],\n",
      "         [ 0.1422,  0.4071, -0.4559],\n",
      "         [ 0.2021,  0.6446, -0.4604]],\n",
      "\n",
      "        [[-0.3497,  0.3659, -0.4696],\n",
      "         [-0.2465,  0.8048, -0.4663],\n",
      "         [-0.0772,  0.6916, -0.4689]],\n",
      "\n",
      "        [[ 0.1087, -0.2898, -0.1008],\n",
      "         [ 0.3525,  0.0432, -0.2471],\n",
      "         [ 0.3503,  0.1152, -0.3040]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.hook_resid_mid\n",
      "tensor([[[-0.4254,  1.4463, -0.6163],\n",
      "         [-1.0461,  1.6396, -1.1870],\n",
      "         [ 0.5492,  1.4568, -2.1514]],\n",
      "\n",
      "        [[-0.4891, -0.1583, -0.6943],\n",
      "         [ 0.1840,  0.6426, -2.9888],\n",
      "         [-0.4658,  1.1139, -2.3919]],\n",
      "\n",
      "        [[ 0.4242,  0.2136, -0.3130],\n",
      "         [-0.3442,  1.0691,  0.3041],\n",
      "         [ 2.8901,  1.3348,  1.2133]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.ln2.hook_scale\n",
      "tensor([[[5.7615],\n",
      "         [2.3803],\n",
      "         [2.1978]],\n",
      "\n",
      "        [[5.4130],\n",
      "         [2.2093],\n",
      "         [2.2512]],\n",
      "\n",
      "        [[5.9583],\n",
      "         [2.0730],\n",
      "         [2.2257]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.ln2.hook_normalized\n",
      "tensor([[[-0.0738,  0.2510, -0.1070],\n",
      "         [-0.4395,  0.6888, -0.4987],\n",
      "         [ 0.2499,  0.6629, -0.9789]],\n",
      "\n",
      "        [[-0.0904, -0.0292, -0.1283],\n",
      "         [ 0.0833,  0.2909, -1.3528],\n",
      "         [-0.2069,  0.4948, -1.0625]],\n",
      "\n",
      "        [[ 0.0712,  0.0358, -0.0525],\n",
      "         [-0.1660,  0.5157,  0.1467],\n",
      "         [ 1.2985,  0.5997,  0.5451]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.mlp.hook_pre\n",
      "tensor([[[ 6.3996e-03, -1.0719e+00,  5.1056e-01],\n",
      "         [-9.7017e-01, -2.3464e+00, -1.2074e+00],\n",
      "         [-3.5575e-01, -2.1133e+00, -1.9081e+00]],\n",
      "\n",
      "        [[-8.7348e-02, -1.4529e+00,  3.2473e-01],\n",
      "         [-1.1701e+00, -2.5896e+00, -5.9029e-01],\n",
      "         [-4.3198e-01, -2.7863e+00, -9.9179e-01]],\n",
      "\n",
      "        [[ 1.7984e-01, -1.1452e+00,  5.6071e-01],\n",
      "         [-5.3460e-01, -2.8606e+00, -3.2626e-03],\n",
      "         [-1.2948e+00, -3.9026e+00, -6.2935e-02]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.mlp.hook_post\n",
      "tensor([[[ 3.2162e-03, -1.5226e-01,  3.5491e-01],\n",
      "         [-1.6117e-01, -2.1871e-02, -1.3742e-01],\n",
      "         [-1.2843e-01, -3.6340e-02, -5.3771e-02]],\n",
      "\n",
      "        [[-4.0634e-02, -1.0647e-01,  2.0370e-01],\n",
      "         [-1.4176e-01, -1.1979e-02, -1.6384e-01],\n",
      "         [-1.4381e-01, -6.9594e-03, -1.5948e-01]],\n",
      "\n",
      "        [[ 1.0275e-01, -1.4456e-01,  3.9948e-01],\n",
      "         [-1.5851e-01, -5.5932e-03, -1.6271e-03],\n",
      "         [-1.2673e-01, -1.1084e-04, -2.9888e-02]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.hook_mlp_out\n",
      "tensor([[[-0.3866, -1.1211, -0.4907],\n",
      "         [ 0.0308,  0.1414,  0.1925],\n",
      "         [-0.4776,  0.3963, -0.2807]],\n",
      "\n",
      "        [[-1.0146, -0.8976, -0.8246],\n",
      "         [ 0.9003, -0.4349, -0.5894],\n",
      "         [-0.4865,  0.0773, -0.4656]],\n",
      "\n",
      "        [[-0.9968, -0.9517, -0.5711],\n",
      "         [ 0.9397,  0.4875, -0.0867],\n",
      "         [-0.2481,  0.4831,  0.5837]]], grad_fn=<SliceBackward0>)\n",
      "blocks.1.hook_resid_post\n",
      "tensor([[[-0.8121,  0.3252, -1.1070],\n",
      "         [-1.0153,  1.7810, -0.9946],\n",
      "         [ 0.0716,  1.8531, -2.4321]],\n",
      "\n",
      "        [[-1.5036, -1.0559, -1.5188],\n",
      "         [ 1.0843,  0.2077, -3.5782],\n",
      "         [-0.9523,  1.1912, -2.8575]],\n",
      "\n",
      "        [[-0.5726, -0.7381, -0.8841],\n",
      "         [ 0.5955,  1.5565,  0.2175],\n",
      "         [ 2.6421,  1.8179,  1.7970]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.hook_resid_pre\n",
      "tensor([[[-0.8121,  0.3252, -1.1070],\n",
      "         [-1.0153,  1.7810, -0.9946],\n",
      "         [ 0.0716,  1.8531, -2.4321]],\n",
      "\n",
      "        [[-1.5036, -1.0559, -1.5188],\n",
      "         [ 1.0843,  0.2077, -3.5782],\n",
      "         [-0.9523,  1.1912, -2.8575]],\n",
      "\n",
      "        [[-0.5726, -0.7381, -0.8841],\n",
      "         [ 0.5955,  1.5565,  0.2175],\n",
      "         [ 2.6421,  1.8179,  1.7970]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.ln1.hook_scale\n",
      "tensor([[[22.8318],\n",
      "         [ 2.3564],\n",
      "         [ 2.1402]],\n",
      "\n",
      "        [[22.0891],\n",
      "         [ 2.2930],\n",
      "         [ 2.2881]],\n",
      "\n",
      "        [[22.7238],\n",
      "         [ 2.1141],\n",
      "         [ 2.3807]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.ln1.hook_normalized\n",
      "tensor([[[-0.0356,  0.0142, -0.0485],\n",
      "         [-0.4309,  0.7558, -0.4221],\n",
      "         [ 0.0334,  0.8659, -1.1364]],\n",
      "\n",
      "        [[-0.0681, -0.0478, -0.0688],\n",
      "         [ 0.4729,  0.0906, -1.5605],\n",
      "         [-0.4162,  0.5206, -1.2489]],\n",
      "\n",
      "        [[-0.0252, -0.0325, -0.0389],\n",
      "         [ 0.2817,  0.7363,  0.1029],\n",
      "         [ 1.1098,  0.7636,  0.7548]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.ln1.hook_scale\n",
      "tensor([[[22.8318],\n",
      "         [ 2.3564],\n",
      "         [ 2.1402]],\n",
      "\n",
      "        [[22.0891],\n",
      "         [ 2.2930],\n",
      "         [ 2.2881]],\n",
      "\n",
      "        [[22.7238],\n",
      "         [ 2.1141],\n",
      "         [ 2.3807]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.ln1.hook_normalized\n",
      "tensor([[[-0.0356,  0.0142, -0.0485],\n",
      "         [-0.4309,  0.7558, -0.4221],\n",
      "         [ 0.0334,  0.8659, -1.1364]],\n",
      "\n",
      "        [[-0.0681, -0.0478, -0.0688],\n",
      "         [ 0.4729,  0.0906, -1.5605],\n",
      "         [-0.4162,  0.5206, -1.2489]],\n",
      "\n",
      "        [[-0.0252, -0.0325, -0.0389],\n",
      "         [ 0.2817,  0.7363,  0.1029],\n",
      "         [ 1.1098,  0.7636,  0.7548]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.ln1.hook_scale\n",
      "tensor([[[22.8318],\n",
      "         [ 2.3564],\n",
      "         [ 2.1402]],\n",
      "\n",
      "        [[22.0891],\n",
      "         [ 2.2930],\n",
      "         [ 2.2881]],\n",
      "\n",
      "        [[22.7238],\n",
      "         [ 2.1141],\n",
      "         [ 2.3807]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.ln1.hook_normalized\n",
      "tensor([[[-0.0356,  0.0142, -0.0485],\n",
      "         [-0.4309,  0.7558, -0.4221],\n",
      "         [ 0.0334,  0.8659, -1.1364]],\n",
      "\n",
      "        [[-0.0681, -0.0478, -0.0688],\n",
      "         [ 0.4729,  0.0906, -1.5605],\n",
      "         [-0.4162,  0.5206, -1.2489]],\n",
      "\n",
      "        [[-0.0252, -0.0325, -0.0389],\n",
      "         [ 0.2817,  0.7363,  0.1029],\n",
      "         [ 1.1098,  0.7636,  0.7548]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.attn.hook_q\n",
      "tensor([[[[ 0.1688, -0.3615,  0.2378],\n",
      "          [ 0.0120, -0.2013,  0.1654],\n",
      "          [-0.7814,  0.9079, -0.3896]],\n",
      "\n",
      "         [[-0.0711,  0.2744,  0.5626],\n",
      "          [ 0.8478, -0.5757, -1.8267],\n",
      "          [-1.2911,  0.1039,  0.4834]],\n",
      "\n",
      "         [[ 0.5612,  0.8385,  1.8211],\n",
      "          [ 0.6690, -0.2965, -2.1761],\n",
      "          [-1.4751, -2.3326,  0.6705]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1533, -0.3693,  0.2037],\n",
      "          [-0.0797, -0.1444,  0.0297],\n",
      "          [-0.7775,  0.9258, -0.5337]],\n",
      "\n",
      "         [[ 0.6869,  0.3955, -0.3525],\n",
      "          [ 2.2156,  0.8939, -3.3245],\n",
      "          [-0.5621, -0.8421, -0.1938]],\n",
      "\n",
      "         [[-0.6163,  0.6561,  0.4930],\n",
      "          [ 1.0773, -0.6582, -3.7796],\n",
      "          [-1.0674, -1.0661,  0.9495]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1865, -0.3726,  0.2371],\n",
      "          [-0.0080, -0.2770,  0.1307],\n",
      "          [-0.7760,  0.9605, -0.4774]],\n",
      "\n",
      "         [[ 0.6088, -0.0735, -0.4267],\n",
      "          [ 1.0514, -0.6968, -1.5170],\n",
      "          [-0.6422,  0.0200, -0.3581]],\n",
      "\n",
      "         [[ 0.3209,  0.9684,  0.0822],\n",
      "          [ 0.0477, -0.0358, -1.1601],\n",
      "          [-0.7390, -1.3204,  1.6491]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.attn.hook_k\n",
      "tensor([[[[-0.1180, -1.2233,  0.3091],\n",
      "          [-0.4762,  0.3484, -0.4350],\n",
      "          [ 1.2082,  3.1067,  3.7896]],\n",
      "\n",
      "         [[ 0.5252, -3.6078,  0.3468],\n",
      "          [-1.3358, -0.7146, -0.7712],\n",
      "          [-3.2016,  2.3669, -1.7370]],\n",
      "\n",
      "         [[-1.5534, -3.1862,  0.0536],\n",
      "          [-1.8191, -0.8025, -0.1790],\n",
      "          [-3.9415,  2.3831, -3.0858]]],\n",
      "\n",
      "\n",
      "        [[[-0.1035, -1.2084,  0.2528],\n",
      "          [-0.4483,  0.4167, -0.3898],\n",
      "          [ 1.3571,  3.0147,  3.8478]],\n",
      "\n",
      "         [[-1.7177, -3.5667,  0.3668],\n",
      "          [-1.1629, -0.8835, -0.6918],\n",
      "          [-3.1428,  1.7552, -1.3870]],\n",
      "\n",
      "         [[ 0.5771, -3.6326,  0.0798],\n",
      "          [-2.7710, -1.6686, -0.5302],\n",
      "          [-3.1466,  1.0341, -3.5970]]],\n",
      "\n",
      "\n",
      "        [[[-0.0859, -1.2100,  0.2665],\n",
      "          [-0.5226,  0.3659, -0.4957],\n",
      "          [ 1.2784,  3.0469,  3.8398]],\n",
      "\n",
      "         [[-0.1623, -2.8086,  0.3125],\n",
      "          [-1.9622, -1.0415, -1.0516],\n",
      "          [-3.1587,  1.8436, -1.2308]],\n",
      "\n",
      "         [[-0.0145, -1.9115,  0.4501],\n",
      "          [-1.7262,  0.3731, -0.0544],\n",
      "          [-1.8329,  0.9604, -3.5215]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.attn.hook_v\n",
      "tensor([[[[-0.0176,  0.1131, -0.2444],\n",
      "          [-0.0244, -0.1288,  0.0688],\n",
      "          [ 0.0151, -0.5082, -0.0522]],\n",
      "\n",
      "         [[ 0.5041, -1.0557,  0.5156],\n",
      "          [ 0.8580, -0.0727, -0.1756],\n",
      "          [ 0.0297, -1.3015, -0.0038]],\n",
      "\n",
      "         [[ 0.0485, -0.9808,  1.0172],\n",
      "          [ 0.1010,  0.1736, -0.9706],\n",
      "          [-0.1800, -0.8761, -0.0072]]],\n",
      "\n",
      "\n",
      "        [[[-0.0148,  0.1470, -0.2061],\n",
      "          [ 0.0142, -0.1403,  0.0867],\n",
      "          [-0.0069, -0.4656, -0.0720]],\n",
      "\n",
      "         [[ 0.2023, -0.5183,  0.3712],\n",
      "          [ 0.2036, -1.0732,  0.6314],\n",
      "          [-0.3761, -1.0820,  0.2205]],\n",
      "\n",
      "         [[ 0.2210, -0.5161,  0.2754],\n",
      "          [-1.0801,  1.5937, -0.1101],\n",
      "          [-0.3777, -1.2277, -0.1210]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0065,  0.0960, -0.2324],\n",
      "          [ 0.0103, -0.1366,  0.0677],\n",
      "          [ 0.0238, -0.5264, -0.0772]],\n",
      "\n",
      "         [[ 0.9943, -0.9951,  0.1814],\n",
      "          [ 0.6450,  0.0417,  0.0202],\n",
      "          [ 0.0808, -1.5631,  0.1512]],\n",
      "\n",
      "         [[ 0.7410, -0.3151, -0.0135],\n",
      "          [-0.3469, -0.4255,  0.2590],\n",
      "          [ 0.6643, -0.7967,  0.3316]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.attn.hook_attn_scores\n",
      "tensor([[[[ 1.7912e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-4.6791e-01, -3.7222e+00, -1.0000e+05],\n",
      "          [-1.2467e+00, -2.1435e+00, -3.5530e+00]],\n",
      "\n",
      "         [[-6.4562e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.9626e+00, -1.1581e+00, -1.0000e+05],\n",
      "          [ 1.4928e+00, -1.8826e+00, -2.1275e+00]],\n",
      "\n",
      "         [[-7.6341e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 6.5367e-01, -4.1948e+00, -1.0000e+05],\n",
      "          [-3.9998e+00, -3.9751e+00, -4.6155e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7683e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-1.2286e-01, -2.7317e+00, -1.0000e+05],\n",
      "          [-8.9001e-01, -2.1450e+00, -3.0393e+00]],\n",
      "\n",
      "         [[-6.3615e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.3227e+00, -2.6100e+00, -1.0000e+05],\n",
      "          [ 1.3345e+00, -1.6347e+00, -1.2070e+00]],\n",
      "\n",
      "         [[-7.7034e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-7.5877e-01, -4.6011e+00, -1.0000e+05],\n",
      "          [-3.8407e+00, -4.1963e+00, -4.8047e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6317e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-3.6906e-01, -4.5735e+00, -1.0000e+05],\n",
      "          [-8.9146e-01, -3.8021e+00, -3.0791e+00]],\n",
      "\n",
      "         [[-6.7527e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.0314e+00, -2.1776e+00, -1.0000e+05],\n",
      "          [ 4.4006e-01, -7.5132e-01, -1.9133e+00]],\n",
      "\n",
      "         [[-8.1035e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.8262e-01, -4.7900e+00, -1.0000e+05],\n",
      "          [-2.7729e+00, -2.3570e+00, -4.8633e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.attn.hook_pattern\n",
      "tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9628, 0.0372, 0.0000],\n",
      "          [0.6634, 0.2706, 0.0661]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9577, 0.0423, 0.0000],\n",
      "          [0.9425, 0.0322, 0.0252]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9922, 0.0078, 0.0000],\n",
      "          [0.3898, 0.3996, 0.2106]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9314, 0.0686, 0.0000],\n",
      "          [0.7134, 0.2034, 0.0832]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9808, 0.0192, 0.0000],\n",
      "          [0.8849, 0.0454, 0.0697]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9790, 0.0210, 0.0000],\n",
      "          [0.4803, 0.3366, 0.1832]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9853, 0.0147, 0.0000],\n",
      "          [0.8572, 0.0467, 0.0962]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9612, 0.0388, 0.0000],\n",
      "          [0.7149, 0.2172, 0.0679]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9931, 0.0069, 0.0000],\n",
      "          [0.3789, 0.5743, 0.0468]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.attn.hook_z\n",
      "tensor([[[[-1.7560e-02,  1.1308e-01, -2.4437e-01],\n",
      "          [-2.4435e-02, -1.2879e-01,  6.8781e-02],\n",
      "          [ 1.5070e-02, -5.0819e-01, -5.2179e-02]],\n",
      "\n",
      "         [[ 1.8332e-03,  6.9635e-02, -2.1612e-01],\n",
      "          [ 1.2860e-02, -1.2642e-01,  5.8454e-02],\n",
      "          [ 1.5184e-02, -5.1436e-01, -5.1803e-02]],\n",
      "\n",
      "         [[ 1.2796e-01, -2.7543e-01,  4.4604e-02],\n",
      "          [ 7.1804e-03, -1.1935e-01,  3.4674e-02],\n",
      "          [-2.0149e-02, -9.0265e-01, -2.3372e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4757e-02,  1.4700e-01, -2.0608e-01],\n",
      "          [ 1.4176e-02, -1.4025e-01,  8.6678e-02],\n",
      "          [-6.8825e-03, -4.6555e-01, -7.1963e-02]],\n",
      "\n",
      "         [[ 1.2769e-04,  1.0138e-01, -1.6649e-01],\n",
      "          [ 1.7816e-02, -1.5818e-01,  9.7144e-02],\n",
      "          [-1.4634e-02, -4.7849e-01, -6.5822e-02]],\n",
      "\n",
      "         [[ 4.9002e-02, -4.3453e-02, -4.8624e-02],\n",
      "          [-5.3472e-02, -6.1817e-02,  9.7715e-02],\n",
      "          [-1.9907e-01, -8.1264e-01,  1.7507e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4969e-03,  9.5997e-02, -2.3244e-01],\n",
      "          [ 1.0283e-02, -1.3658e-01,  6.7705e-02],\n",
      "          [ 2.3759e-02, -5.2644e-01, -7.7196e-02]],\n",
      "\n",
      "         [[ 2.1026e-02,  7.9948e-02, -2.2636e-01],\n",
      "          [ 3.4927e-02, -1.2966e-01,  6.5859e-02],\n",
      "          [ 2.4151e-02, -5.3357e-01, -7.5625e-02]],\n",
      "\n",
      "         [[ 1.2322e-01,  5.5506e-03, -1.9208e-01],\n",
      "          [ 1.2385e-01, -1.1749e-01,  7.0383e-02],\n",
      "          [ 8.6513e-02, -1.1344e+00,  7.3116e-02]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.hook_attn_out\n",
      "tensor([[[ 0.0509, -0.1287, -0.2154],\n",
      "         [ 0.0239, -0.1517, -0.2247],\n",
      "         [ 0.2154, -0.0639, -0.0957]],\n",
      "\n",
      "        [[-0.0288, -0.1721, -0.1292],\n",
      "         [-0.0477, -0.2062, -0.1285],\n",
      "         [-0.0848, -0.4280,  0.1929]],\n",
      "\n",
      "        [[ 0.0100, -0.1130, -0.1151],\n",
      "         [ 0.1050, -0.1169, -0.1523],\n",
      "         [ 0.4742,  0.0482, -0.2542]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.hook_resid_mid\n",
      "tensor([[[-7.6118e-01,  1.9641e-01, -1.3224e+00],\n",
      "         [-9.9139e-01,  1.6293e+00, -1.2193e+00],\n",
      "         [ 2.8697e-01,  1.7892e+00, -2.5278e+00]],\n",
      "\n",
      "        [[-1.5324e+00, -1.2280e+00, -1.6481e+00],\n",
      "         [ 1.0366e+00,  1.4805e-03, -3.7067e+00],\n",
      "         [-1.0371e+00,  7.6321e-01, -2.6646e+00]],\n",
      "\n",
      "        [[-5.6261e-01, -8.5109e-01, -9.9926e-01],\n",
      "         [ 7.0056e-01,  1.4396e+00,  6.5194e-02],\n",
      "         [ 3.1163e+00,  1.8662e+00,  1.5428e+00]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.ln2.hook_scale\n",
      "tensor([[[22.8653],\n",
      "         [ 2.4123],\n",
      "         [ 2.2284]],\n",
      "\n",
      "        [[22.1217],\n",
      "         [ 2.3544],\n",
      "         [ 2.3646]],\n",
      "\n",
      "        [[22.7585],\n",
      "         [ 2.1734],\n",
      "         [ 2.4745]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.ln2.hook_normalized\n",
      "tensor([[[-3.3290e-02,  8.5897e-03, -5.7834e-02],\n",
      "         [-4.1097e-01,  6.7540e-01, -5.0544e-01],\n",
      "         [ 1.2878e-01,  8.0290e-01, -1.1344e+00]],\n",
      "\n",
      "        [[-6.9272e-02, -5.5511e-02, -7.4500e-02],\n",
      "         [ 4.4028e-01,  6.2882e-04, -1.5744e+00],\n",
      "         [-4.3861e-01,  3.2277e-01, -1.1269e+00]],\n",
      "\n",
      "        [[-2.4721e-02, -3.7396e-02, -4.3907e-02],\n",
      "         [ 3.2234e-01,  6.6237e-01,  2.9996e-02],\n",
      "         [ 1.2593e+00,  7.5414e-01,  6.2349e-01]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.mlp.hook_pre\n",
      "tensor([[[ 0.6510, -1.7343,  0.6589],\n",
      "         [-1.5159, -1.6922,  0.3163],\n",
      "         [-0.5944, -1.6976, -0.2007]],\n",
      "\n",
      "        [[ 0.6082, -1.7425,  0.6540],\n",
      "         [-0.8433, -1.0011, -0.9657],\n",
      "         [-0.2517, -1.1099, -2.6290]],\n",
      "\n",
      "        [[ 0.6561, -1.7990,  0.6097],\n",
      "         [-0.5433, -2.7460, -0.6867],\n",
      "         [ 0.0853, -1.6951, -0.7689]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.mlp.hook_post\n",
      "tensor([[[ 0.4833, -0.0720,  0.4909],\n",
      "         [-0.0984, -0.0768,  0.1974],\n",
      "         [-0.1642, -0.0762, -0.0844]],\n",
      "\n",
      "        [[ 0.4430, -0.0710,  0.4861],\n",
      "         [-0.1684, -0.1587, -0.1615],\n",
      "         [-0.1008, -0.1484, -0.0108]],\n",
      "\n",
      "        [[ 0.4882, -0.0648,  0.4444],\n",
      "         [-0.1595, -0.0078, -0.1691],\n",
      "         [ 0.0455, -0.0765, -0.1700]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.hook_mlp_out\n",
      "tensor([[[-2.9334, -3.2071, -3.1580],\n",
      "         [ 0.4245, -0.4271, -0.0672],\n",
      "         [-0.2738,  0.3996,  0.0400]],\n",
      "\n",
      "        [[-2.8254, -3.4868, -3.0658],\n",
      "         [-0.1385,  0.2649, -0.1347],\n",
      "         [-0.7479,  0.3357,  0.0748]],\n",
      "\n",
      "        [[-3.0753, -3.2473, -3.2146],\n",
      "         [-0.6345, -0.4952, -0.1895],\n",
      "         [-1.0175,  0.3183,  0.8304]]], grad_fn=<SliceBackward0>)\n",
      "blocks.2.hook_resid_post\n",
      "tensor([[[-3.6946, -3.0107, -4.4804],\n",
      "         [-0.5669,  1.2022, -1.2864],\n",
      "         [ 0.0131,  2.1888, -2.4878]],\n",
      "\n",
      "        [[-4.3578, -4.7148, -4.7138],\n",
      "         [ 0.8981,  0.2664, -3.8414],\n",
      "         [-1.7850,  1.0989, -2.5898]],\n",
      "\n",
      "        [[-3.6379, -4.0984, -4.2139],\n",
      "         [ 0.0660,  0.9444, -0.1243],\n",
      "         [ 2.0987,  2.1844,  2.3732]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.hook_resid_pre\n",
      "tensor([[[-3.6946, -3.0107, -4.4804],\n",
      "         [-0.5669,  1.2022, -1.2864],\n",
      "         [ 0.0131,  2.1888, -2.4878]],\n",
      "\n",
      "        [[-4.3578, -4.7148, -4.7138],\n",
      "         [ 0.8981,  0.2664, -3.8414],\n",
      "         [-1.7850,  1.0989, -2.5898]],\n",
      "\n",
      "        [[-3.6379, -4.0984, -4.2139],\n",
      "         [ 0.0660,  0.9444, -0.1243],\n",
      "         [ 2.0987,  2.1844,  2.3732]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.ln1.hook_scale\n",
      "tensor([[[92.5947],\n",
      "         [ 2.4877],\n",
      "         [ 2.2752]],\n",
      "\n",
      "        [[91.8513],\n",
      "         [ 2.5439],\n",
      "         [ 2.5021]],\n",
      "\n",
      "        [[92.7008],\n",
      "         [ 2.3332],\n",
      "         [ 2.6756]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.ln1.hook_normalized\n",
      "tensor([[[-0.0399, -0.0325, -0.0484],\n",
      "         [-0.2279,  0.4833, -0.5171],\n",
      "         [ 0.0058,  0.9620, -1.0934]],\n",
      "\n",
      "        [[-0.0474, -0.0513, -0.0513],\n",
      "         [ 0.3530,  0.1047, -1.5101],\n",
      "         [-0.7134,  0.4392, -1.0350]],\n",
      "\n",
      "        [[-0.0392, -0.0442, -0.0455],\n",
      "         [ 0.0283,  0.4048, -0.0533],\n",
      "         [ 0.7844,  0.8164,  0.8870]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.ln1.hook_scale\n",
      "tensor([[[92.5947],\n",
      "         [ 2.4877],\n",
      "         [ 2.2752]],\n",
      "\n",
      "        [[91.8513],\n",
      "         [ 2.5439],\n",
      "         [ 2.5021]],\n",
      "\n",
      "        [[92.7008],\n",
      "         [ 2.3332],\n",
      "         [ 2.6756]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.ln1.hook_normalized\n",
      "tensor([[[-0.0399, -0.0325, -0.0484],\n",
      "         [-0.2279,  0.4833, -0.5171],\n",
      "         [ 0.0058,  0.9620, -1.0934]],\n",
      "\n",
      "        [[-0.0474, -0.0513, -0.0513],\n",
      "         [ 0.3530,  0.1047, -1.5101],\n",
      "         [-0.7134,  0.4392, -1.0350]],\n",
      "\n",
      "        [[-0.0392, -0.0442, -0.0455],\n",
      "         [ 0.0283,  0.4048, -0.0533],\n",
      "         [ 0.7844,  0.8164,  0.8870]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.ln1.hook_scale\n",
      "tensor([[[92.5947],\n",
      "         [ 2.4877],\n",
      "         [ 2.2752]],\n",
      "\n",
      "        [[91.8513],\n",
      "         [ 2.5439],\n",
      "         [ 2.5021]],\n",
      "\n",
      "        [[92.7008],\n",
      "         [ 2.3332],\n",
      "         [ 2.6756]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.ln1.hook_normalized\n",
      "tensor([[[-0.0399, -0.0325, -0.0484],\n",
      "         [-0.2279,  0.4833, -0.5171],\n",
      "         [ 0.0058,  0.9620, -1.0934]],\n",
      "\n",
      "        [[-0.0474, -0.0513, -0.0513],\n",
      "         [ 0.3530,  0.1047, -1.5101],\n",
      "         [-0.7134,  0.4392, -1.0350]],\n",
      "\n",
      "        [[-0.0392, -0.0442, -0.0455],\n",
      "         [ 0.0283,  0.4048, -0.0533],\n",
      "         [ 0.7844,  0.8164,  0.8870]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.attn.hook_q\n",
      "tensor([[[[-0.3929, -0.1015, -0.1131],\n",
      "          [-0.1919,  0.0514, -0.1767],\n",
      "          [ 0.4286, -0.4462,  0.0346]],\n",
      "\n",
      "         [[-1.9626, -1.0575, -0.0471],\n",
      "          [-2.3841,  0.5548, -0.2267],\n",
      "          [-1.4281, -0.8329, -1.2309]],\n",
      "\n",
      "         [[ 0.8014,  1.7904,  0.5288],\n",
      "          [-2.9396,  0.2175,  0.2245],\n",
      "          [-1.7731,  0.9113,  0.2405]]],\n",
      "\n",
      "\n",
      "        [[[-0.3846, -0.0882, -0.1017],\n",
      "          [-0.1692,  0.0371, -0.1889],\n",
      "          [ 0.4412, -0.4355,  0.0088]],\n",
      "\n",
      "         [[-3.1301, -0.9845, -1.9335],\n",
      "          [-2.0621,  0.9634, -0.8429],\n",
      "          [-2.1353,  0.1862, -1.7209]],\n",
      "\n",
      "         [[-3.7110,  0.1685, -0.0509],\n",
      "          [-2.7919,  0.3156, -0.0882],\n",
      "          [-2.3761,  0.5751, -0.5288]]],\n",
      "\n",
      "\n",
      "        [[[-0.4073, -0.0907, -0.1238],\n",
      "          [-0.1710,  0.0431, -0.1899],\n",
      "          [ 0.4305, -0.4379,  0.0148]],\n",
      "\n",
      "         [[-2.5663,  1.3521, -0.1969],\n",
      "          [-2.7767,  0.2592, -0.8215],\n",
      "          [-0.9999,  0.8856, -0.4428]],\n",
      "\n",
      "         [[ 0.5641,  0.7415, -1.5212],\n",
      "          [-1.5657,  0.6503, -0.6832],\n",
      "          [-1.4215,  1.5501,  0.7193]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.attn.hook_k\n",
      "tensor([[[[ 3.4320e-02, -2.2742e-01,  1.6557e-01],\n",
      "          [ 8.0331e-01,  1.8848e-01,  4.1907e-03],\n",
      "          [ 3.3563e-01, -3.5332e-01, -3.3339e-01]],\n",
      "\n",
      "         [[-1.0140e+00, -1.2496e+00,  5.1129e-01],\n",
      "          [-3.9194e-01, -2.0202e+00, -1.9460e+00],\n",
      "          [-5.6370e-01, -4.0678e+00, -1.5859e+00]],\n",
      "\n",
      "         [[ 1.1170e+00,  6.4669e-01,  5.7818e-01],\n",
      "          [ 1.2302e+00, -2.0051e+00, -4.6845e-01],\n",
      "          [-9.6794e-01, -6.8071e+00, -2.3851e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9989e-02, -1.7189e-01,  1.8381e-01],\n",
      "          [ 7.9800e-01,  1.9902e-01,  1.3628e-02],\n",
      "          [ 3.1482e-01, -3.3529e-01, -3.4843e-01]],\n",
      "\n",
      "         [[-1.3667e+00, -9.4232e-01,  1.5570e-02],\n",
      "          [ 8.0092e-01, -1.5510e+00, -2.8841e-01],\n",
      "          [-1.5996e+00, -4.3683e+00, -2.1087e+00]],\n",
      "\n",
      "         [[-2.3500e+00,  7.7447e-01,  8.3002e-01],\n",
      "          [ 1.0710e+00, -2.1579e+00, -2.3879e+00],\n",
      "          [-1.1744e+00, -5.3449e+00, -1.9102e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9235e-02, -2.0287e-01,  1.5006e-01],\n",
      "          [ 7.9895e-01,  1.8718e-01,  3.5432e-04],\n",
      "          [ 3.4200e-01, -3.4303e-01, -3.3098e-01]],\n",
      "\n",
      "         [[-1.5868e+00,  1.2602e+00, -3.4120e-01],\n",
      "          [ 1.0840e+00, -1.0752e+00, -1.3679e+00],\n",
      "          [-7.8614e-01, -5.0571e+00, -2.2703e+00]],\n",
      "\n",
      "         [[ 1.3381e-01,  2.7395e-01, -8.9402e-03],\n",
      "          [-1.6855e-01, -5.3439e-01, -1.9774e+00],\n",
      "          [-8.3490e-01, -5.2012e+00, -1.2215e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.attn.hook_v\n",
      "tensor([[[[ 1.6341e-04, -5.5822e-03,  3.1098e-02],\n",
      "          [-1.3944e-02,  7.3879e-02,  1.1532e-01],\n",
      "          [ 1.2330e-02, -8.1393e-02, -5.4807e-02]],\n",
      "\n",
      "         [[ 2.5369e-01, -7.7338e-01,  5.4701e-01],\n",
      "          [ 2.4401e-01, -2.0032e-01, -6.4863e-02],\n",
      "          [-4.7853e-02, -6.4037e-02, -2.3922e-01]],\n",
      "\n",
      "         [[ 6.5646e-01, -3.9812e-01, -1.7772e-01],\n",
      "          [-3.7881e-01, -8.6211e-02, -2.0073e-01],\n",
      "          [-2.8726e-01, -5.8736e-01, -5.6264e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3532e-03,  5.3524e-03,  2.3845e-02],\n",
      "          [-2.8061e-02,  8.4009e-02,  1.1645e-01],\n",
      "          [ 1.9006e-02, -8.0173e-02, -6.1427e-02]],\n",
      "\n",
      "         [[-1.8828e-01, -1.0495e+00,  2.5527e-01],\n",
      "          [-7.1043e-02, -3.4781e-01, -2.6365e-01],\n",
      "          [-2.3779e-01, -3.7938e-02, -5.3415e-01]],\n",
      "\n",
      "         [[-4.5830e-01, -1.1821e+00,  3.2925e-01],\n",
      "          [ 2.8555e-01, -9.5778e-01, -1.6303e-01],\n",
      "          [ 9.5215e-02, -2.0154e-02, -1.0905e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.5170e-03,  1.1542e-03,  2.9079e-02],\n",
      "          [-2.1336e-02,  7.3876e-02,  1.0943e-01],\n",
      "          [ 2.1560e-02, -8.2246e-02, -5.3202e-02]],\n",
      "\n",
      "         [[ 2.6766e-01, -1.2677e+00,  3.6022e-01],\n",
      "          [ 9.6127e-03, -4.2154e-02, -2.8200e-01],\n",
      "          [-2.4231e-02,  4.9392e-01, -4.7495e-01]],\n",
      "\n",
      "         [[-1.2730e-01, -1.5771e+00,  2.5113e-01],\n",
      "          [ 9.1843e-01,  3.7309e-01,  6.6209e-01],\n",
      "          [ 2.7620e-01,  3.4046e-01, -6.2632e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.attn.hook_attn_scores\n",
      "tensor([[[[ 1.3219e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 7.4628e+00,  3.8773e+00, -1.0000e+05],\n",
      "          [ 6.4975e+00, -1.7856e+00,  3.4366e+00]],\n",
      "\n",
      "         [[ 3.3462e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.0449e+00, -5.9258e+00, -1.0000e+05],\n",
      "          [-2.5334e+00, -4.7128e+00, -6.4761e+00]],\n",
      "\n",
      "         [[ 5.5171e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.9928e+00, -5.1970e+00, -1.0000e+05],\n",
      "          [-4.1321e+00, -3.7892e+00, -5.2344e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2978e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 6.7765e+00,  3.8692e+00, -1.0000e+05],\n",
      "          [ 6.7421e+00, -2.5009e+00,  4.2040e+00]],\n",
      "\n",
      "         [[ 3.2974e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.2625e+00, -5.6242e+00, -1.0000e+05],\n",
      "          [-2.6972e+00, -5.2942e+00, -4.5243e+00]],\n",
      "\n",
      "         [[ 5.4967e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.9796e+00, -5.0054e+00, -1.0000e+05],\n",
      "          [-4.1403e+00, -3.1901e+00, -4.4099e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3291e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 7.2404e+00,  3.9074e+00, -1.0000e+05],\n",
      "          [ 6.4774e+00, -1.0165e-01,  3.0912e+00]],\n",
      "\n",
      "         [[ 3.3114e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.0481e+00, -6.1957e+00, -1.0000e+05],\n",
      "          [-2.4005e+00, -3.9471e+00, -4.2080e+00]],\n",
      "\n",
      "         [[ 5.4358e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-3.1556e+00, -6.5786e+00, -1.0000e+05],\n",
      "          [-3.3166e+00, -4.0705e+00, -3.1111e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.attn.hook_pattern\n",
      "tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.7303e-01, 2.6975e-02, 0.0000e+00],\n",
      "          [9.5502e-01, 2.4137e-04, 4.4738e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.7978e-01, 2.0215e-02, 0.0000e+00],\n",
      "          [8.8300e-01, 9.9878e-02, 1.7126e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.0062e-01, 9.9376e-02, 0.0000e+00],\n",
      "          [3.6481e-01, 5.1403e-01, 1.2116e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.4821e-01, 5.1794e-02, 0.0000e+00],\n",
      "          [9.2669e-01, 8.9689e-05, 7.3221e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.6649e-01, 3.3513e-02, 0.0000e+00],\n",
      "          [8.0947e-01, 6.0302e-02, 1.3023e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [8.8349e-01, 1.1651e-01, 0.0000e+00],\n",
      "          [2.2988e-01, 5.9456e-01, 1.7556e-01]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.6555e-01, 3.4455e-02, 0.0000e+00],\n",
      "          [9.6597e-01, 1.3420e-03, 3.2688e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8444e-01, 1.5556e-02, 0.0000e+00],\n",
      "          [7.2620e-01, 1.5466e-01, 1.1914e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.6842e-01, 3.1585e-02, 0.0000e+00],\n",
      "          [3.7057e-01, 1.7435e-01, 4.5508e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.attn.hook_z\n",
      "tensor([[[[ 1.6341e-04, -5.5822e-03,  3.1098e-02],\n",
      "          [-1.3944e-02,  7.3879e-02,  1.1532e-01],\n",
      "          [ 1.2330e-02, -8.1393e-02, -5.4807e-02]],\n",
      "\n",
      "         [[ 7.0022e-03, -2.6293e-02,  4.5015e-02],\n",
      "          [-8.7294e-03,  6.8336e-02,  1.1168e-01],\n",
      "          [ 6.3489e-03, -7.9668e-02, -7.3133e-02]],\n",
      "\n",
      "         [[ 2.9586e-02, -2.3329e-02,  2.1880e-02],\n",
      "          [ 5.5707e-03,  4.3751e-02,  9.1912e-02],\n",
      "          [-5.4904e-02, -1.3377e-01, -2.1113e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3532e-03,  5.3524e-03,  2.3845e-02],\n",
      "          [-2.8061e-02,  8.4009e-02,  1.1645e-01],\n",
      "          [ 1.9006e-02, -8.0173e-02, -6.1427e-02]],\n",
      "\n",
      "         [[-7.5204e-03, -4.9284e-02,  3.5831e-02],\n",
      "          [-2.9502e-02,  6.9537e-02,  1.0371e-01],\n",
      "          [-1.0914e-02, -7.5252e-02, -1.1650e-01]],\n",
      "\n",
      "         [[-3.1393e-02, -8.1691e-02,  4.6227e-02],\n",
      "          [ 1.0188e-02, -7.7700e-02,  5.7135e-02],\n",
      "          [-1.2030e-01, -4.4525e-02, -3.5085e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.5170e-03,  1.1542e-03,  2.9079e-02],\n",
      "          [-2.1336e-02,  7.3876e-02,  1.0943e-01],\n",
      "          [ 2.1560e-02, -8.2246e-02, -5.3202e-02]],\n",
      "\n",
      "         [[ 2.9299e-03, -4.2562e-02,  4.0488e-02],\n",
      "          [-2.0854e-02,  7.2071e-02,  1.0334e-01],\n",
      "          [ 2.0114e-02, -6.4048e-02, -6.6522e-02]],\n",
      "\n",
      "         [[-1.0097e-02, -5.2140e-02,  3.6782e-02],\n",
      "          [ 9.5412e-02,  9.1579e-02,  1.1474e-01],\n",
      "          [ 1.2946e-01,  2.1057e-01, -3.8755e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.hook_attn_out\n",
      "tensor([[[ 0.0542,  0.0128,  0.1228],\n",
      "         [ 0.0978,  0.0454,  0.0967],\n",
      "         [ 0.0166,  0.2978,  0.1928]],\n",
      "\n",
      "        [[ 0.0460, -0.0095,  0.1345],\n",
      "         [ 0.0696,  0.0065,  0.1078],\n",
      "         [ 0.0288,  0.1160,  0.0506]],\n",
      "\n",
      "        [[ 0.0525,  0.0125,  0.1424],\n",
      "         [ 0.0694,  0.0258,  0.1310],\n",
      "         [ 0.0051, -0.0338,  0.3716]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.hook_resid_mid\n",
      "tensor([[[-3.6404, -2.9979, -4.3576],\n",
      "         [-0.4691,  1.2476, -1.1898],\n",
      "         [ 0.0298,  2.4865, -2.2950]],\n",
      "\n",
      "        [[-4.3117, -4.7243, -4.5793],\n",
      "         [ 0.9677,  0.2729, -3.7336],\n",
      "         [-1.7562,  1.2149, -2.5393]],\n",
      "\n",
      "        [[-3.5854, -4.0860, -4.0715],\n",
      "         [ 0.1354,  0.9702,  0.0067],\n",
      "         [ 2.1039,  2.1506,  2.7449]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.ln2.hook_scale\n",
      "tensor([[[92.4972],\n",
      "         [ 2.4735],\n",
      "         [ 2.3100]],\n",
      "\n",
      "        [[91.7565],\n",
      "         [ 2.5407],\n",
      "         [ 2.5874]],\n",
      "\n",
      "        [[92.6049],\n",
      "         [ 2.3247],\n",
      "         [ 2.7253]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.ln2.hook_normalized\n",
      "tensor([[[-0.0394, -0.0324, -0.0471],\n",
      "         [-0.1896,  0.5044, -0.4810],\n",
      "         [ 0.0129,  1.0764, -0.9935]],\n",
      "\n",
      "        [[-0.0470, -0.0515, -0.0499],\n",
      "         [ 0.3809,  0.1074, -1.4695],\n",
      "         [-0.6788,  0.4695, -0.9814]],\n",
      "\n",
      "        [[-0.0387, -0.0441, -0.0440],\n",
      "         [ 0.0582,  0.4173,  0.0029],\n",
      "         [ 0.7720,  0.7891,  1.0072]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.mlp.hook_pre\n",
      "tensor([[[-2.4978,  0.0530, -2.1326],\n",
      "         [-1.1270, -0.6086, -2.8723],\n",
      "         [-1.1061, -1.3334, -2.1487]],\n",
      "\n",
      "        [[-2.4710,  0.0353, -2.0958],\n",
      "         [-2.3201, -0.7785, -2.6415],\n",
      "         [-0.3298,  0.0523, -1.1018]],\n",
      "\n",
      "        [[-2.4993,  0.0627, -2.1442],\n",
      "         [-1.3465, -0.1004, -2.2797],\n",
      "         [-1.7125, -0.8494, -1.4520]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.mlp.hook_post\n",
      "tensor([[[-0.0152,  0.0276, -0.0349],\n",
      "         [-0.1466, -0.1652, -0.0054],\n",
      "         [-0.1488, -0.1218, -0.0338]],\n",
      "\n",
      "        [[-0.0162,  0.0182, -0.0377],\n",
      "         [-0.0232, -0.1699, -0.0104],\n",
      "         [-0.1223,  0.0273, -0.1492]],\n",
      "\n",
      "        [[-0.0151,  0.0329, -0.0341],\n",
      "         [-0.1202, -0.0462, -0.0255],\n",
      "         [-0.0745, -0.1681, -0.1066]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.hook_mlp_out\n",
      "tensor([[[-0.3313, -0.3438, -0.3432],\n",
      "         [ 0.0044,  0.2379,  0.7934],\n",
      "         [ 0.8413,  0.3722,  0.2236]],\n",
      "\n",
      "        [[-0.3012, -0.2802, -0.3327],\n",
      "         [ 0.2470,  0.9737,  0.4200],\n",
      "         [-0.1631,  0.8414, -0.4329]],\n",
      "\n",
      "        [[-0.3380, -0.3332, -0.3670],\n",
      "         [-0.3326,  0.2663,  0.9223],\n",
      "         [-0.1550,  0.6478,  0.6338]]], grad_fn=<SliceBackward0>)\n",
      "blocks.3.hook_resid_post\n",
      "tensor([[[-3.9717, -3.3417, -4.7008],\n",
      "         [-0.4647,  1.4855, -0.3964],\n",
      "         [ 0.8711,  2.8587, -2.0714]],\n",
      "\n",
      "        [[-4.6129, -5.0045, -4.9120],\n",
      "         [ 1.2146,  1.2467, -3.3136],\n",
      "         [-1.9193,  2.0563, -2.9721]],\n",
      "\n",
      "        [[-3.9234, -4.4191, -4.4385],\n",
      "         [-0.1972,  1.2364,  0.9290],\n",
      "         [ 1.9489,  2.7984,  3.3786]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.hook_resid_pre\n",
      "tensor([[[-3.9717, -3.3417, -4.7008],\n",
      "         [-0.4647,  1.4855, -0.3964],\n",
      "         [ 0.8711,  2.8587, -2.0714]],\n",
      "\n",
      "        [[-4.6129, -5.0045, -4.9120],\n",
      "         [ 1.2146,  1.2467, -3.3136],\n",
      "         [-1.9193,  2.0563, -2.9721]],\n",
      "\n",
      "        [[-3.9234, -4.4191, -4.4385],\n",
      "         [-0.1972,  1.2364,  0.9290],\n",
      "         [ 1.9489,  2.7984,  3.3786]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.ln1.hook_scale\n",
      "tensor([[[99.2753],\n",
      "         [ 2.5850],\n",
      "         [ 2.4798]],\n",
      "\n",
      "        [[97.7011],\n",
      "         [ 2.6102],\n",
      "         [ 2.6791]],\n",
      "\n",
      "        [[99.3028],\n",
      "         [ 2.4464],\n",
      "         [ 2.8423]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.ln1.hook_normalized\n",
      "tensor([[[-0.0400, -0.0337, -0.0474],\n",
      "         [-0.1798,  0.5746, -0.1533],\n",
      "         [ 0.3513,  1.1528, -0.8353]],\n",
      "\n",
      "        [[-0.0472, -0.0512, -0.0503],\n",
      "         [ 0.4653,  0.4776, -1.2695],\n",
      "         [-0.7164,  0.7675, -1.1094]],\n",
      "\n",
      "        [[-0.0395, -0.0445, -0.0447],\n",
      "         [-0.0806,  0.5054,  0.3797],\n",
      "         [ 0.6857,  0.9846,  1.1887]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.ln1.hook_scale\n",
      "tensor([[[99.2753],\n",
      "         [ 2.5850],\n",
      "         [ 2.4798]],\n",
      "\n",
      "        [[97.7011],\n",
      "         [ 2.6102],\n",
      "         [ 2.6791]],\n",
      "\n",
      "        [[99.3028],\n",
      "         [ 2.4464],\n",
      "         [ 2.8423]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.ln1.hook_normalized\n",
      "tensor([[[-0.0400, -0.0337, -0.0474],\n",
      "         [-0.1798,  0.5746, -0.1533],\n",
      "         [ 0.3513,  1.1528, -0.8353]],\n",
      "\n",
      "        [[-0.0472, -0.0512, -0.0503],\n",
      "         [ 0.4653,  0.4776, -1.2695],\n",
      "         [-0.7164,  0.7675, -1.1094]],\n",
      "\n",
      "        [[-0.0395, -0.0445, -0.0447],\n",
      "         [-0.0806,  0.5054,  0.3797],\n",
      "         [ 0.6857,  0.9846,  1.1887]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.ln1.hook_scale\n",
      "tensor([[[99.2753],\n",
      "         [ 2.5850],\n",
      "         [ 2.4798]],\n",
      "\n",
      "        [[97.7011],\n",
      "         [ 2.6102],\n",
      "         [ 2.6791]],\n",
      "\n",
      "        [[99.3028],\n",
      "         [ 2.4464],\n",
      "         [ 2.8423]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.ln1.hook_normalized\n",
      "tensor([[[-0.0400, -0.0337, -0.0474],\n",
      "         [-0.1798,  0.5746, -0.1533],\n",
      "         [ 0.3513,  1.1528, -0.8353]],\n",
      "\n",
      "        [[-0.0472, -0.0512, -0.0503],\n",
      "         [ 0.4653,  0.4776, -1.2695],\n",
      "         [-0.7164,  0.7675, -1.1094]],\n",
      "\n",
      "        [[-0.0395, -0.0445, -0.0447],\n",
      "         [-0.0806,  0.5054,  0.3797],\n",
      "         [ 0.6857,  0.9846,  1.1887]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.attn.hook_q\n",
      "tensor([[[[-2.5248e-03,  3.6504e-01,  2.3516e-01],\n",
      "          [-3.1044e-01, -2.1205e-01,  2.8533e-01],\n",
      "          [-1.2754e-01, -1.9009e-01,  9.6131e-02]],\n",
      "\n",
      "         [[ 6.7711e-01, -8.3941e-01,  1.7617e+00],\n",
      "          [-1.7241e-01,  2.9235e-01, -1.7562e+00],\n",
      "          [-1.6269e+00, -6.8821e-01, -1.0219e+00]],\n",
      "\n",
      "         [[-5.3100e-01, -2.1632e+00,  1.6463e+00],\n",
      "          [ 2.5271e-01, -2.3023e-01, -3.1931e+00],\n",
      "          [-1.6862e+00, -5.6284e-01, -6.7971e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1221e-03,  3.9388e-01,  2.2178e-01],\n",
      "          [-3.0284e-01, -2.1945e-01,  3.0952e-01],\n",
      "          [-1.3406e-01, -2.0324e-01,  1.0094e-01]],\n",
      "\n",
      "         [[ 1.0554e+00, -3.3190e-01, -5.8788e-01],\n",
      "          [ 3.2337e-01, -1.4111e-01, -1.1066e+00],\n",
      "          [-3.7349e-01, -1.2818e-01, -6.0583e-02]],\n",
      "\n",
      "         [[ 1.3751e+00, -4.1354e-01,  1.7130e+00],\n",
      "          [ 1.7834e+00, -6.3003e-01, -1.1766e+00],\n",
      "          [-2.4088e-01, -1.9768e-01,  6.3938e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5222e-03,  3.6823e-01,  2.1442e-01],\n",
      "          [-3.0085e-01, -2.2089e-01,  3.0334e-01],\n",
      "          [-1.2007e-01, -1.9604e-01,  8.1105e-02]],\n",
      "\n",
      "         [[ 1.4451e-01,  3.3510e-01,  8.0095e-01],\n",
      "          [ 6.0810e-02,  5.4524e-01, -2.2613e+00],\n",
      "          [-9.1327e-01, -1.5620e-01, -7.9674e-01]],\n",
      "\n",
      "         [[ 2.1361e+00, -1.9317e+00,  9.0931e-01],\n",
      "          [ 9.7771e-01, -4.6695e-01, -2.5918e+00],\n",
      "          [-9.8873e-01, -4.6115e-01, -9.1283e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.attn.hook_k\n",
      "tensor([[[[-0.8801, -0.1707,  0.3430],\n",
      "          [ 0.3581, -0.0609,  0.4604],\n",
      "          [ 0.1450, -0.6242, -0.2228]],\n",
      "\n",
      "         [[ 2.3069, -0.9444, -3.6939],\n",
      "          [-2.5042,  0.4127,  3.4743],\n",
      "          [ 0.9572,  1.2415,  0.6601]],\n",
      "\n",
      "         [[ 2.3068, -2.7283, -1.2580],\n",
      "          [-2.7130,  1.1815,  2.6807],\n",
      "          [ 0.1115,  2.2600,  0.3585]]],\n",
      "\n",
      "\n",
      "        [[[-0.8919, -0.1523,  0.3162],\n",
      "          [ 0.3517, -0.0284,  0.4612],\n",
      "          [ 0.1513, -0.6300, -0.2357]],\n",
      "\n",
      "         [[ 1.0287,  0.3357, -2.5829],\n",
      "          [-1.0692,  0.4523,  2.1839],\n",
      "          [ 1.4143,  2.6161,  0.0263]],\n",
      "\n",
      "         [[ 1.6270, -1.7569, -4.5325],\n",
      "          [-2.9530, -0.7030,  2.1204],\n",
      "          [-0.7420,  2.7392,  0.3075]]],\n",
      "\n",
      "\n",
      "        [[[-0.8767, -0.1522,  0.3294],\n",
      "          [ 0.3524, -0.0534,  0.4614],\n",
      "          [ 0.1416, -0.6373, -0.2328]],\n",
      "\n",
      "         [[ 2.3066, -1.1931, -4.1189],\n",
      "          [-3.1451,  0.1633,  3.1751],\n",
      "          [ 1.3007,  2.0641,  0.3825]],\n",
      "\n",
      "         [[ 0.1890, -2.3789, -3.9885],\n",
      "          [-1.7451,  0.6938,  2.5528],\n",
      "          [ 1.1597,  2.3222,  1.1702]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.attn.hook_v\n",
      "tensor([[[[-0.1101, -0.1029, -0.0244],\n",
      "          [-0.0462,  0.0090, -0.0780],\n",
      "          [ 0.0237,  0.0912,  0.0503]],\n",
      "\n",
      "         [[ 0.4244, -1.6482,  0.5200],\n",
      "          [ 0.2121,  0.8074,  0.0806],\n",
      "          [-0.3589,  0.3390, -0.8569]],\n",
      "\n",
      "         [[-0.3057, -0.3783,  0.0902],\n",
      "          [ 0.3154,  0.2027,  0.8622],\n",
      "          [ 0.6280,  0.5537,  0.2537]]],\n",
      "\n",
      "\n",
      "        [[[-0.1166, -0.1061, -0.0285],\n",
      "          [-0.0487,  0.0166, -0.0712],\n",
      "          [ 0.0208,  0.0908,  0.0526]],\n",
      "\n",
      "         [[-1.0473, -0.5063,  0.2078],\n",
      "          [ 0.2258,  0.6100, -0.0866],\n",
      "          [-0.0057,  0.0218, -0.0925]],\n",
      "\n",
      "         [[-0.0763, -0.5168, -0.0842],\n",
      "          [ 0.0867, -0.2043,  0.3129],\n",
      "          [-0.5440,  1.4741,  0.4388]]],\n",
      "\n",
      "\n",
      "        [[[-0.1211, -0.1082, -0.0184],\n",
      "          [-0.0428,  0.0111, -0.0717],\n",
      "          [ 0.0242,  0.0938,  0.0462]],\n",
      "\n",
      "         [[ 0.1507, -0.9227,  0.3275],\n",
      "          [-0.2708,  0.3724, -0.3525],\n",
      "          [-1.0736,  0.3508, -0.8682]],\n",
      "\n",
      "         [[ 0.5321,  0.3435, -0.3584],\n",
      "          [-0.5034,  0.6175,  0.3434],\n",
      "          [-1.3438,  0.5842,  0.0207]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.attn.hook_attn_scores\n",
      "tensor([[[[ 5.3106e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.2671e+00, -5.8907e+00, -1.0000e+05],\n",
      "          [-1.9501e+00, -6.5254e+00, -5.6131e+00]],\n",
      "\n",
      "         [[ 3.4099e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.2733e+00, -6.0938e+00, -1.0000e+05],\n",
      "          [-2.4270e+00, -4.5722e+00, -4.4537e+00]],\n",
      "\n",
      "         [[ 2.0640e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.2446e-01, -3.5557e+00, -1.0000e+05],\n",
      "          [-1.0202e-01, -3.9209e+00, -3.3538e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2595e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.4269e+00, -6.9556e+00, -1.0000e+05],\n",
      "          [-2.9331e+00, -6.8296e+00, -7.1886e+00]],\n",
      "\n",
      "         [[ 3.4981e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-1.8728e+00, -5.7667e+00, -1.0000e+05],\n",
      "          [-2.4569e+00, -4.1413e+00, -4.7376e+00]],\n",
      "\n",
      "         [[ 2.0327e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-1.6746e-01, -4.0396e+00, -1.0000e+05],\n",
      "          [-3.9325e-01, -3.9591e+00, -2.7493e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1646e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.5371e+00, -7.1485e+00, -1.0000e+05],\n",
      "          [-2.5342e+00, -4.5370e+00, -4.9916e+00]],\n",
      "\n",
      "         [[ 3.4186e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-1.8506e+00, -6.0117e+00, -1.0000e+05],\n",
      "          [-2.1427e+00, -3.9916e+00, -4.2588e+00]],\n",
      "\n",
      "         [[ 2.0320e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.8841e-01, -5.8784e+00, -1.0000e+05],\n",
      "          [-2.2095e-01, -2.7870e+00, -4.3380e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.attn.hook_pattern\n",
      "tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9740, 0.0260, 0.0000],\n",
      "          [0.9653, 0.0099, 0.0248]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9786, 0.0214, 0.0000],\n",
      "          [0.8008, 0.0937, 0.1055]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9754, 0.0246, 0.0000],\n",
      "          [0.9428, 0.0207, 0.0365]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9893, 0.0107, 0.0000],\n",
      "          [0.9667, 0.0196, 0.0137]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9800, 0.0200, 0.0000],\n",
      "          [0.7765, 0.1441, 0.0794]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9796, 0.0204, 0.0000],\n",
      "          [0.8904, 0.0252, 0.0844]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9902, 0.0098, 0.0000],\n",
      "          [0.8193, 0.1106, 0.0702]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9846, 0.0154, 0.0000],\n",
      "          [0.7825, 0.1232, 0.0943]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9977, 0.0023, 0.0000],\n",
      "          [0.9148, 0.0703, 0.0149]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.attn.hook_z\n",
      "tensor([[[[-0.1101, -0.1029, -0.0244],\n",
      "          [-0.0462,  0.0090, -0.0780],\n",
      "          [ 0.0237,  0.0912,  0.0503]],\n",
      "\n",
      "         [[-0.0962, -0.1431, -0.0103],\n",
      "          [-0.0406,  0.0261, -0.0746],\n",
      "          [ 0.0142,  0.0973,  0.0280]],\n",
      "\n",
      "         [[-0.1097, -0.1251, -0.0162],\n",
      "          [ 0.0162,  0.1043,  0.0361],\n",
      "          [ 0.0378,  0.1132,  0.0390]]],\n",
      "\n",
      "\n",
      "        [[[-0.1166, -0.1061, -0.0285],\n",
      "          [-0.0487,  0.0166, -0.0712],\n",
      "          [ 0.0208,  0.0908,  0.0526]],\n",
      "\n",
      "         [[-0.1265, -0.1104, -0.0260],\n",
      "          [-0.0432,  0.0284, -0.0715],\n",
      "          [ 0.0203,  0.0894,  0.0497]],\n",
      "\n",
      "         [[-0.1343, -0.1196, -0.0246],\n",
      "          [ 0.0016,  0.0845, -0.0430],\n",
      "          [-0.0275,  0.2058,  0.0816]]],\n",
      "\n",
      "\n",
      "        [[[-0.1211, -0.1082, -0.0184],\n",
      "          [-0.0428,  0.0111, -0.0717],\n",
      "          [ 0.0242,  0.0938,  0.0462]],\n",
      "\n",
      "         [[-0.1185, -0.1162, -0.0150],\n",
      "          [-0.0463,  0.0167, -0.0760],\n",
      "          [ 0.0217,  0.0944,  0.0441]],\n",
      "\n",
      "         [[-0.0452, -0.1665, -0.0040],\n",
      "          [-0.1143,  0.1128, -0.0671],\n",
      "          [-0.0734,  0.1192, -0.0185]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.hook_attn_out\n",
      "tensor([[[-0.1472, -0.1407,  0.0231],\n",
      "         [-0.1079, -0.0535, -0.0331],\n",
      "         [ 0.1281,  0.4439, -0.0173]],\n",
      "\n",
      "        [[-0.1155, -0.1515,  0.0232],\n",
      "         [-0.0619, -0.1596, -0.0398],\n",
      "         [ 0.1711, -0.0262, -0.5327]],\n",
      "\n",
      "        [[-0.1341, -0.1399,  0.0336],\n",
      "         [-0.0720, -0.1325,  0.0018],\n",
      "         [ 0.2511, -0.3311,  0.3251]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.hook_resid_mid\n",
      "tensor([[[-4.1189, -3.4824, -4.6777],\n",
      "         [-0.5726,  1.4320, -0.4295],\n",
      "         [ 0.9992,  3.3026, -2.0887]],\n",
      "\n",
      "        [[-4.7283, -5.1560, -4.8888],\n",
      "         [ 1.1527,  1.0871, -3.3533],\n",
      "         [-1.7483,  2.0300, -3.5048]],\n",
      "\n",
      "        [[-4.0574, -4.5590, -4.4049],\n",
      "         [-0.2692,  1.1039,  0.9308],\n",
      "         [ 2.2000,  2.4673,  3.7037]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.ln2.hook_scale\n",
      "tensor([[[99.2403],\n",
      "         [ 2.5786],\n",
      "         [ 2.5518]],\n",
      "\n",
      "        [[97.6659],\n",
      "         [ 2.6078],\n",
      "         [ 2.7527]],\n",
      "\n",
      "        [[99.2697],\n",
      "         [ 2.4350],\n",
      "         [ 2.8956]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.ln2.hook_normalized\n",
      "tensor([[[-0.0415, -0.0351, -0.0471],\n",
      "         [-0.2221,  0.5553, -0.1666],\n",
      "         [ 0.3916,  1.2942, -0.8185]],\n",
      "\n",
      "        [[-0.0484, -0.0528, -0.0501],\n",
      "         [ 0.4420,  0.4169, -1.2859],\n",
      "         [-0.6351,  0.7375, -1.2732]],\n",
      "\n",
      "        [[-0.0409, -0.0459, -0.0444],\n",
      "         [-0.1105,  0.4534,  0.3823],\n",
      "         [ 0.7598,  0.8521,  1.2791]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.mlp.hook_pre\n",
      "tensor([[[ 0.8370, -2.8128, -0.2623],\n",
      "         [-0.6230, -0.5656,  0.5228],\n",
      "         [-0.7720, -1.6029, -0.9116]],\n",
      "\n",
      "        [[ 0.8224, -2.7669, -0.2597],\n",
      "         [ 0.0837, -1.6189,  0.5261],\n",
      "         [ 0.1860, -1.9059, -0.5027]],\n",
      "\n",
      "        [[ 0.8428, -2.8075, -0.2640],\n",
      "         [-0.7720, -1.6616,  0.4336],\n",
      "         [-0.1273, -2.3711, -0.9414]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.mlp.hook_post\n",
      "tensor([[[ 0.6685, -0.0064, -0.1040],\n",
      "         [-0.1662, -0.1617,  0.3656],\n",
      "         [-0.1700, -0.0875, -0.1651]],\n",
      "\n",
      "        [[ 0.6534, -0.0074, -0.1032],\n",
      "         [ 0.0446, -0.0855,  0.3685],\n",
      "         [ 0.1067, -0.0540, -0.1546]],\n",
      "\n",
      "        [[ 0.6744, -0.0065, -0.1045],\n",
      "         [-0.1700, -0.0804,  0.2895],\n",
      "         [-0.0572, -0.0206, -0.1632]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.hook_mlp_out\n",
      "tensor([[[-0.2840, -0.1821, -0.3083],\n",
      "         [-0.9338,  0.3810,  0.3614],\n",
      "         [-0.2853, -0.1146, -0.4982]],\n",
      "\n",
      "        [[-0.2485, -0.1448, -0.3084],\n",
      "         [ 0.4115,  0.7967, -0.5791],\n",
      "         [-0.0058,  0.1048, -0.5361]],\n",
      "\n",
      "        [[-0.2516, -0.1474, -0.3120],\n",
      "         [-0.0543,  0.0389,  0.3459],\n",
      "         [ 0.0484,  0.4001, -0.3146]]], grad_fn=<SliceBackward0>)\n",
      "blocks.4.hook_resid_post\n",
      "tensor([[[-4.4029, -3.6645, -4.9861],\n",
      "         [-1.5064,  1.8129, -0.0681],\n",
      "         [ 0.7139,  3.1880, -2.5869]],\n",
      "\n",
      "        [[-4.9768, -5.3009, -5.1971],\n",
      "         [ 1.5642,  1.8839, -3.9324],\n",
      "         [-1.7540,  2.1349, -4.0410]],\n",
      "\n",
      "        [[-4.3090, -4.7065, -4.7169],\n",
      "         [-0.3235,  1.1429,  1.2768],\n",
      "         [ 2.2484,  2.8675,  3.3891]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.hook_resid_pre\n",
      "tensor([[[-4.4029, -3.6645, -4.9861],\n",
      "         [-1.5064,  1.8129, -0.0681],\n",
      "         [ 0.7139,  3.1880, -2.5869]],\n",
      "\n",
      "        [[-4.9768, -5.3009, -5.1971],\n",
      "         [ 1.5642,  1.8839, -3.9324],\n",
      "         [-1.7540,  2.1349, -4.0410]],\n",
      "\n",
      "        [[-4.3090, -4.7065, -4.7169],\n",
      "         [-0.3235,  1.1429,  1.2768],\n",
      "         [ 2.2484,  2.8675,  3.3891]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.ln1.hook_scale\n",
      "tensor([[[104.6590],\n",
      "         [  2.8692],\n",
      "         [  2.7764]],\n",
      "\n",
      "        [[102.8061],\n",
      "         [  2.8468],\n",
      "         [  3.0445]],\n",
      "\n",
      "        [[104.6513],\n",
      "         [  2.7746],\n",
      "         [  3.1021]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.ln1.hook_normalized\n",
      "tensor([[[-0.0421, -0.0350, -0.0476],\n",
      "         [-0.5250,  0.6319, -0.0237],\n",
      "         [ 0.2571,  1.1482, -0.9317]],\n",
      "\n",
      "        [[-0.0484, -0.0516, -0.0506],\n",
      "         [ 0.5495,  0.6618, -1.3814],\n",
      "         [-0.5761,  0.7012, -1.3273]],\n",
      "\n",
      "        [[-0.0412, -0.0450, -0.0451],\n",
      "         [-0.1166,  0.4119,  0.4602],\n",
      "         [ 0.7248,  0.9244,  1.0925]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.ln1.hook_scale\n",
      "tensor([[[104.6590],\n",
      "         [  2.8692],\n",
      "         [  2.7764]],\n",
      "\n",
      "        [[102.8061],\n",
      "         [  2.8468],\n",
      "         [  3.0445]],\n",
      "\n",
      "        [[104.6513],\n",
      "         [  2.7746],\n",
      "         [  3.1021]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.ln1.hook_normalized\n",
      "tensor([[[-0.0421, -0.0350, -0.0476],\n",
      "         [-0.5250,  0.6319, -0.0237],\n",
      "         [ 0.2571,  1.1482, -0.9317]],\n",
      "\n",
      "        [[-0.0484, -0.0516, -0.0506],\n",
      "         [ 0.5495,  0.6618, -1.3814],\n",
      "         [-0.5761,  0.7012, -1.3273]],\n",
      "\n",
      "        [[-0.0412, -0.0450, -0.0451],\n",
      "         [-0.1166,  0.4119,  0.4602],\n",
      "         [ 0.7248,  0.9244,  1.0925]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.ln1.hook_scale\n",
      "tensor([[[104.6590],\n",
      "         [  2.8692],\n",
      "         [  2.7764]],\n",
      "\n",
      "        [[102.8061],\n",
      "         [  2.8468],\n",
      "         [  3.0445]],\n",
      "\n",
      "        [[104.6513],\n",
      "         [  2.7746],\n",
      "         [  3.1021]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.ln1.hook_normalized\n",
      "tensor([[[-0.0421, -0.0350, -0.0476],\n",
      "         [-0.5250,  0.6319, -0.0237],\n",
      "         [ 0.2571,  1.1482, -0.9317]],\n",
      "\n",
      "        [[-0.0484, -0.0516, -0.0506],\n",
      "         [ 0.5495,  0.6618, -1.3814],\n",
      "         [-0.5761,  0.7012, -1.3273]],\n",
      "\n",
      "        [[-0.0412, -0.0450, -0.0451],\n",
      "         [-0.1166,  0.4119,  0.4602],\n",
      "         [ 0.7248,  0.9244,  1.0925]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.attn.hook_q\n",
      "tensor([[[[-2.2460e-02,  1.9646e-01,  5.2700e-02],\n",
      "          [-3.1703e-01,  1.5989e-01, -3.1252e-01],\n",
      "          [-2.4960e-02, -1.6421e-02, -7.4078e-02]],\n",
      "\n",
      "         [[-1.0210e+00, -2.9456e+00, -5.1963e-01],\n",
      "          [-6.8717e-01,  1.6691e+00, -4.0801e+00],\n",
      "          [ 8.0312e-01,  1.7041e-01, -5.6736e-01]],\n",
      "\n",
      "         [[-4.0714e-01,  5.6853e-01, -1.9218e-01],\n",
      "          [-1.8032e-01,  4.0687e+00, -5.1644e+00],\n",
      "          [ 5.3386e-01, -4.9188e-01,  1.3165e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2843e-02,  1.7178e-01,  7.0296e-02],\n",
      "          [-3.1359e-01,  1.3898e-01, -2.9413e-01],\n",
      "          [-1.4184e-02, -2.4228e-03, -7.9799e-02]],\n",
      "\n",
      "         [[-1.3925e+00, -1.0933e+00,  2.3791e+00],\n",
      "          [-2.9710e-01,  1.6293e+00, -8.8904e-01],\n",
      "          [ 5.1609e-01, -5.0894e-01,  9.7505e-01]],\n",
      "\n",
      "         [[-1.2279e+00,  4.3344e-01,  5.6944e-01],\n",
      "          [ 1.6512e+00,  2.9132e+00,  1.9663e-01],\n",
      "          [ 4.4656e-01, -1.4762e+00,  1.4710e+00]]],\n",
      "\n",
      "\n",
      "        [[[-3.7508e-02,  1.8122e-01,  4.9438e-02],\n",
      "          [-3.4087e-01,  1.4294e-01, -2.6636e-01],\n",
      "          [-1.8894e-02, -1.9770e-02, -7.0371e-02]],\n",
      "\n",
      "         [[-2.1315e+00,  3.2926e-01, -1.2815e+00],\n",
      "          [-9.7902e-01,  3.3096e+00, -1.1812e+00],\n",
      "          [-1.0640e-01,  7.4007e-01,  5.7852e-03]],\n",
      "\n",
      "         [[ 3.6319e+00, -1.4608e+00, -7.6711e-01],\n",
      "          [ 1.0726e+00,  2.4301e+00, -3.1183e+00],\n",
      "          [-3.3823e-01, -5.7562e-01,  1.2466e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.attn.hook_k\n",
      "tensor([[[[ 2.3638e-02, -3.1570e-01,  2.1186e-01],\n",
      "          [ 1.5803e-01,  9.7361e-01, -1.4365e+00],\n",
      "          [-6.8024e-01,  2.6599e-01, -4.1322e-02]],\n",
      "\n",
      "         [[-1.9922e-02,  2.4862e-01,  3.2804e-01],\n",
      "          [-6.4109e-01, -4.2376e+00, -1.1276e+00],\n",
      "          [ 1.3842e+00, -8.4503e-02,  8.2278e-01]],\n",
      "\n",
      "         [[-1.1250e-01, -1.4490e+00, -3.5732e-01],\n",
      "          [-2.1648e+00, -5.5735e+00,  6.9418e-01],\n",
      "          [ 1.7908e+00,  8.8704e-01,  2.9129e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6183e-03, -3.1209e-01,  2.2972e-01],\n",
      "          [ 1.6507e-01,  9.8285e-01, -1.4218e+00],\n",
      "          [-6.8085e-01,  2.4471e-01, -4.6823e-02]],\n",
      "\n",
      "         [[ 1.3010e+00, -1.0590e+00,  5.6007e-01],\n",
      "          [-1.3977e+00, -4.0471e+00, -6.8864e-01],\n",
      "          [ 5.9192e-01, -2.1767e-01,  4.7285e-01]],\n",
      "\n",
      "         [[ 7.5858e-02, -1.6797e+00,  1.2375e+00],\n",
      "          [-1.4603e+00, -6.0360e+00,  2.6905e+00],\n",
      "          [ 1.5327e+00,  7.2411e-01,  6.0175e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2776e-02, -3.0322e-01,  2.3702e-01],\n",
      "          [ 1.5986e-01,  9.6493e-01, -1.4064e+00],\n",
      "          [-6.7329e-01,  2.5930e-01, -5.2305e-02]],\n",
      "\n",
      "         [[-1.1760e+00, -1.1009e+00,  2.2828e-01],\n",
      "          [-2.0422e+00, -4.6558e+00,  2.5597e+00],\n",
      "          [ 1.4402e+00, -7.5051e-01,  1.9512e-01]],\n",
      "\n",
      "         [[-6.4055e-01, -4.5337e-01, -4.5317e-01],\n",
      "          [-1.3360e+00, -4.0988e+00,  2.1563e+00],\n",
      "          [ 3.1722e+00, -1.4039e-01, -2.6651e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.attn.hook_v\n",
      "tensor([[[[ 4.0534e-02, -7.4112e-02,  6.0166e-02],\n",
      "          [ 9.1096e-03,  1.1839e-01, -1.0356e-02],\n",
      "          [ 1.7340e-03,  3.3667e-03,  1.1730e-01]],\n",
      "\n",
      "         [[-2.0306e-01,  1.6154e-01,  4.9223e-01],\n",
      "          [ 7.0905e-01, -8.6013e-01,  5.6629e-03],\n",
      "          [-6.7925e-02, -1.9442e-01, -1.4356e-01]],\n",
      "\n",
      "         [[ 9.7674e-04, -7.9652e-01, -7.6748e-01],\n",
      "          [-6.4258e-02, -9.0239e-01,  8.2622e-01],\n",
      "          [-7.9206e-01,  1.2151e-01,  1.1520e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8022e-02, -7.4579e-02,  5.9672e-02],\n",
      "          [ 2.7730e-03,  1.2142e-01, -5.2342e-03],\n",
      "          [-9.0361e-03,  1.1910e-02,  1.1372e-01]],\n",
      "\n",
      "         [[ 6.5187e-01,  3.9872e-01,  4.5078e-01],\n",
      "          [ 2.6603e-01, -2.2630e-01,  6.6215e-01],\n",
      "          [-4.5313e-01,  3.0550e-01,  6.3063e-01]],\n",
      "\n",
      "         [[ 2.8820e-01, -8.6151e-01,  7.7047e-01],\n",
      "          [ 8.1811e-01,  2.2860e-01, -4.2910e-03],\n",
      "          [ 3.8454e-01, -1.1374e-01,  7.0635e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4516e-02, -7.8552e-02,  5.5914e-02],\n",
      "          [ 1.7662e-02,  1.2341e-01, -1.5161e-03],\n",
      "          [ 4.5200e-03, -7.3010e-04,  1.1649e-01]],\n",
      "\n",
      "         [[ 6.8011e-01, -9.2544e-01,  1.7984e-01],\n",
      "          [ 3.1178e-01,  3.1534e-01,  1.3553e+00],\n",
      "          [ 1.7350e-01, -2.9536e-02, -5.4341e-02]],\n",
      "\n",
      "         [[ 8.1028e-02,  1.7360e-01, -4.5498e-01],\n",
      "          [ 1.0065e+00,  4.2819e-01,  2.1744e-01],\n",
      "          [ 3.4800e-01,  5.7423e-02,  1.0771e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.attn.hook_attn_scores\n",
      "tensor([[[[ 5.4196e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.4603e+00, -6.3165e-01, -1.0000e+05],\n",
      "          [ 2.4120e+00, -1.3200e+00, -2.0941e+00]],\n",
      "\n",
      "         [[ 2.9480e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.6442e+00, -3.1500e+00, -1.0000e+05],\n",
      "          [ 4.3841e+00, -6.5145e+00, -3.2428e+00]],\n",
      "\n",
      "         [[ 1.8308e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.7186e-01, -5.9874e-01, -1.0000e+05],\n",
      "          [ 1.5966e-01,  1.6794e-01, -1.5910e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2736e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.1685e+00, -1.1243e+00, -1.0000e+05],\n",
      "          [ 1.9675e+00, -3.8789e+00, -8.4191e-01]],\n",
      "\n",
      "         [[ 3.0272e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.2485e+00, -7.0927e+00, -1.0000e+05],\n",
      "          [ 4.8020e+00, -1.0542e+01, -3.7881e+00]],\n",
      "\n",
      "         [[ 1.9290e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.0929e-01, -9.9682e-01, -1.0000e+05],\n",
      "          [-9.2189e-02,  1.0488e+00, -1.8888e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3445e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.8475e+00, -1.7864e+00, -1.0000e+05],\n",
      "          [ 2.2809e+00, -3.8745e+00, -3.5058e+00]],\n",
      "\n",
      "         [[ 2.9988e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.9184e+00, -5.4130e+00, -1.0000e+05],\n",
      "          [ 4.3042e+00, -7.7742e+00, -6.9674e+00]],\n",
      "\n",
      "         [[ 1.8385e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.0030e-01, -2.2963e+00, -1.0000e+05],\n",
      "          [ 2.3412e-01, -9.9588e-01, -2.5023e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.attn.hook_pattern\n",
      "tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.5656e-01, 4.3441e-02, 0.0000e+00],\n",
      "          [9.6620e-01, 2.3134e-02, 1.0668e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.9888e-01, 1.1190e-03, 0.0000e+00],\n",
      "          [9.9949e-01, 1.8474e-05, 4.8693e-04]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [7.4471e-01, 2.5529e-01, 0.0000e+00],\n",
      "          [4.5830e-01, 4.6211e-01, 7.9588e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.6418e-01, 3.5818e-02, 0.0000e+00],\n",
      "          [9.4062e-01, 2.7186e-03, 5.6662e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.9999e-01, 1.1874e-05, 0.0000e+00],\n",
      "          [9.9981e-01, 2.1688e-07, 1.8590e-04]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [7.6961e-01, 2.3039e-01, 0.0000e+00],\n",
      "          [2.3279e-01, 7.2859e-01, 3.8612e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.7427e-01, 2.5734e-02, 0.0000e+00],\n",
      "          [9.9484e-01, 2.1110e-03, 3.0523e-03]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.9991e-01, 8.8587e-05, 0.0000e+00],\n",
      "          [9.9998e-01, 5.6805e-06, 1.2729e-05]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.2390e-01, 7.6098e-02, 0.0000e+00],\n",
      "          [7.3687e-01, 2.1538e-01, 4.7750e-02]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.attn.hook_z\n",
      "tensor([[[[ 0.0405, -0.0741,  0.0602],\n",
      "          [ 0.0091,  0.1184, -0.0104],\n",
      "          [ 0.0017,  0.0034,  0.1173]],\n",
      "\n",
      "         [[ 0.0300, -0.0639,  0.0789],\n",
      "          [ 0.0099,  0.1173, -0.0103],\n",
      "          [-0.0160, -0.0471,  0.0507]],\n",
      "\n",
      "         [[ 0.0345, -0.0764,  0.0613],\n",
      "          [ 0.0091,  0.1179, -0.0099],\n",
      "          [-0.0936, -0.0786,  0.0791]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0380, -0.0746,  0.0597],\n",
      "          [ 0.0028,  0.1214, -0.0052],\n",
      "          [-0.0090,  0.0119,  0.1137]],\n",
      "\n",
      "         [[ 0.0600, -0.0576,  0.0737],\n",
      "          [ 0.0028,  0.1214, -0.0052],\n",
      "          [-0.1114,  0.0796,  0.2328]],\n",
      "\n",
      "         [[ 0.0539, -0.1179,  0.1010],\n",
      "          [ 0.0029,  0.1214, -0.0052],\n",
      "          [-0.3174,  0.2210,  0.5132]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0445, -0.0786,  0.0559],\n",
      "          [ 0.0177,  0.1234, -0.0015],\n",
      "          [ 0.0045, -0.0007,  0.1165]],\n",
      "\n",
      "         [[ 0.0609, -0.1003,  0.0591],\n",
      "          [ 0.0177,  0.1234, -0.0014],\n",
      "          [ 0.0174, -0.0029,  0.1035]],\n",
      "\n",
      "         [[ 0.0460, -0.0796,  0.0546],\n",
      "          [ 0.0177,  0.1234, -0.0015],\n",
      "          [ 0.0573, -0.0042,  0.1256]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.hook_attn_out\n",
      "tensor([[[-0.0405, -0.1240,  0.1135],\n",
      "         [-0.0031,  0.0300,  0.0911],\n",
      "         [ 0.2230,  0.3983, -0.0923]],\n",
      "\n",
      "        [[-0.0259, -0.1172,  0.1059],\n",
      "         [ 0.0081, -0.1733, -0.1729],\n",
      "         [ 0.0190, -0.1437, -1.0497]],\n",
      "\n",
      "        [[-0.0191, -0.1297,  0.1221],\n",
      "         [ 0.0942,  0.1112, -0.0065],\n",
      "         [ 0.3408,  0.1847, -0.0523]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.hook_resid_mid\n",
      "tensor([[[-4.4433, -3.7884, -4.8726],\n",
      "         [-1.5095,  1.8429,  0.0229],\n",
      "         [ 0.9369,  3.5863, -2.6792]],\n",
      "\n",
      "        [[-5.0027, -5.4181, -5.0912],\n",
      "         [ 1.5724,  1.7106, -4.1054],\n",
      "         [-1.7351,  1.9911, -5.0906]],\n",
      "\n",
      "        [[-4.3282, -4.8362, -4.5948],\n",
      "         [-0.2293,  1.2540,  1.2702],\n",
      "         [ 2.5892,  3.0522,  3.3368]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.ln2.hook_scale\n",
      "tensor([[[104.6131],\n",
      "         [  2.8826],\n",
      "         [  2.8821]],\n",
      "\n",
      "        [[102.7577],\n",
      "         [  2.8557],\n",
      "         [  3.1218]],\n",
      "\n",
      "        [[104.6071],\n",
      "         [  2.8241],\n",
      "         [  3.1267]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.ln2.hook_normalized\n",
      "tensor([[[-0.0425, -0.0362, -0.0466],\n",
      "         [-0.5237,  0.6393,  0.0080],\n",
      "         [ 0.3251,  1.2444, -0.9296]],\n",
      "\n",
      "        [[-0.0487, -0.0527, -0.0495],\n",
      "         [ 0.5506,  0.5990, -1.4376],\n",
      "         [-0.5558,  0.6378, -1.6307]],\n",
      "\n",
      "        [[-0.0414, -0.0462, -0.0439],\n",
      "         [-0.0812,  0.4441,  0.4498],\n",
      "         [ 0.8281,  0.9762,  1.0672]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.mlp.hook_pre\n",
      "tensor([[[-1.6760,  0.3806, -1.8275],\n",
      "         [-0.7053, -1.1167, -0.0132],\n",
      "         [ 0.7444, -0.1726, -2.1802]],\n",
      "\n",
      "        [[-1.6455,  0.3625, -1.7915],\n",
      "         [-1.1706, -1.1851, -0.9569],\n",
      "         [-0.5277, -1.1847, -2.2558]],\n",
      "\n",
      "        [[-1.6722,  0.3689, -1.8156],\n",
      "         [ 0.3028, -1.5388, -1.5587],\n",
      "         [-0.8140, -0.7935, -4.5324]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.mlp.hook_post\n",
      "tensor([[[-7.8699e-02,  2.4672e-01, -6.1838e-02],\n",
      "         [-1.6955e-01, -1.4766e-01, -6.5225e-03],\n",
      "         [ 5.7435e-01, -7.4490e-02, -3.1627e-02]],\n",
      "\n",
      "        [[-8.2333e-02,  2.3254e-01, -6.5655e-02],\n",
      "         [-1.4171e-01, -1.4004e-01, -1.6215e-01],\n",
      "         [-1.5773e-01, -1.4009e-01, -2.6855e-02]],\n",
      "\n",
      "        [[-7.9144e-02,  2.3754e-01, -6.3080e-02],\n",
      "         [ 1.8740e-01, -9.5499e-02, -9.2993e-02],\n",
      "         [-1.6926e-01, -1.6969e-01, -4.3224e-06]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.hook_mlp_out\n",
      "tensor([[[-0.1236, -0.1094, -0.1801],\n",
      "         [ 0.1400,  0.4421, -0.2278],\n",
      "         [ 0.3583,  0.1781, -0.1137]],\n",
      "\n",
      "        [[-0.0937, -0.1175, -0.1731],\n",
      "         [ 0.0677, -0.4238,  0.0995],\n",
      "         [ 0.5245,  1.0328, -0.2191]],\n",
      "\n",
      "        [[-0.1200, -0.0919, -0.1912],\n",
      "         [-0.1473,  0.2677, -0.5339],\n",
      "         [ 0.4359,  0.0449, -0.5537]]], grad_fn=<SliceBackward0>)\n",
      "blocks.5.hook_resid_post\n",
      "tensor([[[-4.5669, -3.8978, -5.0527],\n",
      "         [-1.3695,  2.2850, -0.2049],\n",
      "         [ 1.2952,  3.7645, -2.7929]],\n",
      "\n",
      "        [[-5.0963, -5.5356, -5.2644],\n",
      "         [ 1.6400,  1.2868, -4.0059],\n",
      "         [-1.2105,  3.0239, -5.3097]],\n",
      "\n",
      "        [[-4.4482, -4.9281, -4.7860],\n",
      "         [-0.3766,  1.5217,  0.7363],\n",
      "         [ 3.0251,  3.0971,  2.7831]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.hook_resid_pre\n",
      "tensor([[[-4.5669, -3.8978, -5.0527],\n",
      "         [-1.3695,  2.2850, -0.2049],\n",
      "         [ 1.2952,  3.7645, -2.7929]],\n",
      "\n",
      "        [[-5.0963, -5.5356, -5.2644],\n",
      "         [ 1.6400,  1.2868, -4.0059],\n",
      "         [-1.2105,  3.0239, -5.3097]],\n",
      "\n",
      "        [[-4.4482, -4.9281, -4.7860],\n",
      "         [-0.3766,  1.5217,  0.7363],\n",
      "         [ 3.0251,  3.0971,  2.7831]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.ln1.hook_scale\n",
      "tensor([[[108.0273],\n",
      "         [  3.1532],\n",
      "         [  3.0748]],\n",
      "\n",
      "        [[106.0005],\n",
      "         [  3.1600],\n",
      "         [  3.2987]],\n",
      "\n",
      "        [[108.0000],\n",
      "         [  3.0534],\n",
      "         [  3.3393]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.ln1.hook_normalized\n",
      "tensor([[[-0.0423, -0.0361, -0.0468],\n",
      "         [-0.4343,  0.7246, -0.0650],\n",
      "         [ 0.4212,  1.2243, -0.9083]],\n",
      "\n",
      "        [[-0.0481, -0.0522, -0.0497],\n",
      "         [ 0.5190,  0.4072, -1.2677],\n",
      "         [-0.3670,  0.9167, -1.6096]],\n",
      "\n",
      "        [[-0.0412, -0.0456, -0.0443],\n",
      "         [-0.1233,  0.4984,  0.2412],\n",
      "         [ 0.9059,  0.9275,  0.8334]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.ln1.hook_scale\n",
      "tensor([[[108.0273],\n",
      "         [  3.1532],\n",
      "         [  3.0748]],\n",
      "\n",
      "        [[106.0005],\n",
      "         [  3.1600],\n",
      "         [  3.2987]],\n",
      "\n",
      "        [[108.0000],\n",
      "         [  3.0534],\n",
      "         [  3.3393]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.ln1.hook_normalized\n",
      "tensor([[[-0.0423, -0.0361, -0.0468],\n",
      "         [-0.4343,  0.7246, -0.0650],\n",
      "         [ 0.4212,  1.2243, -0.9083]],\n",
      "\n",
      "        [[-0.0481, -0.0522, -0.0497],\n",
      "         [ 0.5190,  0.4072, -1.2677],\n",
      "         [-0.3670,  0.9167, -1.6096]],\n",
      "\n",
      "        [[-0.0412, -0.0456, -0.0443],\n",
      "         [-0.1233,  0.4984,  0.2412],\n",
      "         [ 0.9059,  0.9275,  0.8334]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.ln1.hook_scale\n",
      "tensor([[[108.0273],\n",
      "         [  3.1532],\n",
      "         [  3.0748]],\n",
      "\n",
      "        [[106.0005],\n",
      "         [  3.1600],\n",
      "         [  3.2987]],\n",
      "\n",
      "        [[108.0000],\n",
      "         [  3.0534],\n",
      "         [  3.3393]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.ln1.hook_normalized\n",
      "tensor([[[-0.0423, -0.0361, -0.0468],\n",
      "         [-0.4343,  0.7246, -0.0650],\n",
      "         [ 0.4212,  1.2243, -0.9083]],\n",
      "\n",
      "        [[-0.0481, -0.0522, -0.0497],\n",
      "         [ 0.5190,  0.4072, -1.2677],\n",
      "         [-0.3670,  0.9167, -1.6096]],\n",
      "\n",
      "        [[-0.0412, -0.0456, -0.0443],\n",
      "         [-0.1233,  0.4984,  0.2412],\n",
      "         [ 0.9059,  0.9275,  0.8334]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.attn.hook_q\n",
      "tensor([[[[-1.3718e-01, -2.4108e-01,  3.6533e-02],\n",
      "          [-2.6837e-01,  5.8075e-01, -2.3606e-01],\n",
      "          [-3.6802e-01, -4.1355e-01, -4.8926e-01]],\n",
      "\n",
      "         [[-7.4509e-01,  1.4619e+00, -3.5939e-01],\n",
      "          [ 1.3620e+00,  9.9499e-01, -3.7286e+00],\n",
      "          [-4.3561e-01, -1.6311e-01, -7.4070e-01]],\n",
      "\n",
      "         [[-7.0737e-01,  2.3320e+00, -8.3292e-01],\n",
      "          [ 4.9349e-01,  2.1750e-03, -3.2533e+00],\n",
      "          [-8.3394e-01, -7.9761e-01, -8.5953e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3541e-01, -2.2184e-01,  3.4278e-02],\n",
      "          [-2.7759e-01,  5.8838e-01, -2.0104e-01],\n",
      "          [-3.6697e-01, -4.2795e-01, -4.8686e-01]],\n",
      "\n",
      "         [[-5.6225e-01,  2.6524e+00,  1.1688e+00],\n",
      "          [-1.1381e+00,  1.4508e+00, -8.5723e-01],\n",
      "          [-7.8683e-01, -9.6540e-02, -1.1340e+00]],\n",
      "\n",
      "         [[ 4.8200e-01,  2.9870e+00, -5.5580e-01],\n",
      "          [ 1.6484e+00,  8.2109e-01, -1.9929e+00],\n",
      "          [-1.0510e+00,  2.0231e-01, -4.7726e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3528e-01, -2.2607e-01,  4.2177e-02],\n",
      "          [-2.7138e-01,  5.6935e-01, -2.2450e-01],\n",
      "          [-3.7986e-01, -4.2856e-01, -4.8335e-01]],\n",
      "\n",
      "         [[ 4.2351e-01,  2.4749e+00, -3.3120e-01],\n",
      "          [ 2.6266e-01,  4.7693e-01, -1.1512e+00],\n",
      "          [-7.7213e-01, -2.8038e-02, -4.6900e-01]],\n",
      "\n",
      "         [[-1.0098e+00,  2.0206e+00, -1.3506e+00],\n",
      "          [ 1.2079e+00,  1.6309e-01, -4.8404e-01],\n",
      "          [-4.6158e-01, -1.7027e-01, -7.9515e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.attn.hook_k\n",
      "tensor([[[[-0.3349,  0.8794, -0.1610],\n",
      "          [ 0.0451,  0.8528, -0.6209],\n",
      "          [-0.3154,  0.1354, -0.9950]],\n",
      "\n",
      "         [[ 0.3020, -4.1608,  1.1729],\n",
      "          [-0.3079, -0.2357, -0.5355],\n",
      "          [-0.7788,  0.7410,  3.0010]],\n",
      "\n",
      "         [[-0.5009, -2.7756,  2.0786],\n",
      "          [-0.4378, -1.4860, -0.5898],\n",
      "          [-0.5973, -0.3480,  3.3563]]],\n",
      "\n",
      "\n",
      "        [[[-0.3214,  0.8655, -0.1593],\n",
      "          [ 0.0169,  0.8529, -0.6390],\n",
      "          [-0.3185,  0.1484, -0.9873]],\n",
      "\n",
      "         [[ 0.5827, -4.4895,  0.3974],\n",
      "          [-1.9629,  0.4085,  0.5007],\n",
      "          [-0.8685,  0.4480,  4.5740]],\n",
      "\n",
      "         [[ 0.0308, -4.1765,  1.5111],\n",
      "          [-1.3494,  0.5980,  0.8769],\n",
      "          [-0.5578,  0.7357,  3.5913]]],\n",
      "\n",
      "\n",
      "        [[[-0.3276,  0.8703, -0.1669],\n",
      "          [ 0.0312,  0.8572, -0.6256],\n",
      "          [-0.3128,  0.1386, -0.9905]],\n",
      "\n",
      "         [[-0.4143, -4.5354,  1.6406],\n",
      "          [-0.2516, -0.9290,  0.6118],\n",
      "          [-0.4174,  0.1053,  3.4642]],\n",
      "\n",
      "         [[-0.4549, -3.7714,  1.8949],\n",
      "          [-0.7888,  0.6488,  0.0636],\n",
      "          [-0.0490,  0.5155,  3.6522]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.attn.hook_v\n",
      "tensor([[[[ 0.1675, -0.0981,  0.0450],\n",
      "          [ 0.0237,  0.1000, -0.1023],\n",
      "          [-0.0054,  0.0606,  0.1043]],\n",
      "\n",
      "         [[ 0.7320, -0.1859,  0.3827],\n",
      "          [ 0.5008, -0.3397, -0.0707],\n",
      "          [ 0.5395, -1.1970,  1.5322]],\n",
      "\n",
      "         [[ 0.7702, -0.2247,  0.4655],\n",
      "          [ 0.0455,  0.6043,  0.7578],\n",
      "          [-0.8856, -0.6899,  1.8533]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1625, -0.1048,  0.0441],\n",
      "          [ 0.0188,  0.1119, -0.1102],\n",
      "          [ 0.0157,  0.0648,  0.0770]],\n",
      "\n",
      "         [[ 0.2648, -0.2852,  0.1090],\n",
      "          [-0.4110, -0.4665, -0.2351],\n",
      "          [-0.1543,  1.3598,  0.7861]],\n",
      "\n",
      "         [[-0.3639,  0.1021, -0.4164],\n",
      "          [-0.2640, -0.9479, -0.3531],\n",
      "          [ 0.7805, -0.6105,  0.8847]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1664, -0.0921,  0.0374],\n",
      "          [ 0.0141,  0.1060, -0.1041],\n",
      "          [-0.0071,  0.0592,  0.1043]],\n",
      "\n",
      "         [[ 0.0129,  0.0426,  0.0871],\n",
      "          [ 0.7293, -0.8168, -0.2843],\n",
      "          [-0.0521,  0.2293,  0.7720]],\n",
      "\n",
      "         [[-0.5352, -0.1250, -0.2398],\n",
      "          [ 0.0899,  0.4944,  0.4086],\n",
      "          [-0.8113, -0.4024, -0.4066]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.attn.hook_attn_scores\n",
      "tensor([[[[ 1.3840e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-9.6426e-01, -3.1991e+00, -1.0000e+05],\n",
      "          [-1.0025e+00, -1.9701e+00, -4.9539e+00]],\n",
      "\n",
      "         [[ 6.8761e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.0304e+00, -2.1373e+00, -1.0000e+05],\n",
      "          [ 1.0440e+00, -1.5458e+00, -2.4088e+00]],\n",
      "\n",
      "         [[ 7.5389e-02, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.7893e-01, -4.3665e+00, -1.0000e+05],\n",
      "          [ 1.1994e-01, -3.9515e+00, -3.3662e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4662e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-1.1048e+00, -3.8267e+00, -1.0000e+05],\n",
      "          [-1.7564e+00, -3.4210e+00, -3.7151e+00]],\n",
      "\n",
      "         [[ 6.9707e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 5.5051e-01, -2.5519e+00, -1.0000e+05],\n",
      "          [ 2.7548e-01, -4.5983e+00, -3.5134e+00]],\n",
      "\n",
      "         [[ 8.7414e-02, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.0755e-01, -4.7967e+00, -1.0000e+05],\n",
      "          [ 1.8259e-01, -3.6970e+00, -3.8637e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4287e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-1.0946e+00, -3.7384e+00, -1.0000e+05],\n",
      "          [-7.4040e-01, -2.2677e+00, -3.0259e+00]],\n",
      "\n",
      "         [[ 6.8627e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.9501e-01, -2.3224e+00, -1.0000e+05],\n",
      "          [ 1.2561e+00, -2.4336e+00, -2.3722e+00]],\n",
      "\n",
      "         [[ 8.1084e-02, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.9721e-01, -4.0336e+00, -1.0000e+05],\n",
      "          [ 3.5656e-01, -3.7566e+00, -3.7265e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.attn.hook_pattern\n",
      "tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9033, 0.0967, 0.0000],\n",
      "          [0.7147, 0.2716, 0.0137]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9596, 0.0404, 0.0000],\n",
      "          [0.9036, 0.0678, 0.0286]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9905, 0.0095, 0.0000],\n",
      "          [0.9545, 0.0163, 0.0292]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9383, 0.0617, 0.0000],\n",
      "          [0.7517, 0.1423, 0.1060]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9570, 0.0430, 0.0000],\n",
      "          [0.9706, 0.0074, 0.0220]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9940, 0.0060, 0.0000],\n",
      "          [0.9633, 0.0199, 0.0168]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9336, 0.0664, 0.0000],\n",
      "          [0.7582, 0.1646, 0.0771]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9436, 0.0564, 0.0000],\n",
      "          [0.9510, 0.0238, 0.0253]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9857, 0.0143, 0.0000],\n",
      "          [0.9679, 0.0158, 0.0163]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.attn.hook_z\n",
      "tensor([[[[ 1.6748e-01, -9.8150e-02,  4.4985e-02],\n",
      "          [ 2.3693e-02,  1.0003e-01, -1.0227e-01],\n",
      "          [-5.3588e-03,  6.0564e-02,  1.0428e-01]],\n",
      "\n",
      "         [[ 2.2204e-01, -1.0664e-01,  7.7633e-02],\n",
      "          [ 4.2969e-02,  8.2268e-02, -1.0100e-01],\n",
      "          [-1.7529e-04,  4.8600e-02,  1.1787e-01]],\n",
      "\n",
      "         [[ 3.2907e-01, -1.2373e-01,  1.4249e-01],\n",
      "          [ 5.6666e-02,  8.4645e-02, -7.5528e-02],\n",
      "          [-2.2217e-02,  1.8160e-02,  1.7864e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6254e-01, -1.0482e-01,  4.4122e-02],\n",
      "          [ 1.8775e-02,  1.1192e-01, -1.1023e-01],\n",
      "          [ 1.5686e-02,  6.4812e-02,  7.6992e-02]],\n",
      "\n",
      "         [[ 1.6885e-01, -1.1594e-01,  4.8125e-02],\n",
      "          [ 2.8880e-04,  8.7046e-02, -1.1560e-01],\n",
      "          [ 1.4661e-02,  7.2626e-02,  8.1270e-02]],\n",
      "\n",
      "         [[ 1.2127e-01, -1.0854e-01,  4.5332e-03],\n",
      "          [ 9.3762e-03,  8.4362e-02, -1.1649e-01],\n",
      "          [ 2.5186e-02,  7.9206e-02,  1.0471e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6643e-01, -9.2079e-02,  3.7430e-02],\n",
      "          [ 1.4098e-02,  1.0601e-01, -1.0409e-01],\n",
      "          [-7.0749e-03,  5.9217e-02,  1.0429e-01]],\n",
      "\n",
      "         [[ 1.5624e-01, -8.3138e-02,  4.0728e-02],\n",
      "          [ 5.4429e-02,  5.3975e-02, -1.1425e-01],\n",
      "          [-7.7207e-03,  6.1655e-02,  1.1386e-01]],\n",
      "\n",
      "         [[ 8.7032e-02, -7.2442e-02,  2.4225e-02],\n",
      "          [ 3.3004e-02,  9.3898e-02, -9.5418e-02],\n",
      "          [-2.0908e-02,  5.4379e-02,  1.0653e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.hook_attn_out\n",
      "tensor([[[-0.0431, -0.0342,  0.1087],\n",
      "         [-0.0904,  0.0258,  0.1055],\n",
      "         [-0.1837,  0.1883,  0.1087]],\n",
      "\n",
      "        [[-0.0315, -0.0180,  0.0994],\n",
      "         [-0.0361, -0.0764, -0.0904],\n",
      "         [ 0.1895, -0.0748, -0.2817]],\n",
      "\n",
      "        [[-0.0343, -0.0357,  0.1303],\n",
      "         [-0.0497,  0.1064,  0.1872],\n",
      "         [ 0.0226,  0.1701,  0.1271]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.hook_resid_mid\n",
      "tensor([[[-4.6100, -3.9320, -4.9440],\n",
      "         [-1.4599,  2.3108, -0.0994],\n",
      "         [ 1.1116,  3.9528, -2.6841]],\n",
      "\n",
      "        [[-5.1278, -5.5536, -5.1650],\n",
      "         [ 1.6039,  1.2104, -4.0963],\n",
      "         [-1.0210,  2.9492, -5.5914]],\n",
      "\n",
      "        [[-4.4825, -4.9638, -4.6557],\n",
      "         [-0.4263,  1.6281,  0.9235],\n",
      "         [ 3.0477,  3.2671,  2.9101]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.ln2.hook_scale\n",
      "tensor([[[108.0571],\n",
      "         [  3.1919],\n",
      "         [  3.1508]],\n",
      "\n",
      "        [[106.0279],\n",
      "         [  3.1983],\n",
      "         [  3.4031]],\n",
      "\n",
      "        [[108.0289],\n",
      "         [  3.1025],\n",
      "         [  3.3923]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.ln2.hook_normalized\n",
      "tensor([[[-0.0427, -0.0364, -0.0458],\n",
      "         [-0.4574,  0.7239, -0.0311],\n",
      "         [ 0.3528,  1.2545, -0.8519]],\n",
      "\n",
      "        [[-0.0484, -0.0524, -0.0487],\n",
      "         [ 0.5015,  0.3784, -1.2808],\n",
      "         [-0.3000,  0.8666, -1.6430]],\n",
      "\n",
      "        [[-0.0415, -0.0459, -0.0431],\n",
      "         [-0.1374,  0.5248,  0.2977],\n",
      "         [ 0.8984,  0.9631,  0.8579]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.mlp.hook_pre\n",
      "tensor([[[ 2.6694e-01, -1.0054e+00,  3.5393e-01],\n",
      "         [-3.4246e-01, -5.7660e-01,  1.6976e-03],\n",
      "         [ 1.4502e-01, -1.9016e+00, -7.4232e-01]],\n",
      "\n",
      "        [[ 2.4026e-01, -9.8310e-01,  3.4802e-01],\n",
      "         [-1.3510e+00, -1.3339e+00, -5.2524e-01],\n",
      "         [-1.9375e-01, -6.1343e-01,  3.6130e-02]],\n",
      "\n",
      "        [[ 2.6987e-01, -9.7695e-01,  3.6444e-01],\n",
      "         [-8.3269e-01, -9.4942e-01, -6.6020e-01],\n",
      "         [-1.1875e+00, -8.2801e-01, -4.6227e-01]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.mlp.hook_post\n",
      "tensor([[[ 0.1616, -0.1584,  0.2259],\n",
      "         [-0.1253, -0.1627,  0.0008],\n",
      "         [ 0.0809, -0.0544, -0.1700]],\n",
      "\n",
      "        [[ 0.1429, -0.1602,  0.2214],\n",
      "         [-0.1196, -0.1218, -0.1574],\n",
      "         [-0.0820, -0.1655,  0.0186]],\n",
      "\n",
      "        [[ 0.1636, -0.1607,  0.2340],\n",
      "         [-0.1687, -0.1627, -0.1681],\n",
      "         [-0.1398, -0.1689, -0.1488]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.hook_mlp_out\n",
      "tensor([[[-0.1256, -0.0288, -0.1722],\n",
      "         [ 0.1898, -0.0591, -0.5341],\n",
      "         [ 0.1914, -0.7260, -0.8789]],\n",
      "\n",
      "        [[-0.1133, -0.0579, -0.1570],\n",
      "         [-0.0938, -0.2838,  0.4028],\n",
      "         [-0.1918,  0.1631, -0.0129]],\n",
      "\n",
      "        [[-0.1563, -0.0325, -0.1435],\n",
      "         [ 0.0382,  0.0176, -0.0896],\n",
      "         [ 0.3808, -0.8063,  1.1142]]], grad_fn=<SliceBackward0>)\n",
      "blocks.6.hook_resid_post\n",
      "tensor([[[-4.7356, -3.9608, -5.1162],\n",
      "         [-1.2701,  2.2517, -0.6335],\n",
      "         [ 1.3030,  3.2268, -3.5631]],\n",
      "\n",
      "        [[-5.2411, -5.6115, -5.3220],\n",
      "         [ 1.5101,  0.9266, -3.6936],\n",
      "         [-1.2128,  3.1123, -5.6044]],\n",
      "\n",
      "        [[-4.6388, -4.9963, -4.7993],\n",
      "         [-0.3881,  1.6457,  0.8339],\n",
      "         [ 3.4285,  2.4608,  4.0243]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.hook_resid_pre\n",
      "tensor([[[-4.7356, -3.9608, -5.1162],\n",
      "         [-1.2701,  2.2517, -0.6335],\n",
      "         [ 1.3030,  3.2268, -3.5631]],\n",
      "\n",
      "        [[-5.2411, -5.6115, -5.3220],\n",
      "         [ 1.5101,  0.9266, -3.6936],\n",
      "         [-1.2128,  3.1123, -5.6044]],\n",
      "\n",
      "        [[-4.6388, -4.9963, -4.7993],\n",
      "         [-0.3881,  1.6457,  0.8339],\n",
      "         [ 3.4285,  2.4608,  4.0243]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.ln1.hook_scale\n",
      "tensor([[[110.0426],\n",
      "         [  3.4656],\n",
      "         [  3.4300]],\n",
      "\n",
      "        [[107.9128],\n",
      "         [  3.4944],\n",
      "         [  3.6699]],\n",
      "\n",
      "        [[110.0024],\n",
      "         [  3.5072],\n",
      "         [  3.6699]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.ln1.hook_normalized\n",
      "tensor([[[-0.0430, -0.0360, -0.0465],\n",
      "         [-0.3665,  0.6497, -0.1828],\n",
      "         [ 0.3799,  0.9408, -1.0388]],\n",
      "\n",
      "        [[-0.0486, -0.0520, -0.0493],\n",
      "         [ 0.4322,  0.2652, -1.0570],\n",
      "         [-0.3305,  0.8481, -1.5271]],\n",
      "\n",
      "        [[-0.0422, -0.0454, -0.0436],\n",
      "         [-0.1107,  0.4692,  0.2378],\n",
      "         [ 0.9342,  0.6706,  1.0966]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.ln1.hook_scale\n",
      "tensor([[[110.0426],\n",
      "         [  3.4656],\n",
      "         [  3.4300]],\n",
      "\n",
      "        [[107.9128],\n",
      "         [  3.4944],\n",
      "         [  3.6699]],\n",
      "\n",
      "        [[110.0024],\n",
      "         [  3.5072],\n",
      "         [  3.6699]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.ln1.hook_normalized\n",
      "tensor([[[-0.0430, -0.0360, -0.0465],\n",
      "         [-0.3665,  0.6497, -0.1828],\n",
      "         [ 0.3799,  0.9408, -1.0388]],\n",
      "\n",
      "        [[-0.0486, -0.0520, -0.0493],\n",
      "         [ 0.4322,  0.2652, -1.0570],\n",
      "         [-0.3305,  0.8481, -1.5271]],\n",
      "\n",
      "        [[-0.0422, -0.0454, -0.0436],\n",
      "         [-0.1107,  0.4692,  0.2378],\n",
      "         [ 0.9342,  0.6706,  1.0966]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.ln1.hook_scale\n",
      "tensor([[[110.0426],\n",
      "         [  3.4656],\n",
      "         [  3.4300]],\n",
      "\n",
      "        [[107.9128],\n",
      "         [  3.4944],\n",
      "         [  3.6699]],\n",
      "\n",
      "        [[110.0024],\n",
      "         [  3.5072],\n",
      "         [  3.6699]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.ln1.hook_normalized\n",
      "tensor([[[-0.0430, -0.0360, -0.0465],\n",
      "         [-0.3665,  0.6497, -0.1828],\n",
      "         [ 0.3799,  0.9408, -1.0388]],\n",
      "\n",
      "        [[-0.0486, -0.0520, -0.0493],\n",
      "         [ 0.4322,  0.2652, -1.0570],\n",
      "         [-0.3305,  0.8481, -1.5271]],\n",
      "\n",
      "        [[-0.0422, -0.0454, -0.0436],\n",
      "         [-0.1107,  0.4692,  0.2378],\n",
      "         [ 0.9342,  0.6706,  1.0966]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.attn.hook_q\n",
      "tensor([[[[ 0.0395, -0.3079,  0.3215],\n",
      "          [ 0.1281, -0.1473, -0.0114],\n",
      "          [ 0.2422,  0.1356,  0.2810]],\n",
      "\n",
      "         [[-0.3195,  1.0214, -0.0465],\n",
      "          [-1.7494,  0.2859, -1.2889],\n",
      "          [ 2.1042, -0.2300,  2.5773]],\n",
      "\n",
      "         [[ 1.3918,  1.1763, -0.8275],\n",
      "          [-1.3042,  3.0455, -1.1198],\n",
      "          [ 1.2935,  0.4017,  3.1381]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0624, -0.3209,  0.3210],\n",
      "          [ 0.1295, -0.1331, -0.0178],\n",
      "          [ 0.2212,  0.1246,  0.2633]],\n",
      "\n",
      "         [[ 1.4369, -0.3451,  0.5926],\n",
      "          [-0.3131,  0.4839, -1.1372],\n",
      "          [ 0.7914, -3.4275,  0.5337]],\n",
      "\n",
      "         [[ 1.3854,  0.2884,  0.2900],\n",
      "          [-1.1396,  0.2608, -1.6346],\n",
      "          [ 0.7085, -1.8595,  2.9038]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0369, -0.3244,  0.3202],\n",
      "          [ 0.1290, -0.1413, -0.0256],\n",
      "          [ 0.2414,  0.1215,  0.2880]],\n",
      "\n",
      "         [[ 0.0205,  1.3626, -0.1274],\n",
      "          [ 0.0070, -0.0908, -1.9603],\n",
      "          [ 2.1070, -0.1758,  3.5026]],\n",
      "\n",
      "         [[ 0.8027,  1.2609,  0.1946],\n",
      "          [ 0.1175,  0.2062,  0.4605],\n",
      "          [ 2.7168, -0.9359,  2.6577]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.attn.hook_k\n",
      "tensor([[[[ 1.0330, -0.2498, -0.1115],\n",
      "          [-0.1520, -0.0647,  0.1708],\n",
      "          [ 0.1942,  0.3038,  1.1245]],\n",
      "\n",
      "         [[-4.0005, -0.9390,  0.6993],\n",
      "          [-1.0948,  0.0071,  0.5834],\n",
      "          [ 0.9847, -0.1146, -0.6591]],\n",
      "\n",
      "         [[-5.8264, -2.4699,  2.2940],\n",
      "          [-0.9064,  0.0527, -1.2628],\n",
      "          [ 0.7590, -0.6661, -1.7433]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0268, -0.2771, -0.1212],\n",
      "          [-0.1377, -0.0582,  0.1646],\n",
      "          [ 0.1890,  0.2813,  1.1075]],\n",
      "\n",
      "         [[-4.7091, -2.0052,  0.8505],\n",
      "          [-0.5982,  0.5011,  0.3813],\n",
      "          [ 0.2297, -1.6905, -0.2716]],\n",
      "\n",
      "         [[-5.1888, -2.7292, -1.0694],\n",
      "          [ 0.0632,  0.4097,  0.2225],\n",
      "          [ 0.1475, -1.7111, -2.2615]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0343, -0.2567, -0.1354],\n",
      "          [-0.1499, -0.0606,  0.1463],\n",
      "          [ 0.2054,  0.2976,  1.1291]],\n",
      "\n",
      "         [[-4.1090, -1.5321, -0.0454],\n",
      "          [-0.6370, -0.0058, -0.5982],\n",
      "          [ 0.5650, -1.3329, -1.5190]],\n",
      "\n",
      "         [[-4.1360, -1.7654,  0.5728],\n",
      "          [ 0.6810,  1.4782, -0.7489],\n",
      "          [ 1.3687, -0.5410, -0.6982]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.attn.hook_v\n",
      "tensor([[[[-7.1101e-02,  1.6130e-02, -1.7935e-01],\n",
      "          [ 5.0425e-02, -1.1044e-01,  1.0113e-01],\n",
      "          [-1.1069e-01, -8.3664e-02, -1.2352e-01]],\n",
      "\n",
      "         [[ 2.8647e-02, -1.7808e-01, -6.7830e-01],\n",
      "          [-3.8251e-01, -9.6787e-01,  4.8758e-01],\n",
      "          [-1.0983e+00,  4.2109e-01, -1.9090e-01]],\n",
      "\n",
      "         [[-7.4371e-02, -7.6622e-01,  5.1190e-01],\n",
      "          [ 1.5647e-03, -2.0160e-01, -6.3029e-01],\n",
      "          [-1.7353e+00, -3.4622e-01, -5.8092e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.7569e-02,  7.0710e-03, -1.9259e-01],\n",
      "          [ 4.1577e-02, -1.1214e-01,  9.9631e-02],\n",
      "          [-1.2899e-01, -7.6243e-02, -1.3421e-01]],\n",
      "\n",
      "         [[-3.9667e-01,  5.8635e-02, -8.7824e-01],\n",
      "          [ 1.1367e+00, -6.5222e-01, -1.5808e+00],\n",
      "          [-2.5576e+00, -1.6311e-01, -1.2446e+00]],\n",
      "\n",
      "         [[ 3.7973e-01, -1.7589e-01, -3.5700e-01],\n",
      "          [ 5.7086e-01, -1.1717e-01, -6.8058e-01],\n",
      "          [-1.1476e+00,  8.2796e-01,  4.7984e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.4925e-02,  1.0508e-02, -1.9461e-01],\n",
      "          [ 5.1295e-02, -1.1714e-01,  9.0320e-02],\n",
      "          [-1.1393e-01, -6.8926e-02, -1.4390e-01]],\n",
      "\n",
      "         [[-1.5834e-01, -1.2301e-01, -6.2406e-01],\n",
      "          [ 1.4278e-01, -1.1312e+00,  1.3704e+00],\n",
      "          [-1.1026e+00,  7.4997e-01, -6.7949e-01]],\n",
      "\n",
      "         [[-7.5205e-01,  4.4256e-01, -2.7539e-01],\n",
      "          [ 5.3437e-01, -1.9311e-01, -5.6809e-01],\n",
      "          [ 1.2636e+00, -5.6694e-01, -2.2124e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.attn.hook_attn_scores\n",
      "tensor([[[[ 6.3570e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-1.5966e+00, -3.9916e+00, -1.0000e+05],\n",
      "          [-1.4446e+00, -1.8156e+00, -3.0436e+00]],\n",
      "\n",
      "         [[ 6.7573e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.0356e+00,  5.8578e-01, -1.0000e+05],\n",
      "          [ 3.8853e+00, -1.2928e+00,  2.6079e-01]],\n",
      "\n",
      "         [[ 1.3579e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 6.7507e+00,  2.4213e+00, -1.0000e+05],\n",
      "          [ 6.9719e+00,  1.0485e+00,  3.2144e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4354e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-2.1046e+00, -3.4485e+00, -1.0000e+05],\n",
      "          [-2.2870e+00, -1.5692e+00, -3.3439e+00]],\n",
      "\n",
      "         [[ 6.7304e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.4525e+00, -2.8546e-01, -1.0000e+05],\n",
      "          [ 4.1117e+00, -2.0251e+00,  5.5159e-01]],\n",
      "\n",
      "         [[ 1.3715e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 6.1885e+00, -1.3142e+00, -1.0000e+05],\n",
      "          [ 6.4748e+00, -2.6844e+00,  1.3583e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3268e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [-1.7366e+00, -3.4260e+00, -1.0000e+05],\n",
      "          [-1.0197e+00, -7.2186e-01, -2.7578e+00]],\n",
      "\n",
      "         [[ 6.7473e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.9015e+00,  6.5140e-01, -1.0000e+05],\n",
      "          [ 3.5200e+00, -6.9229e-01, -1.1499e+00]],\n",
      "\n",
      "         [[ 1.3623e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 6.8243e+00,  5.3594e-01, -1.0000e+05],\n",
      "          [ 6.4524e+00, -7.5405e-01,  3.1922e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.attn.hook_pattern\n",
      "tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.1645e-01, 8.3554e-02, 0.0000e+00],\n",
      "          [5.2851e-01, 3.6469e-01, 1.0681e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.6923e-01, 3.0773e-02, 0.0000e+00],\n",
      "          [9.6871e-01, 5.4628e-03, 2.5829e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8700e-01, 1.3004e-02, 0.0000e+00],\n",
      "          [9.7464e-01, 2.6084e-03, 2.2750e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [7.9312e-01, 2.0688e-01, 0.0000e+00],\n",
      "          [2.9435e-01, 6.0336e-01, 1.0229e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.9132e-01, 8.6805e-03, 0.0000e+00],\n",
      "          [9.7031e-01, 2.0978e-03, 2.7592e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.9945e-01, 5.5127e-04, 0.0000e+00],\n",
      "          [9.9394e-01, 1.0461e-04, 5.9602e-03]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [8.4415e-01, 1.5585e-01, 0.0000e+00],\n",
      "          [3.9639e-01, 5.3391e-01, 6.9704e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8594e-01, 1.4063e-02, 0.0000e+00],\n",
      "          [9.7639e-01, 1.4463e-02, 9.1516e-03]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.9815e-01, 1.8544e-03, 0.0000e+00],\n",
      "          [9.9710e-01, 7.3963e-04, 2.1634e-03]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.attn.hook_z\n",
      "tensor([[[[-7.1101e-02,  1.6130e-02, -1.7935e-01],\n",
      "          [ 5.0425e-02, -1.1044e-01,  1.0113e-01],\n",
      "          [-1.1069e-01, -8.3664e-02, -1.2352e-01]],\n",
      "\n",
      "         [[-6.2767e-02, -9.6964e-05, -2.2104e-01],\n",
      "          [ 3.7103e-02, -1.3683e-01,  1.1302e-01],\n",
      "          [-1.2353e-01, -7.7100e-02, -1.2440e-01]],\n",
      "\n",
      "         [[-3.5074e-02, -1.3826e-01, -2.8748e-01],\n",
      "          [ 4.6798e-02, -1.1748e-01,  8.4349e-02],\n",
      "          [-1.5023e-01, -8.8320e-02, -1.3410e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.7569e-02,  7.0710e-03, -1.9259e-01],\n",
      "          [ 4.1577e-02, -1.1214e-01,  9.9631e-02],\n",
      "          [-1.2899e-01, -7.6243e-02, -1.3421e-01]],\n",
      "\n",
      "         [[-1.3565e-01,  1.7738e-02, -3.3443e-01],\n",
      "          [ 5.1084e-02, -1.1683e-01,  8.5044e-02],\n",
      "          [-1.3033e-01, -7.6291e-02, -1.3482e-01]],\n",
      "\n",
      "         [[-2.2038e-01,  1.9467e-02, -6.2310e-01],\n",
      "          [ 5.8479e-02, -1.1342e-01,  7.4578e-02],\n",
      "          [-1.3531e-01, -7.0863e-02, -1.3067e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.4925e-02,  1.0508e-02, -1.9461e-01],\n",
      "          [ 5.1295e-02, -1.1714e-01,  9.0320e-02],\n",
      "          [-1.1393e-01, -6.8926e-02, -1.4390e-01]],\n",
      "\n",
      "         [[-8.7925e-02, -1.0301e-02, -2.6154e-01],\n",
      "          [ 5.2581e-02, -1.3141e-01,  1.0832e-01],\n",
      "          [-1.1576e-01, -6.7408e-02, -1.4489e-01]],\n",
      "\n",
      "         [[-1.6666e-01, -3.0664e-02, -4.2953e-01],\n",
      "          [ 5.7039e-02, -1.3251e-01,  1.0281e-01],\n",
      "          [-1.1168e-01, -6.9398e-02, -1.4877e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.hook_attn_out\n",
      "tensor([[[-0.0633,  0.0127,  0.0599],\n",
      "         [-0.1207,  0.0524, -0.0129],\n",
      "         [-0.3192,  0.0450, -0.0853]],\n",
      "\n",
      "        [[-0.0568, -0.0062, -0.0220],\n",
      "         [ 0.0629, -0.0476,  0.0046],\n",
      "         [ 0.3419, -0.0361, -0.0560]],\n",
      "\n",
      "        [[-0.0662,  0.0116,  0.0128],\n",
      "         [-0.0349,  0.0214,  0.0144],\n",
      "         [ 0.2010, -0.1013, -0.0749]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.hook_resid_mid\n",
      "tensor([[[-4.7989, -3.9481, -5.0563],\n",
      "         [-1.3907,  2.3040, -0.6465],\n",
      "         [ 0.9838,  3.2719, -3.6484]],\n",
      "\n",
      "        [[-5.2979, -5.6177, -5.3441],\n",
      "         [ 1.5730,  0.8789, -3.6890],\n",
      "         [-0.8709,  3.0762, -5.6603]],\n",
      "\n",
      "        [[-4.7049, -4.9848, -4.7865],\n",
      "         [-0.4230,  1.6670,  0.8483],\n",
      "         [ 3.6295,  2.3595,  3.9494]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.ln2.hook_scale\n",
      "tensor([[[110.0630],\n",
      "         [  3.5186],\n",
      "         [  3.5919]],\n",
      "\n",
      "        [[107.9340],\n",
      "         [  3.5664],\n",
      "         [  3.8929]],\n",
      "\n",
      "        [[110.0268],\n",
      "         [  3.5689],\n",
      "         [  3.7724]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.ln2.hook_normalized\n",
      "tensor([[[-0.0436, -0.0359, -0.0459],\n",
      "         [-0.3952,  0.6548, -0.1837],\n",
      "         [ 0.2739,  0.9109, -1.0157]],\n",
      "\n",
      "        [[-0.0491, -0.0520, -0.0495],\n",
      "         [ 0.4411,  0.2465, -1.0344],\n",
      "         [-0.2237,  0.7902, -1.4540]],\n",
      "\n",
      "        [[-0.0428, -0.0453, -0.0435],\n",
      "         [-0.1185,  0.4671,  0.2377],\n",
      "         [ 0.9621,  0.6255,  1.0469]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.mlp.hook_pre\n",
      "tensor([[[ 0.1259,  0.3977, -1.4670],\n",
      "         [ 0.0105,  0.2889, -1.1016],\n",
      "         [-0.3154, -0.4664, -0.8666]],\n",
      "\n",
      "        [[ 0.1186,  0.4004, -1.4678],\n",
      "         [-0.5727, -0.6516, -2.1852],\n",
      "         [-0.2729, -0.2877, -1.2332]],\n",
      "\n",
      "        [[ 0.1260,  0.4018, -1.4587],\n",
      "         [ 0.5884, -0.1945, -1.5670],\n",
      "         [-0.0165, -0.0115, -0.5853]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.mlp.hook_post\n",
      "tensor([[[ 0.0692,  0.2603, -0.1047],\n",
      "         [ 0.0053,  0.1773, -0.1493],\n",
      "         [-0.1187, -0.1495, -0.1674]],\n",
      "\n",
      "        [[ 0.0649,  0.2625, -0.1046],\n",
      "         [-0.1623, -0.1677, -0.0313],\n",
      "         [-0.1071, -0.1113, -0.1343]],\n",
      "\n",
      "        [[ 0.0693,  0.2636, -0.1057],\n",
      "         [ 0.4247, -0.0822, -0.0920],\n",
      "         [-0.0082, -0.0057, -0.1634]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.hook_mlp_out\n",
      "tensor([[[-0.0334,  0.0581, -0.2216],\n",
      "         [-0.1916,  0.0443, -0.8736],\n",
      "         [ 0.4676, -1.0430, -0.8823]],\n",
      "\n",
      "        [[-0.0710,  0.0429, -0.1908],\n",
      "         [ 0.6829, -0.3675,  1.3248],\n",
      "         [ 0.4724, -0.4608,  0.1738]],\n",
      "\n",
      "        [[-0.0502,  0.0364, -0.2245],\n",
      "         [-0.0442,  1.0081, -0.9168],\n",
      "         [ 0.6385,  1.0207,  1.1619]]], grad_fn=<SliceBackward0>)\n",
      "blocks.7.hook_resid_post\n",
      "tensor([[[-4.8323, -3.8900, -5.2779],\n",
      "         [-1.5823,  2.3483, -1.5200],\n",
      "         [ 1.4514,  2.2288, -4.5307]],\n",
      "\n",
      "        [[-5.3689, -5.5747, -5.5349],\n",
      "         [ 2.2559,  0.5114, -2.3642],\n",
      "         [-0.3985,  2.6153, -5.4866]],\n",
      "\n",
      "        [[-4.7551, -4.9484, -5.0110],\n",
      "         [-0.4672,  2.6751, -0.0685],\n",
      "         [ 4.2680,  3.3802,  5.1113]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.hook_resid_pre\n",
      "tensor([[[-4.8323, -3.8900, -5.2779],\n",
      "         [-1.5823,  2.3483, -1.5200],\n",
      "         [ 1.4514,  2.2288, -4.5307]],\n",
      "\n",
      "        [[-5.3689, -5.5747, -5.5349],\n",
      "         [ 2.2559,  0.5114, -2.3642],\n",
      "         [-0.3985,  2.6153, -5.4866]],\n",
      "\n",
      "        [[-4.7551, -4.9484, -5.0110],\n",
      "         [-0.4672,  2.6751, -0.0685],\n",
      "         [ 4.2680,  3.3802,  5.1113]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.ln1.hook_scale\n",
      "tensor([[[111.2555],\n",
      "         [  4.0057],\n",
      "         [  4.0337]],\n",
      "\n",
      "        [[109.0647],\n",
      "         [  4.0151],\n",
      "         [  4.4851]],\n",
      "\n",
      "        [[111.2089],\n",
      "         [  4.1660],\n",
      "         [  4.1905]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.ln1.hook_normalized\n",
      "tensor([[[-0.0434, -0.0350, -0.0474],\n",
      "         [-0.3950,  0.5863, -0.3795],\n",
      "         [ 0.3598,  0.5525, -1.1232]],\n",
      "\n",
      "        [[-0.0492, -0.0511, -0.0507],\n",
      "         [ 0.5619,  0.1274, -0.5888],\n",
      "         [-0.0889,  0.5831, -1.2233]],\n",
      "\n",
      "        [[-0.0428, -0.0445, -0.0451],\n",
      "         [-0.1121,  0.6421, -0.0164],\n",
      "         [ 1.0185,  0.8066,  1.2197]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.ln1.hook_scale\n",
      "tensor([[[111.2555],\n",
      "         [  4.0057],\n",
      "         [  4.0337]],\n",
      "\n",
      "        [[109.0647],\n",
      "         [  4.0151],\n",
      "         [  4.4851]],\n",
      "\n",
      "        [[111.2089],\n",
      "         [  4.1660],\n",
      "         [  4.1905]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.ln1.hook_normalized\n",
      "tensor([[[-0.0434, -0.0350, -0.0474],\n",
      "         [-0.3950,  0.5863, -0.3795],\n",
      "         [ 0.3598,  0.5525, -1.1232]],\n",
      "\n",
      "        [[-0.0492, -0.0511, -0.0507],\n",
      "         [ 0.5619,  0.1274, -0.5888],\n",
      "         [-0.0889,  0.5831, -1.2233]],\n",
      "\n",
      "        [[-0.0428, -0.0445, -0.0451],\n",
      "         [-0.1121,  0.6421, -0.0164],\n",
      "         [ 1.0185,  0.8066,  1.2197]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.ln1.hook_scale\n",
      "tensor([[[111.2555],\n",
      "         [  4.0057],\n",
      "         [  4.0337]],\n",
      "\n",
      "        [[109.0647],\n",
      "         [  4.0151],\n",
      "         [  4.4851]],\n",
      "\n",
      "        [[111.2089],\n",
      "         [  4.1660],\n",
      "         [  4.1905]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.ln1.hook_normalized\n",
      "tensor([[[-0.0434, -0.0350, -0.0474],\n",
      "         [-0.3950,  0.5863, -0.3795],\n",
      "         [ 0.3598,  0.5525, -1.1232]],\n",
      "\n",
      "        [[-0.0492, -0.0511, -0.0507],\n",
      "         [ 0.5619,  0.1274, -0.5888],\n",
      "         [-0.0889,  0.5831, -1.2233]],\n",
      "\n",
      "        [[-0.0428, -0.0445, -0.0451],\n",
      "         [-0.1121,  0.6421, -0.0164],\n",
      "         [ 1.0185,  0.8066,  1.2197]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.attn.hook_q\n",
      "tensor([[[[ 0.1503,  0.4971,  0.1728],\n",
      "          [ 0.0805,  0.0575,  0.0969],\n",
      "          [-0.0277,  0.0138,  0.0667]],\n",
      "\n",
      "         [[-0.2328, -1.3659,  1.3183],\n",
      "          [ 0.8664,  0.0347,  0.7316],\n",
      "          [-1.0428,  0.2306,  0.7330]],\n",
      "\n",
      "         [[-0.2340, -1.3174,  0.8851],\n",
      "          [-0.3581,  1.5578,  2.4057],\n",
      "          [-0.5089, -0.0073,  0.6321]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1704,  0.4822,  0.1635],\n",
      "          [ 0.0661,  0.0461,  0.1174],\n",
      "          [-0.0574,  0.0102,  0.0493]],\n",
      "\n",
      "         [[-0.0908, -1.9766, -0.1648],\n",
      "          [ 0.4205, -0.1843,  0.8235],\n",
      "          [-0.3483, -0.0892,  0.7719]],\n",
      "\n",
      "         [[ 0.2336, -2.0234,  0.1316],\n",
      "          [ 0.0704, -0.1827,  0.3334],\n",
      "          [-1.1404,  0.6633,  0.1488]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1442,  0.4907,  0.1663],\n",
      "          [ 0.0786,  0.0632,  0.1090],\n",
      "          [-0.0317,  0.0167,  0.0787]],\n",
      "\n",
      "         [[-1.0813, -1.4276,  0.9621],\n",
      "          [-0.1882,  0.0236,  0.5122],\n",
      "          [ 0.3094,  0.4083,  1.2882]],\n",
      "\n",
      "         [[-0.6407, -1.6813,  0.3561],\n",
      "          [ 0.2936, -1.6581,  2.2663],\n",
      "          [ 0.2416,  0.0812,  0.6797]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.attn.hook_k\n",
      "tensor([[[[-0.0363, -2.3376,  0.1748],\n",
      "          [-0.8211,  0.2265,  0.4681],\n",
      "          [-0.8573,  0.4706,  0.0325]],\n",
      "\n",
      "         [[-1.0674,  5.1302, -0.0816],\n",
      "          [ 0.5912, -0.3555, -0.2710],\n",
      "          [ 1.1877, -0.7032, -0.1376]],\n",
      "\n",
      "         [[-1.3491,  4.7774,  1.3082],\n",
      "          [-0.1600,  0.7198,  0.5314],\n",
      "          [ 0.7773, -0.7850,  0.4559]]],\n",
      "\n",
      "\n",
      "        [[[-0.0279, -2.3207,  0.1672],\n",
      "          [-0.7982,  0.2069,  0.4708],\n",
      "          [-0.8410,  0.4739,  0.0215]],\n",
      "\n",
      "         [[-0.1865,  5.5925,  0.2936],\n",
      "          [ 0.0947, -0.5663,  0.1549],\n",
      "          [ 1.0875,  0.6427,  0.6670]],\n",
      "\n",
      "         [[-0.5864,  4.5522, -0.4337],\n",
      "          [ 0.2127, -0.4720, -0.6137],\n",
      "          [ 0.5186, -0.4504,  0.2390]]],\n",
      "\n",
      "\n",
      "        [[[-0.0408, -2.3353,  0.1773],\n",
      "          [-0.8199,  0.2174,  0.4723],\n",
      "          [-0.8548,  0.4635,  0.0232]],\n",
      "\n",
      "         [[-0.8038,  4.6568, -0.4765],\n",
      "          [ 1.2764,  0.2620, -0.0376],\n",
      "          [ 1.2827, -0.4957,  0.4691]],\n",
      "\n",
      "         [[-0.7144,  4.4647, -0.5507],\n",
      "          [-0.1019,  0.0145, -0.6036],\n",
      "          [ 1.8007,  0.0893,  0.1400]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.attn.hook_v\n",
      "tensor([[[[ 0.1775, -0.0610, -0.1657],\n",
      "          [-0.0542, -0.0896,  0.0125],\n",
      "          [-0.0462, -0.0648,  0.0602]],\n",
      "\n",
      "         [[-0.1137, -1.1382,  1.3032],\n",
      "          [-1.3124,  0.0141,  0.4807],\n",
      "          [-0.4769,  1.2094,  0.1704]],\n",
      "\n",
      "         [[ 0.5299,  0.4038,  0.3362],\n",
      "          [-0.6093, -0.8667, -0.7671],\n",
      "          [ 0.0636,  0.3435,  0.1375]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1695, -0.0545, -0.1805],\n",
      "          [-0.0574, -0.1175,  0.0151],\n",
      "          [-0.0443, -0.0676,  0.0502]],\n",
      "\n",
      "         [[-1.0820,  0.7673, -0.0134],\n",
      "          [-0.9454, -0.6881, -0.2967],\n",
      "          [-0.0398, -0.1690, -0.8565]],\n",
      "\n",
      "         [[-1.2066, -0.0597,  0.6902],\n",
      "          [-0.7343, -1.1466, -1.2514],\n",
      "          [-1.3071, -0.2654,  1.1392]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1853, -0.0586, -0.1741],\n",
      "          [-0.0589, -0.1135,  0.0124],\n",
      "          [-0.0390, -0.0714,  0.0692]],\n",
      "\n",
      "         [[-0.4991, -0.1970,  0.7528],\n",
      "          [-1.3421, -0.4240,  0.3071],\n",
      "          [-0.3346,  0.2755,  0.5901]],\n",
      "\n",
      "         [[ 0.5264,  1.5943, -1.0156],\n",
      "          [ 1.2008,  0.6012, -1.3881],\n",
      "          [-1.3174,  1.2879,  0.7691]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.attn.hook_attn_scores\n",
      "tensor([[[[ 1.1007e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 9.4790e-01, -2.7982e+00, -1.0000e+05],\n",
      "          [ 8.9935e-01, -2.2809e+00, -2.3018e+00]],\n",
      "\n",
      "         [[ 8.8434e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.4404e+00,  2.5775e-02, -1.0000e+05],\n",
      "          [ 5.0542e+00,  3.1222e-01,  2.1793e+00]],\n",
      "\n",
      "         [[ 5.3159e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.1388e+00, -1.1041e+00, -1.0000e+05],\n",
      "          [ 1.6918e+00, -1.4437e+00, -1.4274e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1874e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 8.8948e-01, -2.8844e+00, -1.0000e+05],\n",
      "          [ 1.0421e+00, -3.1122e+00, -2.1724e+00]],\n",
      "\n",
      "         [[ 9.1148e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.4662e+00, -1.5023e+00, -1.0000e+05],\n",
      "          [ 3.8513e+00, -1.6324e+00, -2.4285e-01]],\n",
      "\n",
      "         [[ 5.3861e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.5937e+00, -3.6613e-01, -1.0000e+05],\n",
      "          [ 2.0532e+00, -1.2662e+00,  4.2886e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0834e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.0114e+00, -2.9814e+00, -1.0000e+05],\n",
      "          [ 9.9840e-01, -2.5903e+00, -3.4332e+00]],\n",
      "\n",
      "         [[ 8.8846e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.4943e+00, -8.5465e-01, -1.0000e+05],\n",
      "          [ 4.6201e+00, -7.4687e-02, -1.8529e+00]],\n",
      "\n",
      "         [[ 5.3364e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.1653e+00, -9.8083e-01, -1.0000e+05],\n",
      "          [ 2.4558e+00, -7.3660e-01, -2.0267e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.attn.hook_pattern\n",
      "tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9769, 0.0231, 0.0000],\n",
      "          [0.9240, 0.0384, 0.0376]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9880, 0.0120, 0.0000],\n",
      "          [0.9388, 0.0082, 0.0530]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9624, 0.0376, 0.0000],\n",
      "          [0.9194, 0.0400, 0.0406]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9776, 0.0224, 0.0000],\n",
      "          [0.9471, 0.0149, 0.0380]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9931, 0.0069, 0.0000],\n",
      "          [0.9796, 0.0041, 0.0163]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9507, 0.0493, 0.0000],\n",
      "          [0.8546, 0.0309, 0.1145]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9819, 0.0181, 0.0000],\n",
      "          [0.9620, 0.0266, 0.0114]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9953, 0.0047, 0.0000],\n",
      "          [0.9894, 0.0090, 0.0015]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9588, 0.0412, 0.0000],\n",
      "          [0.9502, 0.0390, 0.0107]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.attn.hook_z\n",
      "tensor([[[[ 0.1775, -0.0610, -0.1657],\n",
      "          [-0.0542, -0.0896,  0.0125],\n",
      "          [-0.0462, -0.0648,  0.0602]],\n",
      "\n",
      "         [[ 0.1708, -0.0859, -0.1318],\n",
      "          [-0.0693, -0.0884,  0.0181],\n",
      "          [-0.0624, -0.0169,  0.0643]],\n",
      "\n",
      "         [[ 0.1796, -0.0849, -0.0904],\n",
      "          [-0.0939, -0.1299, -0.0250],\n",
      "          [-0.0590,  0.0027,  0.0677]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1695, -0.0545, -0.1805],\n",
      "          [-0.0574, -0.1175,  0.0151],\n",
      "          [-0.0443, -0.0676,  0.0502]],\n",
      "\n",
      "         [[ 0.1414, -0.0361, -0.1768],\n",
      "          [-0.0635, -0.1215,  0.0129],\n",
      "          [-0.0441, -0.0726,  0.0055]],\n",
      "\n",
      "         [[ 0.0985, -0.0425, -0.1449],\n",
      "          [-0.0721, -0.1366, -0.0069],\n",
      "          [-0.1888, -0.0934,  0.1468]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1853, -0.0586, -0.1741],\n",
      "          [-0.0589, -0.1135,  0.0124],\n",
      "          [-0.0390, -0.0714,  0.0692]],\n",
      "\n",
      "         [[ 0.1729, -0.0611, -0.1573],\n",
      "          [-0.0650, -0.1149,  0.0138],\n",
      "          [-0.0511, -0.0571,  0.0907]],\n",
      "\n",
      "         [[ 0.1710, -0.0434, -0.1591],\n",
      "          [-0.0686, -0.1152,  0.0129],\n",
      "          [-0.0642, -0.0433,  0.0971]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.hook_attn_out\n",
      "tensor([[[-0.0282, -0.0195,  0.0789],\n",
      "         [-0.1029,  0.0858,  0.0353],\n",
      "         [-0.1375,  0.3682,  0.1265]],\n",
      "\n",
      "        [[-0.0291,  0.0036,  0.0148],\n",
      "         [ 0.0468, -0.2173,  0.0488],\n",
      "         [ 0.0281, -0.0727,  0.1356]],\n",
      "\n",
      "        [[-0.0371,  0.0086,  0.0463],\n",
      "         [-0.0432,  0.0640,  0.0628],\n",
      "         [ 0.4217, -0.0857, -0.0280]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.hook_resid_mid\n",
      "tensor([[[-4.8605, -3.9095, -5.1990],\n",
      "         [-1.6852,  2.4342, -1.4847],\n",
      "         [ 1.3139,  2.5970, -4.4042]],\n",
      "\n",
      "        [[-5.3981, -5.5712, -5.5201],\n",
      "         [ 2.3027,  0.2941, -2.3155],\n",
      "         [-0.3704,  2.5426, -5.3510]],\n",
      "\n",
      "        [[-4.7922, -4.9397, -4.9647],\n",
      "         [-0.5104,  2.7391, -0.0057],\n",
      "         [ 4.6897,  3.2945,  5.0833]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.ln2.hook_scale\n",
      "tensor([[[111.3172],\n",
      "         [  4.1147],\n",
      "         [  4.1815]],\n",
      "\n",
      "        [[109.1294],\n",
      "         [  4.1543],\n",
      "         [  4.6910]],\n",
      "\n",
      "        [[111.2722],\n",
      "         [  4.2898],\n",
      "         [  4.3619]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.ln2.hook_normalized\n",
      "tensor([[[-0.0437, -0.0351, -0.0467],\n",
      "         [-0.4095,  0.5916, -0.3608],\n",
      "         [ 0.3142,  0.6211, -1.0533]],\n",
      "\n",
      "        [[-0.0495, -0.0511, -0.0506],\n",
      "         [ 0.5543,  0.0708, -0.5574],\n",
      "         [-0.0790,  0.5420, -1.1407]],\n",
      "\n",
      "        [[-0.0431, -0.0444, -0.0446],\n",
      "         [-0.1190,  0.6385, -0.0013],\n",
      "         [ 1.0751,  0.7553,  1.1654]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.mlp.hook_pre\n",
      "tensor([[[ 0.1422, -1.0118, -1.9399],\n",
      "         [-1.0357, -1.9471, -1.0457],\n",
      "         [-0.7338, -1.7813, -1.0704]],\n",
      "\n",
      "        [[ 0.1458, -1.0080, -1.9349],\n",
      "         [-0.7705, -1.5811, -1.1612],\n",
      "         [-1.0820, -0.5049, -1.6066]],\n",
      "\n",
      "        [[ 0.1458, -1.0173, -1.9502],\n",
      "         [-0.5000, -0.8761, -1.7630],\n",
      "         [-0.7698, -1.0361, -0.4780]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.mlp.hook_post\n",
      "tensor([[[ 0.0792, -0.1578, -0.0508],\n",
      "         [-0.1557, -0.0501, -0.1548],\n",
      "         [-0.1700, -0.0668, -0.1524]],\n",
      "\n",
      "        [[ 0.0814, -0.1581, -0.0512],\n",
      "         [-0.1700, -0.0902, -0.1428],\n",
      "         [-0.1513, -0.1549, -0.0871]],\n",
      "\n",
      "        [[ 0.0814, -0.1573, -0.0498],\n",
      "         [-0.1543, -0.1670, -0.0688],\n",
      "         [-0.1700, -0.1557, -0.1512]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.hook_mlp_out\n",
      "tensor([[[-2.6187e-03,  4.6680e-02, -1.4385e-01],\n",
      "         [-1.9034e-01,  8.8129e-01, -1.8591e-02],\n",
      "         [-2.2001e-01, -3.6211e-04, -7.1618e-01]],\n",
      "\n",
      "        [[ 1.3799e-02,  1.4349e-02, -1.2871e-01],\n",
      "         [ 8.7682e-01,  5.1212e-01, -3.8518e-01],\n",
      "         [ 8.7039e-01, -1.6343e+00, -5.1008e-01]],\n",
      "\n",
      "        [[-1.7296e-03,  2.0731e-02, -1.4742e-01],\n",
      "         [-2.1516e-02,  8.5953e-01, -1.7762e-03],\n",
      "         [ 8.1662e-01, -1.9969e+00,  9.5416e-02]]], grad_fn=<SliceBackward0>)\n",
      "blocks.8.hook_resid_post\n",
      "tensor([[[-4.8631, -3.8628, -5.3428],\n",
      "         [-1.8755,  3.3155, -1.5033],\n",
      "         [ 1.0939,  2.5967, -5.1203]],\n",
      "\n",
      "        [[-5.3843, -5.5568, -5.6488],\n",
      "         [ 3.1795,  0.8062, -2.7006],\n",
      "         [ 0.5000,  0.9083, -5.8611]],\n",
      "\n",
      "        [[-4.7939, -4.9190, -5.1121],\n",
      "         [-0.5319,  3.5986, -0.0075],\n",
      "         [ 5.5063,  1.2976,  5.1787]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.hook_resid_pre\n",
      "tensor([[[-4.8631, -3.8628, -5.3428],\n",
      "         [-1.8755,  3.3155, -1.5033],\n",
      "         [ 1.0939,  2.5967, -5.1203]],\n",
      "\n",
      "        [[-5.3843, -5.5568, -5.6488],\n",
      "         [ 3.1795,  0.8062, -2.7006],\n",
      "         [ 0.5000,  0.9083, -5.8611]],\n",
      "\n",
      "        [[-4.7939, -4.9190, -5.1121],\n",
      "         [-0.5319,  3.5986, -0.0075],\n",
      "         [ 5.5063,  1.2976,  5.1787]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.ln1.hook_scale\n",
      "tensor([[[112.0038],\n",
      "         [  4.7210],\n",
      "         [  4.7291]],\n",
      "\n",
      "        [[109.7592],\n",
      "         [  4.5688],\n",
      "         [  5.0604]],\n",
      "\n",
      "        [[111.9490],\n",
      "         [  4.8446],\n",
      "         [  5.0498]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.ln1.hook_normalized\n",
      "tensor([[[-0.0434, -0.0345, -0.0477],\n",
      "         [-0.3973,  0.7023, -0.3184],\n",
      "         [ 0.2313,  0.5491, -1.0827]],\n",
      "\n",
      "        [[-0.0491, -0.0506, -0.0515],\n",
      "         [ 0.6959,  0.1765, -0.5911],\n",
      "         [ 0.0988,  0.1795, -1.1582]],\n",
      "\n",
      "        [[-0.0428, -0.0439, -0.0457],\n",
      "         [-0.1098,  0.7428, -0.0015],\n",
      "         [ 1.0904,  0.2570,  1.0255]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.ln1.hook_scale\n",
      "tensor([[[112.0038],\n",
      "         [  4.7210],\n",
      "         [  4.7291]],\n",
      "\n",
      "        [[109.7592],\n",
      "         [  4.5688],\n",
      "         [  5.0604]],\n",
      "\n",
      "        [[111.9490],\n",
      "         [  4.8446],\n",
      "         [  5.0498]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.ln1.hook_normalized\n",
      "tensor([[[-0.0434, -0.0345, -0.0477],\n",
      "         [-0.3973,  0.7023, -0.3184],\n",
      "         [ 0.2313,  0.5491, -1.0827]],\n",
      "\n",
      "        [[-0.0491, -0.0506, -0.0515],\n",
      "         [ 0.6959,  0.1765, -0.5911],\n",
      "         [ 0.0988,  0.1795, -1.1582]],\n",
      "\n",
      "        [[-0.0428, -0.0439, -0.0457],\n",
      "         [-0.1098,  0.7428, -0.0015],\n",
      "         [ 1.0904,  0.2570,  1.0255]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.ln1.hook_scale\n",
      "tensor([[[112.0038],\n",
      "         [  4.7210],\n",
      "         [  4.7291]],\n",
      "\n",
      "        [[109.7592],\n",
      "         [  4.5688],\n",
      "         [  5.0604]],\n",
      "\n",
      "        [[111.9490],\n",
      "         [  4.8446],\n",
      "         [  5.0498]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.ln1.hook_normalized\n",
      "tensor([[[-0.0434, -0.0345, -0.0477],\n",
      "         [-0.3973,  0.7023, -0.3184],\n",
      "         [ 0.2313,  0.5491, -1.0827]],\n",
      "\n",
      "        [[-0.0491, -0.0506, -0.0515],\n",
      "         [ 0.6959,  0.1765, -0.5911],\n",
      "         [ 0.0988,  0.1795, -1.1582]],\n",
      "\n",
      "        [[-0.0428, -0.0439, -0.0457],\n",
      "         [-0.1098,  0.7428, -0.0015],\n",
      "         [ 1.0904,  0.2570,  1.0255]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.attn.hook_q\n",
      "tensor([[[[ 0.3278,  0.2712, -0.0984],\n",
      "          [-0.2147,  0.2004,  0.0038],\n",
      "          [-0.1605,  0.0650,  0.2036]],\n",
      "\n",
      "         [[ 0.2602, -1.2450,  0.3617],\n",
      "          [-0.8004,  1.3157,  0.1516],\n",
      "          [-0.7553,  1.6830,  1.2715]],\n",
      "\n",
      "         [[-0.1180, -0.0702, -0.1175],\n",
      "          [-1.0546,  1.1623,  0.7925],\n",
      "          [-1.0254,  1.2192,  0.8186]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3161,  0.2604, -0.0997],\n",
      "          [-0.1997,  0.2179,  0.0084],\n",
      "          [-0.1538,  0.0662,  0.2015]],\n",
      "\n",
      "         [[-0.2087, -1.1566, -0.2640],\n",
      "          [-1.5411,  0.4298,  0.3579],\n",
      "          [-1.4819,  0.4176,  0.4216]],\n",
      "\n",
      "         [[ 0.9477, -0.5407, -0.4747],\n",
      "          [-0.7458,  0.5986,  0.9424],\n",
      "          [-0.5158,  0.4467,  1.1119]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3128,  0.2592, -0.0910],\n",
      "          [-0.2245,  0.1989,  0.0066],\n",
      "          [-0.1603,  0.0711,  0.2037]],\n",
      "\n",
      "         [[ 0.9689, -0.6607,  0.3506],\n",
      "          [-0.9504,  0.9101,  0.7670],\n",
      "          [-1.2250,  1.1440,  1.3127]],\n",
      "\n",
      "         [[ 0.5331, -1.0034, -0.5216],\n",
      "          [ 0.1866,  1.6421,  1.1326],\n",
      "          [-0.6212,  1.1898,  0.0973]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.attn.hook_k\n",
      "tensor([[[[ 0.0471, -0.2645, -0.4356],\n",
      "          [-0.2821,  0.1591,  0.1177],\n",
      "          [-1.2388, -0.0988,  0.5546]],\n",
      "\n",
      "         [[ 0.2362,  0.0683, -1.8083],\n",
      "          [ 0.1906,  0.5326, -0.3916],\n",
      "          [ 1.8148,  1.6472, -0.6659]],\n",
      "\n",
      "         [[-0.8489, -0.1872, -0.7026],\n",
      "          [ 1.2288,  1.3036,  1.5583],\n",
      "          [ 1.3943,  3.7199,  1.1073]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0461, -0.2513, -0.4378],\n",
      "          [-0.2755,  0.1585,  0.1180],\n",
      "          [-1.2081, -0.0969,  0.5663]],\n",
      "\n",
      "         [[ 0.3089, -0.4334, -0.6352],\n",
      "          [-1.1527, -0.1154, -0.1249],\n",
      "          [ 2.2153,  2.5744,  0.0980]],\n",
      "\n",
      "         [[ 0.8511,  0.1050, -1.7040],\n",
      "          [-1.3388,  0.8558, -0.5540],\n",
      "          [ 2.3142,  2.0453, -1.3947]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0350, -0.2577, -0.4440],\n",
      "          [-0.2835,  0.1529,  0.1104],\n",
      "          [-1.2291, -0.0908,  0.5545]],\n",
      "\n",
      "         [[ 0.8543, -0.7851, -0.6664],\n",
      "          [-0.3350,  0.5371, -0.3411],\n",
      "          [ 0.7286,  2.1354, -0.9219]],\n",
      "\n",
      "         [[ 1.6164, -0.2064,  0.2526],\n",
      "          [-1.0000,  0.3533, -1.8739],\n",
      "          [ 1.4930,  0.9309,  0.8319]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.attn.hook_v\n",
      "tensor([[[[-0.0364, -0.1416,  0.0992],\n",
      "          [ 0.0285, -0.0821, -0.0478],\n",
      "          [ 0.0541, -0.0381, -0.0811]],\n",
      "\n",
      "         [[-0.8540, -0.4220,  0.1589],\n",
      "          [-0.6130,  0.0291, -1.1006],\n",
      "          [ 1.1449, -0.7966, -1.4918]],\n",
      "\n",
      "         [[-0.2207,  0.0285, -0.5583],\n",
      "          [ 2.2691,  0.7784, -0.7838],\n",
      "          [ 0.0941,  0.0915, -1.4730]]],\n",
      "\n",
      "\n",
      "        [[[-0.0542, -0.1408,  0.1377],\n",
      "          [ 0.0203, -0.0894, -0.0399],\n",
      "          [ 0.0598, -0.0300, -0.0717]],\n",
      "\n",
      "         [[-1.0478, -0.9245,  2.4404],\n",
      "          [-0.5359,  1.0732, -0.3547],\n",
      "          [ 1.0237, -0.9937,  0.6550]],\n",
      "\n",
      "         [[-0.1346, -1.1915,  0.2309],\n",
      "          [ 0.2517,  0.2829, -0.2077],\n",
      "          [ 0.3126,  0.1849,  0.6500]]],\n",
      "\n",
      "\n",
      "        [[[-0.0533, -0.1504,  0.1064],\n",
      "          [ 0.0312, -0.0776, -0.0440],\n",
      "          [ 0.0388, -0.0263, -0.0779]],\n",
      "\n",
      "         [[-1.1635,  0.1674, -1.3946],\n",
      "          [ 0.5412,  0.7433,  0.5045],\n",
      "          [ 1.3028, -1.0626, -0.7802]],\n",
      "\n",
      "         [[-0.9872,  0.2459, -0.4189],\n",
      "          [-2.0377, -0.6349, -1.8266],\n",
      "          [ 0.9161, -2.2595, -0.1767]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.attn.hook_attn_scores\n",
      "tensor([[[[ 1.2201e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.6860e+00,  4.1153e-02, -1.0000e+05],\n",
      "          [ 2.3754e+00, -6.9136e-02, -2.2702e-01]],\n",
      "\n",
      "         [[ 1.2119e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.7938e+00, -2.1871e+00, -1.0000e+05],\n",
      "          [ 3.4770e+00, -3.1083e+00, -9.6075e-01]],\n",
      "\n",
      "         [[ 8.0463e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.7487e+00, -6.9175e-01, -1.0000e+05],\n",
      "          [ 2.5829e+00, -7.1739e-01, -1.5436e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2260e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.8531e+00, -1.5899e-01, -1.0000e+05],\n",
      "          [ 2.5474e+00, -1.6993e+00, -5.5122e-01]],\n",
      "\n",
      "         [[ 1.2395e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.8745e+00, -2.9677e+00, -1.0000e+05],\n",
      "          [ 3.2798e+00, -2.6429e+00, -8.7977e-01]],\n",
      "\n",
      "         [[ 8.1528e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.8879e+00, -9.8065e-01, -1.0000e+05],\n",
      "          [ 2.4603e+00, -1.1482e+00, -1.0354e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2285e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.8970e+00,  1.1565e+00, -1.0000e+05],\n",
      "          [ 2.6470e+00,  9.5777e-01, -1.0941e-01]],\n",
      "\n",
      "         [[ 1.2088e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.3320e+00, -1.9527e+00, -1.0000e+05],\n",
      "          [ 4.1237e+00, -1.4710e+00, -2.8925e+00]],\n",
      "\n",
      "         [[ 8.1454e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.0416e+00, -5.1865e-01, -1.0000e+05],\n",
      "          [ 2.7423e+00,  3.4689e-01, -1.5749e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.attn.hook_pattern\n",
      "tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.3369e-01, 6.6309e-02, 0.0000e+00],\n",
      "          [8.6142e-01, 7.4746e-02, 6.3830e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.9748e-01, 2.5202e-03, 0.0000e+00],\n",
      "          [9.8697e-01, 1.3626e-03, 1.1669e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.6895e-01, 3.1054e-02, 0.0000e+00],\n",
      "          [9.4966e-01, 3.5017e-02, 1.5327e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.5312e-01, 4.6882e-02, 0.0000e+00],\n",
      "          [9.4391e-01, 1.3509e-02, 4.2581e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.9893e-01, 1.0666e-03, 0.0000e+00],\n",
      "          [9.8204e-01, 2.6298e-03, 1.5333e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.7954e-01, 2.0461e-02, 0.0000e+00],\n",
      "          [9.4570e-01, 2.5620e-02, 2.8680e-02]]],\n",
      "\n",
      "\n",
      "        [[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [8.5075e-01, 1.4925e-01, 0.0000e+00],\n",
      "          [8.0116e-01, 1.4795e-01, 5.0890e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.9496e-01, 5.0431e-03, 0.0000e+00],\n",
      "          [9.9541e-01, 3.7004e-03, 8.9310e-04]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.7235e-01, 2.7646e-02, 0.0000e+00],\n",
      "          [8.7247e-01, 7.9512e-02, 4.8016e-02]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.attn.hook_z\n",
      "tensor([[[[-0.0364, -0.1416,  0.0992],\n",
      "          [ 0.0285, -0.0821, -0.0478],\n",
      "          [ 0.0541, -0.0381, -0.0811]],\n",
      "\n",
      "         [[-0.0906, -0.1602,  0.1031],\n",
      "          [ 0.0268, -0.0819, -0.0504],\n",
      "          [ 0.0880, -0.0617, -0.1249]],\n",
      "\n",
      "         [[-0.1093, -0.1517,  0.0617],\n",
      "          [ 0.0537, -0.0719, -0.0578],\n",
      "          [ 0.0929, -0.0627, -0.1519]]],\n",
      "\n",
      "\n",
      "        [[[-0.0542, -0.1408,  0.1377],\n",
      "          [ 0.0203, -0.0894, -0.0399],\n",
      "          [ 0.0598, -0.0300, -0.0717]],\n",
      "\n",
      "         [[-0.1007, -0.1775,  0.2457],\n",
      "          [ 0.0197, -0.0882, -0.0402],\n",
      "          [ 0.0795, -0.0498, -0.0568]],\n",
      "\n",
      "         [[-0.0710, -0.1961,  0.1728],\n",
      "          [ 0.0223, -0.0806, -0.0433],\n",
      "          [ 0.0917, -0.0486, -0.0324]]],\n",
      "\n",
      "\n",
      "        [[[-0.0533, -0.1504,  0.1064],\n",
      "          [ 0.0312, -0.0776, -0.0440],\n",
      "          [ 0.0388, -0.0263, -0.0779]],\n",
      "\n",
      "         [[-0.2190, -0.1030, -0.1176],\n",
      "          [ 0.0338, -0.0735, -0.0413],\n",
      "          [ 0.0738, -0.0549, -0.0974]],\n",
      "\n",
      "         [[-0.2651, -0.0832, -0.1424],\n",
      "          [ 0.0313, -0.0751, -0.0436],\n",
      "          [ 0.1815, -0.2159, -0.1385]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.hook_attn_out\n",
      "tensor([[[-0.0800,  0.1017, -0.0137],\n",
      "         [-0.2000,  0.2286,  0.0314],\n",
      "         [-0.1678,  0.2785, -0.0490]],\n",
      "\n",
      "        [[-0.0790, -0.0010, -0.0467],\n",
      "         [ 0.0083, -0.1150,  0.0488],\n",
      "         [-0.0400, -0.3450,  0.0506]],\n",
      "\n",
      "        [[-0.0977,  0.0893, -0.0256],\n",
      "         [-0.0733,  0.1469, -0.2443],\n",
      "         [-0.0954,  0.1076, -0.2536]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.hook_resid_mid\n",
      "tensor([[[-4.9431, -3.7611, -5.3566],\n",
      "         [-2.0755,  3.5440, -1.4719],\n",
      "         [ 0.9261,  2.8752, -5.1693]],\n",
      "\n",
      "        [[-5.4633, -5.5578, -5.6954],\n",
      "         [ 3.1878,  0.6913, -2.6518],\n",
      "         [ 0.4599,  0.5634, -5.8105]],\n",
      "\n",
      "        [[-4.8917, -4.8297, -5.1378],\n",
      "         [-0.6052,  3.7455, -0.2518],\n",
      "         [ 5.4109,  1.4052,  4.9251]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.ln2.hook_scale\n",
      "tensor([[[112.0608],\n",
      "         [  4.8742],\n",
      "         [  5.0704]],\n",
      "\n",
      "        [[109.8181],\n",
      "         [  4.7427],\n",
      "         [  5.4013]],\n",
      "\n",
      "        [[112.0069],\n",
      "         [  4.9851],\n",
      "         [  5.1992]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.ln2.hook_normalized\n",
      "tensor([[[-0.0441, -0.0336, -0.0478],\n",
      "         [-0.4258,  0.7271, -0.3020],\n",
      "         [ 0.1827,  0.5671, -1.0195]],\n",
      "\n",
      "        [[-0.0497, -0.0506, -0.0519],\n",
      "         [ 0.6721,  0.1458, -0.5591],\n",
      "         [ 0.0852,  0.1043, -1.0758]],\n",
      "\n",
      "        [[-0.0437, -0.0431, -0.0459],\n",
      "         [-0.1214,  0.7513, -0.0505],\n",
      "         [ 1.0407,  0.2703,  0.9473]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.mlp.hook_pre\n",
      "tensor([[[-1.9722,  0.1237, -1.4596],\n",
      "         [-0.8219, -0.9951, -1.2348],\n",
      "         [-0.5305, -1.2607, -0.9971]],\n",
      "\n",
      "        [[-1.9595,  0.1337, -1.4580],\n",
      "         [-1.0228, -1.5604, -1.2473],\n",
      "         [-2.3938, -0.8553, -1.1443]],\n",
      "\n",
      "        [[-1.9800,  0.1261, -1.4626],\n",
      "         [-1.1946, -0.8787, -0.8839],\n",
      "         [-1.0155, -0.7252,  0.0991]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.mlp.hook_post\n",
      "tensor([[[-0.0478,  0.0680, -0.1056],\n",
      "         [-0.1690, -0.1592, -0.1341],\n",
      "         [-0.1580, -0.1310, -0.1590]],\n",
      "\n",
      "        [[-0.0490,  0.0739, -0.1058],\n",
      "         [-0.1569, -0.0928, -0.1326],\n",
      "         [-0.0196, -0.1679, -0.1447]],\n",
      "\n",
      "        [[-0.0471,  0.0694, -0.1052],\n",
      "         [-0.1389, -0.1669, -0.1666],\n",
      "         [-0.1575, -0.1699,  0.0535]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.hook_mlp_out\n",
      "tensor([[[-0.0060, -0.0293, -0.3096],\n",
      "         [-0.3205, -0.2727, -0.5023],\n",
      "         [ 1.5714,  0.3708,  0.7015]],\n",
      "\n",
      "        [[-0.0332, -0.0533, -0.2894],\n",
      "         [-0.4734, -0.4635, -0.7952],\n",
      "         [-0.9028, -0.4587, -1.0750]],\n",
      "\n",
      "        [[-0.0406, -0.0047, -0.2948],\n",
      "         [-0.7067,  0.6718, -0.6094],\n",
      "         [ 0.6201,  0.1194, -0.1129]]], grad_fn=<SliceBackward0>)\n",
      "blocks.9.hook_resid_post\n",
      "tensor([[[-4.9491, -3.7904, -5.6661],\n",
      "         [-2.3959,  3.2713, -1.9742],\n",
      "         [ 2.4975,  3.2460, -4.4678]],\n",
      "\n",
      "        [[-5.4966, -5.6111, -5.9848],\n",
      "         [ 2.7144,  0.2277, -3.4470],\n",
      "         [-0.4429,  0.1047, -6.8855]],\n",
      "\n",
      "        [[-4.9322, -4.8343, -5.4326],\n",
      "         [-1.3118,  4.4173, -0.8612],\n",
      "         [ 6.0310,  1.5247,  4.8123]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.hook_resid_pre\n",
      "tensor([[[-4.9491, -3.7904, -5.6661],\n",
      "         [-2.3959,  3.2713, -1.9742],\n",
      "         [ 2.4975,  3.2460, -4.4678]],\n",
      "\n",
      "        [[-5.4966, -5.6111, -5.9848],\n",
      "         [ 2.7144,  0.2277, -3.4470],\n",
      "         [-0.4429,  0.1047, -6.8855]],\n",
      "\n",
      "        [[-4.9322, -4.8343, -5.4326],\n",
      "         [-1.3118,  4.4173, -0.8612],\n",
      "         [ 6.0310,  1.5247,  4.8123]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.ln1.hook_scale\n",
      "tensor([[[112.3773],\n",
      "         [  5.4134],\n",
      "         [  5.9020]],\n",
      "\n",
      "        [[110.0837],\n",
      "         [  5.2592],\n",
      "         [  5.7790]],\n",
      "\n",
      "        [[112.3120],\n",
      "         [  5.4999],\n",
      "         [  6.1085]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.ln1.hook_normalized\n",
      "tensor([[[-0.0440, -0.0337, -0.0504],\n",
      "         [-0.4426,  0.6043, -0.3647],\n",
      "         [ 0.4232,  0.5500, -0.7570]],\n",
      "\n",
      "        [[-0.0499, -0.0510, -0.0544],\n",
      "         [ 0.5161,  0.0433, -0.6554],\n",
      "         [-0.0766,  0.0181, -1.1915]],\n",
      "\n",
      "        [[-0.0439, -0.0430, -0.0484],\n",
      "         [-0.2385,  0.8032, -0.1566],\n",
      "         [ 0.9873,  0.2496,  0.7878]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.ln1.hook_scale\n",
      "tensor([[[112.3773],\n",
      "         [  5.4134],\n",
      "         [  5.9020]],\n",
      "\n",
      "        [[110.0837],\n",
      "         [  5.2592],\n",
      "         [  5.7790]],\n",
      "\n",
      "        [[112.3120],\n",
      "         [  5.4999],\n",
      "         [  6.1085]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.ln1.hook_normalized\n",
      "tensor([[[-0.0440, -0.0337, -0.0504],\n",
      "         [-0.4426,  0.6043, -0.3647],\n",
      "         [ 0.4232,  0.5500, -0.7570]],\n",
      "\n",
      "        [[-0.0499, -0.0510, -0.0544],\n",
      "         [ 0.5161,  0.0433, -0.6554],\n",
      "         [-0.0766,  0.0181, -1.1915]],\n",
      "\n",
      "        [[-0.0439, -0.0430, -0.0484],\n",
      "         [-0.2385,  0.8032, -0.1566],\n",
      "         [ 0.9873,  0.2496,  0.7878]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.ln1.hook_scale\n",
      "tensor([[[112.3773],\n",
      "         [  5.4134],\n",
      "         [  5.9020]],\n",
      "\n",
      "        [[110.0837],\n",
      "         [  5.2592],\n",
      "         [  5.7790]],\n",
      "\n",
      "        [[112.3120],\n",
      "         [  5.4999],\n",
      "         [  6.1085]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.ln1.hook_normalized\n",
      "tensor([[[-0.0440, -0.0337, -0.0504],\n",
      "         [-0.4426,  0.6043, -0.3647],\n",
      "         [ 0.4232,  0.5500, -0.7570]],\n",
      "\n",
      "        [[-0.0499, -0.0510, -0.0544],\n",
      "         [ 0.5161,  0.0433, -0.6554],\n",
      "         [-0.0766,  0.0181, -1.1915]],\n",
      "\n",
      "        [[-0.0439, -0.0430, -0.0484],\n",
      "         [-0.2385,  0.8032, -0.1566],\n",
      "         [ 0.9873,  0.2496,  0.7878]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.attn.hook_q\n",
      "tensor([[[[ 0.1341,  0.6103, -0.4916],\n",
      "          [ 0.3913, -0.5118,  0.1940],\n",
      "          [ 0.1610,  0.4317,  0.1381]],\n",
      "\n",
      "         [[-0.6464,  0.4796, -1.4067],\n",
      "          [ 1.9648, -2.8919, -0.6606],\n",
      "          [ 1.2678, -0.2020,  0.6733]],\n",
      "\n",
      "         [[-0.7611,  0.6687, -0.9821],\n",
      "          [ 2.1075, -2.8000, -0.4624],\n",
      "          [ 1.9651, -0.0674,  0.1517]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1666,  0.5850, -0.5179],\n",
      "          [ 0.3983, -0.4742,  0.2169],\n",
      "          [ 0.1579,  0.4370,  0.1585]],\n",
      "\n",
      "         [[ 0.6345, -0.5333, -0.0527],\n",
      "          [ 0.0205, -0.8112,  1.4835],\n",
      "          [ 1.0035,  0.7700,  0.3946]],\n",
      "\n",
      "         [[-0.1628,  0.8749, -1.3277],\n",
      "          [-0.1451, -1.3866, -1.9146],\n",
      "          [ 0.7416,  0.0148,  0.3397]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1613,  0.6033, -0.4910],\n",
      "          [ 0.3918, -0.4991,  0.1810],\n",
      "          [ 0.1485,  0.4201,  0.1492]],\n",
      "\n",
      "         [[ 0.4856,  0.4592, -1.0682],\n",
      "          [ 1.6958, -1.9629, -1.3959],\n",
      "          [ 0.9810, -0.0648,  1.0079]],\n",
      "\n",
      "         [[ 0.5566,  0.2479, -0.1365],\n",
      "          [-0.8236, -0.5040,  0.3233],\n",
      "          [ 1.7531,  0.0330, -1.3927]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.attn.hook_k\n",
      "tensor([[[[-0.5260,  0.4777, -0.8581],\n",
      "          [ 0.8556, -2.0830,  0.1766],\n",
      "          [ 1.0213,  0.3969, -0.1779]],\n",
      "\n",
      "         [[ 0.4253,  0.2799, -1.0986],\n",
      "          [ 0.8263,  1.5191,  2.3880],\n",
      "          [-0.3125,  0.2008, -0.1373]],\n",
      "\n",
      "         [[-0.0307, -0.1518, -1.1775],\n",
      "          [ 2.7861,  0.6962,  0.4826],\n",
      "          [-0.3926, -1.5176,  0.2548]]],\n",
      "\n",
      "\n",
      "        [[[-0.5190,  0.4926, -0.8617],\n",
      "          [ 0.8403, -2.0569,  0.1685],\n",
      "          [ 0.9824,  0.3793, -0.1739]],\n",
      "\n",
      "         [[ 0.7467,  0.5148, -2.0115],\n",
      "          [ 1.2133,  2.3476,  0.8237],\n",
      "          [-0.7606,  0.4243, -0.0993]],\n",
      "\n",
      "         [[ 0.2561,  1.3763, -0.4153],\n",
      "          [ 0.7803,  2.5617,  0.6219],\n",
      "          [-0.2374,  0.0312, -0.1348]]],\n",
      "\n",
      "\n",
      "        [[[-0.5353,  0.4926, -0.8576],\n",
      "          [ 0.8533, -2.0684,  0.1580],\n",
      "          [ 1.0082,  0.3895, -0.1581]],\n",
      "\n",
      "         [[ 0.5371,  1.5796,  0.4609],\n",
      "          [ 1.0713,  1.0794,  1.5438],\n",
      "          [-0.5080, -0.0238,  0.2184]],\n",
      "\n",
      "         [[ 0.1052,  2.2175, -0.1143],\n",
      "          [ 1.6053,  0.4281, -0.0028],\n",
      "          [-0.5848,  0.2103,  0.7114]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.attn.hook_v\n",
      "tensor([[[[-1.1714e-01, -7.5734e-02,  3.5467e-03],\n",
      "          [-2.1413e-02,  5.0377e-02,  9.0172e-02],\n",
      "          [ 1.0071e-01,  1.1521e-01,  7.9155e-02]],\n",
      "\n",
      "         [[ 1.3546e+00,  8.0940e-01,  8.0513e-01],\n",
      "          [ 1.2840e+00, -7.8682e-01,  8.0065e-01],\n",
      "          [ 2.3696e+00,  9.2289e-01,  2.2844e-01]],\n",
      "\n",
      "         [[ 8.3663e-01, -3.8487e-01, -6.8672e-01],\n",
      "          [ 1.7454e+00,  2.4982e-01,  1.3148e+00],\n",
      "          [ 1.2257e+00, -2.2621e-01,  1.8314e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.0875e-01, -3.9384e-02,  6.9472e-04],\n",
      "          [ 8.6833e-03,  5.1176e-02,  1.2147e-01],\n",
      "          [ 8.7709e-02,  1.5326e-01,  2.8195e-02]],\n",
      "\n",
      "         [[ 3.2615e-01, -1.5389e-01,  2.0520e+00],\n",
      "          [-8.9794e-02,  1.4203e+00,  8.4899e-01],\n",
      "          [ 1.1420e+00, -7.8584e-01, -5.0211e-01]],\n",
      "\n",
      "         [[ 1.3402e-01,  3.5514e-01,  9.0624e-01],\n",
      "          [-1.2186e+00, -5.4813e-01,  8.7866e-02],\n",
      "          [ 1.6398e+00, -1.0210e-01,  1.9701e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0201e-01, -7.9437e-02,  3.3266e-03],\n",
      "          [-1.1875e-02,  6.3205e-02,  8.4451e-02],\n",
      "          [ 9.2757e-02,  1.2214e-01,  7.5003e-02]],\n",
      "\n",
      "         [[ 8.8579e-01,  1.2307e+00, -2.2651e-01],\n",
      "          [ 1.3327e+00,  8.3314e-01, -5.6553e-01],\n",
      "          [-7.0729e-01, -6.2183e-01,  1.4607e-01]],\n",
      "\n",
      "         [[-1.1568e+00, -4.0647e-01,  1.8761e+00],\n",
      "          [-1.5927e+00,  5.4169e-01,  5.0607e-01],\n",
      "          [ 6.7423e-01,  1.8994e+00, -2.2870e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.attn.hook_attn_scores\n",
      "tensor([[[[ 1.8823e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.1658e+00,  2.7131e-01, -1.0000e+05],\n",
      "          [ 2.8618e+00,  2.3472e-01, -7.2579e-01]],\n",
      "\n",
      "         [[ 2.1220e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.4510e+00, -4.8233e-01, -1.0000e+05],\n",
      "          [ 4.8828e+00,  5.0339e-01,  8.9107e-01]],\n",
      "\n",
      "         [[ 2.0096e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.7920e+00,  3.2770e-02, -1.0000e+05],\n",
      "          [ 3.5561e+00,  2.9654e-01, -3.8537e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8721e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.7343e+00, -3.2486e-02, -1.0000e+05],\n",
      "          [ 2.5728e+00,  3.1915e-01, -9.7486e-01]],\n",
      "\n",
      "         [[ 2.1395e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.4479e+00, -5.9105e-02, -1.0000e+05],\n",
      "          [ 4.0983e+00,  2.9736e-01,  6.9405e-01]],\n",
      "\n",
      "         [[ 2.0190e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.8837e+00, -9.2887e-01, -1.0000e+05],\n",
      "          [ 3.2444e+00, -4.9661e-01,  9.3583e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8909e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.0617e+00,  3.5429e-01, -1.0000e+05],\n",
      "          [ 2.9530e+00,  5.5268e-01, -7.7507e-01]],\n",
      "\n",
      "         [[ 2.1204e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 4.4640e+00,  4.1499e-01, -1.0000e+05],\n",
      "          [ 4.9368e+00,  1.2292e+00, -3.6752e-01]],\n",
      "\n",
      "         [[ 2.0146e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.5971e+00, -1.6192e-01, -1.0000e+05],\n",
      "          [ 4.4292e+00, -1.3448e+00, -2.0149e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.attn.hook_pattern\n",
      "tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9476, 0.0524, 0.0000],\n",
      "          [0.9091, 0.0657, 0.0252]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9928, 0.0072, 0.0000],\n",
      "          [0.9699, 0.0122, 0.0179]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9772, 0.0228, 0.0000],\n",
      "          [0.9382, 0.0360, 0.0258]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9409, 0.0591, 0.0000],\n",
      "          [0.8820, 0.0926, 0.0254]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9891, 0.0109, 0.0000],\n",
      "          [0.9473, 0.0212, 0.0315]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9919, 0.0081, 0.0000],\n",
      "          [0.8904, 0.0211, 0.0885]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.9375, 0.0625, 0.0000],\n",
      "          [0.8971, 0.0814, 0.0216]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9829, 0.0171, 0.0000],\n",
      "          [0.9713, 0.0238, 0.0048]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9772, 0.0228, 0.0000],\n",
      "          [0.9953, 0.0031, 0.0016]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.attn.hook_z\n",
      "tensor([[[[-0.1171, -0.0757,  0.0035],\n",
      "          [-0.0214,  0.0504,  0.0902],\n",
      "          [ 0.1007,  0.1152,  0.0792]],\n",
      "\n",
      "         [[-0.0400, -0.0293,  0.0456],\n",
      "          [-0.0121,  0.0444,  0.0953],\n",
      "          [ 0.1524,  0.1336,  0.0826]],\n",
      "\n",
      "         [[ 0.0036, -0.0253,  0.0389],\n",
      "          [ 0.0261,  0.0438,  0.1207],\n",
      "          [ 0.2114,  0.1355,  0.1297]]],\n",
      "\n",
      "\n",
      "        [[[-0.1087, -0.0394,  0.0007],\n",
      "          [ 0.0087,  0.0512,  0.1215],\n",
      "          [ 0.0877,  0.1533,  0.0282]],\n",
      "\n",
      "         [[-0.0830, -0.0462,  0.1220],\n",
      "          [ 0.0076,  0.0661,  0.1294],\n",
      "          [ 0.0962,  0.1457,  0.0239]],\n",
      "\n",
      "         [[-0.0623, -0.0400,  0.2137],\n",
      "          [-0.0320,  0.0613,  0.1358],\n",
      "          [ 0.2473,  0.1108,  0.0319]]],\n",
      "\n",
      "\n",
      "        [[[-0.1020, -0.0794,  0.0033],\n",
      "          [-0.0119,  0.0632,  0.0845],\n",
      "          [ 0.0928,  0.1221,  0.0750]],\n",
      "\n",
      "         [[-0.0402,  0.0025, -0.0110],\n",
      "          [ 0.0112,  0.0764,  0.0733],\n",
      "          [ 0.0745,  0.1052,  0.0766]],\n",
      "\n",
      "         [[-0.0444,  0.0201,  0.0250],\n",
      "          [ 0.0125,  0.0839,  0.0710],\n",
      "          [ 0.0912,  0.1226,  0.0747]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.hook_attn_out\n",
      "tensor([[[-0.0200,  0.0414, -0.0638],\n",
      "         [-0.1475,  0.0981, -0.0493],\n",
      "         [-0.3667,  0.0986, -0.0864]],\n",
      "\n",
      "        [[-0.0207,  0.0379, -0.0805],\n",
      "         [ 0.0475,  0.1704, -0.1034],\n",
      "         [ 0.2839,  0.1182, -0.6222]],\n",
      "\n",
      "        [[-0.0183,  0.0898, -0.0461],\n",
      "         [-0.0775,  0.2274, -0.2101],\n",
      "         [ 0.0085,  0.0899,  0.0184]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.hook_resid_mid\n",
      "tensor([[[-4.9691, -3.7490, -5.7299],\n",
      "         [-2.5434,  3.3694, -2.0235],\n",
      "         [ 2.1308,  3.3446, -4.5542]],\n",
      "\n",
      "        [[-5.5173, -5.5731, -6.0653],\n",
      "         [ 2.7619,  0.3982, -3.5504],\n",
      "         [-0.1590,  0.2229, -7.5077]],\n",
      "\n",
      "        [[-4.9506, -4.7445, -5.4786],\n",
      "         [-1.3894,  4.6447, -1.0712],\n",
      "         [ 6.0395,  1.6146,  4.8307]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.ln2.hook_scale\n",
      "tensor([[[112.4167],\n",
      "         [  5.6827],\n",
      "         [  6.3694]],\n",
      "\n",
      "        [[110.1203],\n",
      "         [  5.4632],\n",
      "         [  6.4646]],\n",
      "\n",
      "        [[112.3529],\n",
      "         [  5.8728],\n",
      "         [  6.2981]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.ln2.hook_normalized\n",
      "tensor([[[-0.0442, -0.0333, -0.0510],\n",
      "         [-0.4476,  0.5929, -0.3561],\n",
      "         [ 0.3345,  0.5251, -0.7150]],\n",
      "\n",
      "        [[-0.0501, -0.0506, -0.0551],\n",
      "         [ 0.5055,  0.0729, -0.6499],\n",
      "         [-0.0246,  0.0345, -1.1613]],\n",
      "\n",
      "        [[-0.0441, -0.0422, -0.0488],\n",
      "         [-0.2366,  0.7909, -0.1824],\n",
      "         [ 0.9589,  0.2564,  0.7670]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.mlp.hook_pre\n",
      "tensor([[[-0.8481, -0.0492, -0.5315],\n",
      "         [-0.4844, -0.7903, -0.6881],\n",
      "         [ 0.9141, -0.8037, -0.8871]],\n",
      "\n",
      "        [[-0.8424, -0.0514, -0.5319],\n",
      "         [-0.1272,  0.0531, -0.5435],\n",
      "         [-0.3591,  0.5291, -0.5110]],\n",
      "\n",
      "        [[-0.8539, -0.0439, -0.5305],\n",
      "         [ 0.0357, -0.0231, -0.9902],\n",
      "         [-1.3378, -0.2683, -1.0792]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.mlp.hook_post\n",
      "tensor([[[-0.1682, -0.0236, -0.1582],\n",
      "         [-0.1521, -0.1697, -0.1691],\n",
      "         [ 0.7491, -0.1695, -0.1665]],\n",
      "\n",
      "        [[-0.1684, -0.0246, -0.1582],\n",
      "         [-0.0571,  0.0277, -0.1595],\n",
      "         [-0.1292,  0.3712, -0.1557]],\n",
      "\n",
      "        [[-0.1680, -0.0212, -0.1580],\n",
      "         [ 0.0184, -0.0113, -0.1596],\n",
      "         [-0.1213, -0.1058, -0.1515]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.hook_mlp_out\n",
      "tensor([[[-0.1208,  0.1385, -0.3249],\n",
      "         [ 0.0312,  0.8565, -0.4478],\n",
      "         [-1.8694, -0.3864, -1.7451]],\n",
      "\n",
      "        [[-0.0726,  0.0435, -0.2563],\n",
      "         [ 0.7496,  0.4341,  0.6529],\n",
      "         [-0.4511,  0.1433, -0.5775]],\n",
      "\n",
      "        [[-0.1341,  0.0925, -0.2707],\n",
      "         [-0.7697, -0.5962,  0.1698],\n",
      "         [ 1.3760,  0.7505,  1.0121]]], grad_fn=<SliceBackward0>)\n",
      "blocks.10.hook_resid_post\n",
      "tensor([[[-5.0899, -3.6105, -6.0548],\n",
      "         [-2.5122,  4.2259, -2.4712],\n",
      "         [ 0.2615,  2.9582, -6.2993]],\n",
      "\n",
      "        [[-5.5899, -5.5297, -6.3216],\n",
      "         [ 3.5115,  0.8323, -2.8975],\n",
      "         [-0.6100,  0.3661, -8.0852]],\n",
      "\n",
      "        [[-5.0846, -4.6520, -5.7494],\n",
      "         [-2.1591,  4.0485, -0.9015],\n",
      "         [ 7.4155,  2.3651,  5.8428]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.hook_resid_pre\n",
      "tensor([[[-5.0899, -3.6105, -6.0548],\n",
      "         [-2.5122,  4.2259, -2.4712],\n",
      "         [ 0.2615,  2.9582, -6.2993]],\n",
      "\n",
      "        [[-5.5899, -5.5297, -6.3216],\n",
      "         [ 3.5115,  0.8323, -2.8975],\n",
      "         [-0.6100,  0.3661, -8.0852]],\n",
      "\n",
      "        [[-5.0846, -4.6520, -5.7494],\n",
      "         [-2.1591,  4.0485, -0.9015],\n",
      "         [ 7.4155,  2.3651,  5.8428]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.ln1.hook_scale\n",
      "tensor([[[112.4229],\n",
      "         [  8.4704],\n",
      "         [  9.3139]],\n",
      "\n",
      "        [[110.0670],\n",
      "         [  8.6428],\n",
      "         [  8.9324]],\n",
      "\n",
      "        [[112.3537],\n",
      "         [  9.1140],\n",
      "         [  8.7492]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.ln1.hook_normalized\n",
      "tensor([[[-0.0453, -0.0321, -0.0539],\n",
      "         [-0.2966,  0.4989, -0.2917],\n",
      "         [ 0.0281,  0.3176, -0.6763]],\n",
      "\n",
      "        [[-0.0508, -0.0502, -0.0574],\n",
      "         [ 0.4063,  0.0963, -0.3352],\n",
      "         [-0.0683,  0.0410, -0.9052]],\n",
      "\n",
      "        [[-0.0453, -0.0414, -0.0512],\n",
      "         [-0.2369,  0.4442, -0.0989],\n",
      "         [ 0.8476,  0.2703,  0.6678]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.ln1.hook_scale\n",
      "tensor([[[112.4229],\n",
      "         [  8.4704],\n",
      "         [  9.3139]],\n",
      "\n",
      "        [[110.0670],\n",
      "         [  8.6428],\n",
      "         [  8.9324]],\n",
      "\n",
      "        [[112.3537],\n",
      "         [  9.1140],\n",
      "         [  8.7492]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.ln1.hook_normalized\n",
      "tensor([[[-0.0453, -0.0321, -0.0539],\n",
      "         [-0.2966,  0.4989, -0.2917],\n",
      "         [ 0.0281,  0.3176, -0.6763]],\n",
      "\n",
      "        [[-0.0508, -0.0502, -0.0574],\n",
      "         [ 0.4063,  0.0963, -0.3352],\n",
      "         [-0.0683,  0.0410, -0.9052]],\n",
      "\n",
      "        [[-0.0453, -0.0414, -0.0512],\n",
      "         [-0.2369,  0.4442, -0.0989],\n",
      "         [ 0.8476,  0.2703,  0.6678]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.ln1.hook_scale\n",
      "tensor([[[112.4229],\n",
      "         [  8.4704],\n",
      "         [  9.3139]],\n",
      "\n",
      "        [[110.0670],\n",
      "         [  8.6428],\n",
      "         [  8.9324]],\n",
      "\n",
      "        [[112.3537],\n",
      "         [  9.1140],\n",
      "         [  8.7492]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.ln1.hook_normalized\n",
      "tensor([[[-0.0453, -0.0321, -0.0539],\n",
      "         [-0.2966,  0.4989, -0.2917],\n",
      "         [ 0.0281,  0.3176, -0.6763]],\n",
      "\n",
      "        [[-0.0508, -0.0502, -0.0574],\n",
      "         [ 0.4063,  0.0963, -0.3352],\n",
      "         [-0.0683,  0.0410, -0.9052]],\n",
      "\n",
      "        [[-0.0453, -0.0414, -0.0512],\n",
      "         [-0.2369,  0.4442, -0.0989],\n",
      "         [ 0.8476,  0.2703,  0.6678]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.attn.hook_q\n",
      "tensor([[[[-2.0422,  1.9252,  0.3249],\n",
      "          [-1.6899,  0.7516,  1.9611],\n",
      "          [-2.1339, -1.0259,  1.3589]],\n",
      "\n",
      "         [[-0.0931, -1.1834, -0.7890],\n",
      "          [-0.0248, -0.3380,  2.3998],\n",
      "          [ 0.4385,  0.5543,  1.0373]],\n",
      "\n",
      "         [[-0.1486, -1.9327, -0.8695],\n",
      "          [ 0.4102, -0.9053,  0.3666],\n",
      "          [ 0.2681,  0.4862,  0.4619]]],\n",
      "\n",
      "\n",
      "        [[[-2.0269,  1.9157,  0.3146],\n",
      "          [-1.6771,  0.7599,  1.9783],\n",
      "          [-2.1215, -1.0153,  1.3593]],\n",
      "\n",
      "         [[ 0.2388, -1.2628, -0.9953],\n",
      "          [ 0.1752, -0.1343,  1.4776],\n",
      "          [ 0.2444, -0.3283,  0.6543]],\n",
      "\n",
      "         [[ 1.6835, -1.8770, -1.5537],\n",
      "          [ 0.7063,  0.5381,  0.4449],\n",
      "          [ 0.8588, -0.2933,  0.0825]]],\n",
      "\n",
      "\n",
      "        [[[-2.0359,  1.9255,  0.3268],\n",
      "          [-1.7020,  0.7531,  1.9870],\n",
      "          [-2.1158, -1.0208,  1.3730]],\n",
      "\n",
      "         [[-0.0693, -1.2969, -0.1657],\n",
      "          [ 0.0259,  0.1957,  1.0294],\n",
      "          [ 0.6087,  0.1780,  0.5440]],\n",
      "\n",
      "         [[-1.1948, -1.8138, -0.3818],\n",
      "          [-0.8234,  0.7009,  1.4829],\n",
      "          [ 0.7629, -1.2378,  0.4385]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.attn.hook_k\n",
      "tensor([[[[-1.7158, -0.3213, -0.3065],\n",
      "          [ 0.1080, -0.0814,  2.3071],\n",
      "          [-0.2056,  1.0627,  0.4715]],\n",
      "\n",
      "         [[ 0.8141,  0.0251,  0.0297],\n",
      "          [ 0.5323, -0.1664, -1.4260],\n",
      "          [-0.9800,  1.1781, -0.4875]],\n",
      "\n",
      "         [[-0.1160,  0.2127, -0.4432],\n",
      "          [ 0.4013, -1.0048,  0.3686],\n",
      "          [-1.5567,  1.3205, -0.6679]]],\n",
      "\n",
      "\n",
      "        [[[-1.7161, -0.2949, -0.2876],\n",
      "          [ 0.1197, -0.0691,  2.2802],\n",
      "          [-0.2019,  1.0601,  0.4580]],\n",
      "\n",
      "         [[ 0.9281, -0.1625, -0.5601],\n",
      "          [ 1.1101, -0.6679, -0.9203],\n",
      "          [-1.1412,  0.4220,  0.6529]],\n",
      "\n",
      "         [[ 1.1963, -0.4563, -0.7223],\n",
      "          [ 0.1871, -0.7382, -0.7127],\n",
      "          [-0.5852,  1.5893,  0.2296]]],\n",
      "\n",
      "\n",
      "        [[[-1.7178, -0.3268, -0.3087],\n",
      "          [ 0.1054, -0.0765,  2.3109],\n",
      "          [-0.1999,  1.0656,  0.4706]],\n",
      "\n",
      "         [[ 0.2561, -0.1252, -0.3513],\n",
      "          [ 0.0511, -0.2160, -0.2964],\n",
      "          [-0.7870,  1.8725,  0.3605]],\n",
      "\n",
      "         [[ 0.1499, -0.6604,  0.3957],\n",
      "          [ 0.4286, -0.1068, -1.0359],\n",
      "          [ 0.6279,  2.3942,  0.5386]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.attn.hook_v\n",
      "tensor([[[[ 1.2106e-01, -1.3817e-02, -8.1438e-02],\n",
      "          [-4.6224e-02, -4.3612e-02, -1.7725e-03],\n",
      "          [ 4.6787e-02, -9.8738e-03, -6.2557e-02]],\n",
      "\n",
      "         [[ 8.4078e-01, -1.4905e-01, -2.5681e-01],\n",
      "          [-1.8874e+00,  1.2048e+00,  4.0161e-01],\n",
      "          [ 1.6456e+00,  6.0440e-01, -8.6757e-02]],\n",
      "\n",
      "         [[ 1.0408e+00,  3.3560e-01,  4.1217e-01],\n",
      "          [-7.5427e-01, -2.2496e-01, -3.9501e-01],\n",
      "          [-6.2478e-01, -4.5923e-01,  1.5127e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0615e-01,  1.7662e-02, -8.6120e-02],\n",
      "          [-1.1426e-02, -3.5068e-02, -1.8766e-03],\n",
      "          [ 9.0394e-02, -4.5780e-04, -1.0970e-01]],\n",
      "\n",
      "         [[-3.7708e-01, -6.3756e-01, -5.5811e-02],\n",
      "          [ 7.7848e-01, -3.2923e-03, -5.6292e-01],\n",
      "          [-1.1735e+00,  8.0746e-01, -2.9572e-02]],\n",
      "\n",
      "         [[ 2.7031e-01, -6.9757e-01,  1.0526e+00],\n",
      "          [-4.3052e-01,  3.3988e-01,  5.9328e-01],\n",
      "          [-4.2298e-01,  1.1957e+00, -8.3207e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4109e-01, -1.9637e-02, -7.5452e-02],\n",
      "          [-3.7292e-02, -1.9511e-02, -3.4226e-04],\n",
      "          [ 5.2558e-02,  7.3106e-03, -8.0354e-02]],\n",
      "\n",
      "         [[ 1.0497e+00,  1.3172e-01,  1.3051e+00],\n",
      "          [-8.1023e-01, -6.5129e-01,  1.0140e+00],\n",
      "          [ 9.0451e-01,  5.4643e-01, -2.6764e-03]],\n",
      "\n",
      "         [[-8.7277e-01,  1.0565e+00,  2.1756e+00],\n",
      "          [ 1.3541e+00, -1.9220e+00, -2.4063e+00],\n",
      "          [ 3.8107e+00,  1.4938e+00,  1.3629e-01]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.attn.hook_attn_scores\n",
      "tensor([[[[ 8.9447e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.9123e+00,  7.9402e-01, -1.0000e+05],\n",
      "          [ 1.6016e+00,  8.7563e-01,  5.7656e-01]],\n",
      "\n",
      "         [[ 2.5566e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.5413e+00, -6.6039e-01, -1.0000e+05],\n",
      "          [ 3.4030e+00,  4.0714e-01, -7.1404e-01]],\n",
      "\n",
      "         [[ 4.4065e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.3900e+00, -1.0960e+00, -1.0000e+05],\n",
      "          [ 3.2039e+00, -1.1876e-01, -8.4454e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3895e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 2.1656e+00,  3.5935e-01, -1.0000e+05],\n",
      "          [ 1.4666e+00,  1.0417e+00,  2.1845e+00]],\n",
      "\n",
      "         [[ 2.5305e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.7243e+00, -4.3065e-01, -1.0000e+05],\n",
      "          [ 2.9073e+00, -9.6455e-02,  8.9665e-01]],\n",
      "\n",
      "         [[ 4.3680e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.6220e+00, -3.5947e-01, -1.0000e+05],\n",
      "          [ 2.7551e+00,  2.5705e-01, -7.3543e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9520e-01, -1.0000e+05, -1.0000e+05],\n",
      "          [ 1.7059e+00,  1.3207e+00, -1.0000e+05],\n",
      "          [ 2.6119e+00,  2.0583e-01,  4.6862e-01]],\n",
      "\n",
      "         [[ 2.5457e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.3752e+00,  3.9853e-01, -1.0000e+05],\n",
      "          [ 4.6094e+00,  3.3204e-01,  5.1854e-01]],\n",
      "\n",
      "         [[ 4.4284e+00, -1.0000e+05, -1.0000e+05],\n",
      "          [ 3.1874e+00, -3.4194e-01, -1.0000e+05],\n",
      "          [ 4.1084e+00, -5.7153e-01, -2.0263e+00]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.attn.hook_pattern\n",
      "tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.7537, 0.2463, 0.0000],\n",
      "          [0.5427, 0.2626, 0.1947]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9853, 0.0147, 0.0000],\n",
      "          [0.9378, 0.0469, 0.0153]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9889, 0.0111, 0.0000],\n",
      "          [0.9492, 0.0342, 0.0166]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.8589, 0.1411, 0.0000],\n",
      "          [0.2700, 0.1765, 0.5535]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9846, 0.0154, 0.0000],\n",
      "          [0.8449, 0.0419, 0.1131]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9817, 0.0183, 0.0000],\n",
      "          [0.8762, 0.0721, 0.0518]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5951, 0.4049, 0.0000],\n",
      "          [0.8282, 0.0747, 0.0971]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9515, 0.0485, 0.0000],\n",
      "          [0.9703, 0.0135, 0.0162]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.9715, 0.0285, 0.0000],\n",
      "          [0.9887, 0.0092, 0.0021]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.attn.hook_z\n",
      "tensor([[[[ 1.2106e-01, -1.3817e-02, -8.1438e-02],\n",
      "          [-4.6224e-02, -4.3612e-02, -1.7725e-03],\n",
      "          [ 4.6787e-02, -9.8738e-03, -6.2557e-02]],\n",
      "\n",
      "         [[ 2.9835e-01, -4.7130e-02, -1.2464e-01],\n",
      "          [-7.3381e-02, -2.5198e-02,  4.1772e-03],\n",
      "          [ 6.4598e-02, -3.0304e-03, -6.2827e-02]],\n",
      "\n",
      "         [[ 4.8913e-01,  1.8709e-02, -3.1376e-02],\n",
      "          [-1.4337e-01,  1.2150e-02,  1.1132e-02],\n",
      "          [ 9.0385e-02,  3.7078e-03, -3.7292e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0615e-01,  1.7662e-02, -8.6120e-02],\n",
      "          [-1.1426e-02, -3.5068e-02, -1.8766e-03],\n",
      "          [ 9.0394e-02, -4.5780e-04, -1.0970e-01]],\n",
      "\n",
      "         [[ 3.7969e-02, -7.4781e-02, -8.1844e-02],\n",
      "          [ 7.7312e-04, -3.4577e-02, -1.0541e-02],\n",
      "          [ 6.7244e-02,  1.4340e-02, -1.0823e-01]],\n",
      "\n",
      "         [[ 1.1171e-01, -4.9389e-01,  5.4952e-01],\n",
      "          [-2.5737e-02,  8.6853e-03,  4.1946e-02],\n",
      "          [-2.7268e-02,  1.1969e-01, -1.4132e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4109e-01, -1.9637e-02, -7.5452e-02],\n",
      "          [-3.7292e-02, -1.9511e-02, -3.4226e-04],\n",
      "          [ 5.2558e-02,  7.3106e-03, -8.0354e-02]],\n",
      "\n",
      "         [[ 5.0896e-01,  4.1645e-02,  4.8352e-01],\n",
      "          [-7.4774e-02, -5.0148e-02,  4.8846e-02],\n",
      "          [ 7.6829e-02,  2.2669e-02, -7.8141e-02]],\n",
      "\n",
      "         [[ 1.1048e-01,  9.6179e-02,  2.4627e-01],\n",
      "          [-2.5122e-02, -5.8891e-02, -2.5725e-02],\n",
      "          [ 6.8423e-02,  1.5441e-02, -7.9178e-02]]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.hook_attn_out\n",
      "tensor([[[ 4.3605,  4.3173,  4.2097],\n",
      "         [ 0.5275,  0.4726,  0.0504],\n",
      "         [ 0.5171,  0.9283,  0.3962]],\n",
      "\n",
      "        [[ 4.3184,  4.2161,  4.1089],\n",
      "         [ 0.2670, -0.1244, -0.6509],\n",
      "         [ 0.7235,  0.9469, -0.6626]],\n",
      "\n",
      "        [[ 4.3659,  4.3311,  4.1763],\n",
      "         [ 0.4840, -0.0257,  0.0409],\n",
      "         [ 0.2736, -0.1604,  0.0794]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.hook_resid_mid\n",
      "tensor([[[-0.7294,  0.7069, -1.8451],\n",
      "         [-1.9847,  4.6985, -2.4209],\n",
      "         [ 0.7786,  3.8865, -5.9032]],\n",
      "\n",
      "        [[-1.2715, -1.3136, -2.2126],\n",
      "         [ 3.7784,  0.7078, -3.5484],\n",
      "         [ 0.1135,  1.3131, -8.7478]],\n",
      "\n",
      "        [[-0.7187, -0.3209, -1.5731],\n",
      "         [-1.6751,  4.0227, -0.8606],\n",
      "         [ 7.6890,  2.2047,  5.9221]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.ln2.hook_scale\n",
      "tensor([[[17.3085],\n",
      "         [10.5344],\n",
      "         [12.6833]],\n",
      "\n",
      "        [[16.2286],\n",
      "         [10.2469],\n",
      "         [14.7569]],\n",
      "\n",
      "        [[17.3891],\n",
      "         [12.3179],\n",
      "         [10.0402]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.ln2.hook_normalized\n",
      "tensor([[[-0.0421,  0.0408, -0.1066],\n",
      "         [-0.1884,  0.4460, -0.2298],\n",
      "         [ 0.0614,  0.3064, -0.4654]],\n",
      "\n",
      "        [[-0.0783, -0.0809, -0.1363],\n",
      "         [ 0.3687,  0.0691, -0.3463],\n",
      "         [ 0.0077,  0.0890, -0.5928]],\n",
      "\n",
      "        [[-0.0413, -0.0185, -0.0905],\n",
      "         [-0.1360,  0.3266, -0.0699],\n",
      "         [ 0.7658,  0.2196,  0.5898]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.mlp.hook_pre\n",
      "tensor([[[-0.1690, -0.3977,  0.6819],\n",
      "         [-0.0998, -0.6147,  1.2987],\n",
      "         [ 0.0767,  0.3872,  1.8182]],\n",
      "\n",
      "        [[-0.0059, -0.3232,  0.5598],\n",
      "         [ 0.2270, -0.1345,  1.1912],\n",
      "         [-0.5143,  0.3430,  2.0601]],\n",
      "\n",
      "        [[-0.0057, -0.2729,  0.7464],\n",
      "         [-0.3467, -0.0076,  1.5084],\n",
      "         [-2.1376, -0.7008,  0.2024]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.mlp.hook_post\n",
      "tensor([[[-0.0732, -0.1374,  0.5129],\n",
      "         [-0.0459, -0.1656,  1.1725],\n",
      "         [ 0.0407,  0.2519,  1.7554]],\n",
      "\n",
      "        [[-0.0029, -0.1206,  0.3987],\n",
      "         [ 0.1339, -0.0600,  1.0518],\n",
      "         [-0.1561,  0.2175,  2.0197]],\n",
      "\n",
      "        [[-0.0028, -0.1071,  0.5763],\n",
      "         [-0.1263, -0.0038,  1.4090],\n",
      "         [-0.0346, -0.1694,  0.1174]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.hook_mlp_out\n",
      "tensor([[[-0.2489,  0.4627, -0.9180],\n",
      "         [ 0.1435, -0.5268,  0.8440],\n",
      "         [-0.5047,  1.1901, -1.2225]],\n",
      "\n",
      "        [[-0.8760,  0.6864, -0.6091],\n",
      "         [ 0.1949,  1.8668,  0.8553],\n",
      "         [-0.6032, -1.1954, -0.0108]],\n",
      "\n",
      "        [[ 0.2672,  1.0555, -1.1502],\n",
      "         [-0.0998,  0.3526, -2.6244],\n",
      "         [-0.6765,  0.4814, -0.5357]]], grad_fn=<SliceBackward0>)\n",
      "blocks.11.hook_resid_post\n",
      "tensor([[[-0.9783,  1.1696, -2.7632],\n",
      "         [-1.8412,  4.1717, -1.5769],\n",
      "         [ 0.2740,  5.0765, -7.1257]],\n",
      "\n",
      "        [[-2.1475, -0.6272, -2.8218],\n",
      "         [ 3.9734,  2.5747, -2.6931],\n",
      "         [-0.4898,  0.1176, -8.7585]],\n",
      "\n",
      "        [[-0.4515,  0.7346, -2.7234],\n",
      "         [-1.7749,  4.3754, -3.4850],\n",
      "         [ 7.0125,  2.6861,  5.3864]]], grad_fn=<SliceBackward0>)\n",
      "ln_final.hook_scale\n",
      "tensor([[[13.4053],\n",
      "         [12.1539],\n",
      "         [15.8644]],\n",
      "\n",
      "        [[12.1828],\n",
      "         [11.4934],\n",
      "         [16.3107]],\n",
      "\n",
      "        [[13.4553],\n",
      "         [13.5659],\n",
      "         [12.3789]]], grad_fn=<SliceBackward0>)\n",
      "ln_final.hook_normalized\n",
      "tensor([[[-0.0730,  0.0872, -0.2061],\n",
      "         [-0.1515,  0.3432, -0.1297],\n",
      "         [ 0.0173,  0.3200, -0.4492]],\n",
      "\n",
      "        [[-0.1763, -0.0515, -0.2316],\n",
      "         [ 0.3457,  0.2240, -0.2343],\n",
      "         [-0.0300,  0.0072, -0.5370]],\n",
      "\n",
      "        [[-0.0336,  0.0546, -0.2024],\n",
      "         [-0.1308,  0.3225, -0.2569],\n",
      "         [ 0.5665,  0.2170,  0.4351]]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#uses default size of 3x3 corner\n",
    "### colab used \"tokens\" from earlier, I'm going to stick with rand_toks\n",
    "def print_corner(tensor, hook):\n",
    "    print(hook.name)\n",
    "    print(get_corner(tensor))\n",
    "\n",
    "logits = model.run_with_hooks(rand_toks, fwd_hooks=[(all_hooks_fn, print_corner)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hook_embed torch.Size([4, 50, 768])\n",
      "hook_pos_embed torch.Size([4, 50, 768])\n",
      "blocks.0.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.0.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.0.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.0.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.0.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.0.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.0.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.0.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.0.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.0.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.0.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.0.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.0.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.0.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.0.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.0.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.0.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.1.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.1.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.1.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.1.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.1.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.1.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.1.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.1.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.1.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.1.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.1.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.1.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.1.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.1.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.1.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.1.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.1.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.2.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.2.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.2.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.2.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.2.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.2.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.2.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.2.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.2.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.2.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.2.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.2.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.2.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.2.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.2.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.2.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.2.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.3.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.3.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.3.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.3.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.3.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.3.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.3.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.3.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.3.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.3.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.3.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.3.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.3.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.3.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.3.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.3.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.3.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.4.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.4.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.4.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.4.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.4.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.4.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.4.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.4.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.4.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.4.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.4.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.4.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.4.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.4.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.4.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.4.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.4.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.5.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.5.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.5.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.5.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.5.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.5.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.5.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.5.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.5.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.5.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.5.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.5.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.5.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.5.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.5.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.5.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.5.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.6.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.6.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.6.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.6.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.6.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.6.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.6.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.6.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.6.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.6.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.6.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.6.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.6.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.6.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.6.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.6.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.6.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.7.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.7.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.7.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.7.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.7.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.7.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.7.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.7.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.7.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.7.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.7.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.7.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.7.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.7.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.7.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.7.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.7.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.8.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.8.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.8.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.8.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.8.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.8.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.8.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.8.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.8.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.8.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.8.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.8.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.8.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.8.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.8.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.8.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.8.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.9.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.9.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.9.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.9.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.9.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.9.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.9.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.9.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.9.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.9.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.9.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.9.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.9.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.9.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.9.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.9.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.9.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.10.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.10.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.10.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.10.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.10.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.10.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.10.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.10.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.10.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.10.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.10.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.10.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.10.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.10.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.10.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.10.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.10.hook_resid_post torch.Size([4, 50, 768])\n",
      "blocks.11.hook_resid_pre torch.Size([4, 50, 768])\n",
      "blocks.11.ln1.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.11.ln1.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.11.attn.hook_q torch.Size([4, 50, 12, 64])\n",
      "blocks.11.attn.hook_k torch.Size([4, 50, 12, 64])\n",
      "blocks.11.attn.hook_v torch.Size([4, 50, 12, 64])\n",
      "blocks.11.attn.hook_attn_scores torch.Size([4, 12, 50, 50])\n",
      "blocks.11.attn.hook_pattern torch.Size([4, 12, 50, 50])\n",
      "blocks.11.attn.hook_z torch.Size([4, 50, 12, 64])\n",
      "blocks.11.hook_attn_out torch.Size([4, 50, 768])\n",
      "blocks.11.hook_resid_mid torch.Size([4, 50, 768])\n",
      "blocks.11.ln2.hook_scale torch.Size([4, 50, 1])\n",
      "blocks.11.ln2.hook_normalized torch.Size([4, 50, 768])\n",
      "blocks.11.mlp.hook_pre torch.Size([4, 50, 3072])\n",
      "blocks.11.mlp.hook_post torch.Size([4, 50, 3072])\n",
      "blocks.11.hook_mlp_out torch.Size([4, 50, 768])\n",
      "blocks.11.hook_resid_post torch.Size([4, 50, 768])\n",
      "ln_final.hook_scale torch.Size([4, 50, 1])\n",
      "ln_final.hook_normalized torch.Size([4, 50, 768])\n"
     ]
    }
   ],
   "source": [
    "## cache all the activations \n",
    "model.reset_hooks()\n",
    "logits, cache = model.run_with_cache(rand_toks)\n",
    "for name in cache:\n",
    "    print(name, cache[name].shape)\n",
    "\n",
    "# This should be the same as printing the shape of activations like we did before. Let's check: \n",
    "model.reset_hooks()\n",
    "shape_cache = {}\n",
    "def cache_shape(tensor, hook):\n",
    "    shape_cache[hook.name] = tensor.shape\n",
    "logits = model.run_with_hooks(rand_toks, fwd_hooks = [(all_hooks_fn, cache_shape)])\n",
    "\n",
    "for name in cache:\n",
    "    assert cache[name].shape == shape_cache[name]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDITING ACTIVATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.4487, 11.0131,  7.8047,  ..., -2.9968, -3.2080,  8.5503],\n",
       "         [ 4.5501,  4.6872,  3.5226,  ..., -4.7606, -2.3688,  4.5484],\n",
       "         [ 6.0779,  6.6369,  2.5403,  ..., -3.2799, -1.3250,  7.7766],\n",
       "         [ 7.9233,  9.0306,  5.9391,  ...,  1.1033, -1.2689,  8.0923],\n",
       "         [ 4.1626,  4.4285,  1.5028,  ..., -1.7751, -1.4225,  3.4835],\n",
       "         [14.3212,  8.7445,  3.4807,  ...,  1.2178, -2.7917,  9.4326]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### PRUNING ATTENTION HEADS ###########\n",
    "\n",
    "head_dict = {3:[0,3,7], 7:[8,9]}\n",
    "fwd_hooks = []\n",
    "for layer, heads in head_dict.items():\n",
    "    hook = f\"blocks.{layer}.attn.hook_z\" #this can be a string\n",
    "    hook_fn = f\"prune_fn_{layer}\" #this needs to be a callable function of this name\n",
    "    fwd_hooks.append((hook, eval(hook_fn)))\n",
    "\n",
    "\n",
    "logits = model.run_with_hooks(tokens, fwd_hooks = fwd_hooks)\n",
    "\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New logits = tensor([[[ 7.5261, 11.1214,  7.8919,  8.1297,  7.4282],\n",
      "         [ 4.5895,  4.6344,  3.1930,  3.0397,  4.7588],\n",
      "         [ 7.4953,  8.5096,  4.7810,  5.4829,  6.5468],\n",
      "         [ 9.6950, 13.1113,  6.2229,  3.7978,  6.4755],\n",
      "         [ 4.9499,  6.9523,  0.6289,  0.3997,  1.7647]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "OG logits = tensor([[[ 7.5261, 11.1214,  7.8919,  8.1297,  7.4282],\n",
      "         [ 4.5895,  4.6344,  3.1930,  3.0397,  4.7588],\n",
      "         [ 6.0709,  6.6744,  2.5337,  0.9526,  3.9620],\n",
      "         [ 7.8493,  9.2531,  5.9004,  2.1225,  3.5641],\n",
      "         [ 4.2368,  4.4603,  1.5758, -0.1628,  2.1362]]],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 1.4244,  1.8352,  2.2473,  ..., -0.9822, -0.6487, -0.6475],\n",
       "          [ 1.8457,  3.8582,  0.3225,  ..., -0.3913,  0.0780,  0.3606],\n",
       "          [ 0.7131,  2.4920, -0.9469,  ...,  0.1432,  2.0542, -0.8026],\n",
       "          [-0.0442,  1.6058, -2.9549,  ..., -0.7779,  0.7996, -1.3249]]],\n",
       "        grad_fn=<SubBackward0>),\n",
       " torch.Size([1, 6, 50257]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### RESTRICT ALL ATTENTION HEADS TO ONLY ATTEND TO CURRENT AND PREVIOUS TOKENS ###########\n",
    "\n",
    "## This is a separate example from above. Always reset hooks (even though the default of run_with_hooks and run_with_cache is to do it anyway)\n",
    "### Also, I think they use the cache just for the original model, to compare with the hooked function. We could easily make the function to change hooks update the cache. \n",
    "\n",
    "model.reset_hooks()\n",
    "def filter_hook_attn(name):\n",
    "    split_name = name.split('.')\n",
    "    #if (split_name[-1] == 'hook_attn'):\n",
    "    #print(split_name[-1])\n",
    "    ## only change the attn heads\n",
    "    return (split_name[-1] == 'hook_pattern')\n",
    "\n",
    "# Apply a mask to the attention pattern that only considers the current and previous tokens\n",
    "### attn has shape batch x head_no x query_pos x key_pos\n",
    "def restrict_attn(attn, hook):\n",
    "    # key and query length (context length) should be the same? \n",
    "    assert attn.size(-2) == attn.size(-1)\n",
    "    n_context = attn.size(-1)\n",
    "    key_pos = torch.arange(n_context)[None, :]\n",
    "    query_pos = torch.arange(n_context)[:,None]\n",
    "    ZERO = torch.tensor(0.)\n",
    "    mask = (key_pos > (query_pos - 2))\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        ZERO = ZERO.cuda()\n",
    "        mask = mask.cuda()\n",
    "    attn = torch.where(mask, attn, ZERO)\n",
    "    #print(attn)\n",
    "    return attn\n",
    "\n",
    "logits = model.run_with_hooks(tokens, fwd_hooks = [(filter_hook_attn, restrict_attn)])\n",
    "\n",
    "print(f\"New logits = {get_corner(logits,5)}\")\n",
    "print(f\"OG logits = {get_corner(original_logits,5)}\")\n",
    "logits - original_logits, logits.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FREEZING ATTENTION PATTERNS: \n",
    "Run the model twice: Once on the original text, getting the attention pattern, again on the new text, replacing them with the cached pattern \n",
    "-- I'll do it once the way they did (deprecated), and again the way I think it should be done now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['blocks.0.attn.hook_pattern', 'blocks.1.attn.hook_pattern', 'blocks.2.attn.hook_pattern', 'blocks.3.attn.hook_pattern', 'blocks.4.attn.hook_pattern', 'blocks.5.attn.hook_pattern', 'blocks.6.attn.hook_pattern', 'blocks.7.attn.hook_pattern', 'blocks.8.attn.hook_pattern', 'blocks.9.attn.hook_pattern', 'blocks.10.attn.hook_pattern', 'blocks.11.attn.hook_pattern'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 7.5261, 11.1214,  7.8919,  ..., -3.1299, -3.3873,  8.5934],\n",
       "          [ 4.5895,  4.6344,  3.1930,  ..., -4.6853, -2.3474,  4.6327],\n",
       "          [ 6.0709,  6.6744,  2.5337,  ..., -3.2367, -1.5178,  8.0657],\n",
       "          [ 7.8493,  9.2531,  5.9004,  ...,  0.9130, -1.4072,  8.2276],\n",
       "          [ 4.2368,  4.4603,  1.5758,  ..., -1.7220, -1.1896,  3.2500],\n",
       "          [14.2398,  8.7174,  4.0264,  ...,  1.2469, -2.7178,  9.8876]]],\n",
       "        grad_fn=<AddBackward0>),\n",
       " tensor([[[ 7.5261e+00,  1.1121e+01,  7.8919e+00,  ..., -3.1299e+00,\n",
       "           -3.3873e+00,  8.5934e+00],\n",
       "          [ 6.1054e+00,  6.3903e+00,  4.8687e+00,  ..., -8.8158e-01,\n",
       "            7.6134e-02,  6.2353e+00],\n",
       "          [ 6.2097e+00,  5.8213e+00,  4.8398e+00,  ..., -4.5794e+00,\n",
       "            1.4583e-03,  5.5054e+00],\n",
       "          [ 8.3301e+00,  7.7019e+00,  5.6676e+00,  ..., -2.2781e+00,\n",
       "           -3.6617e-01,  7.6546e+00],\n",
       "          [ 5.0353e+00,  4.3325e+00,  2.1272e+00,  ..., -4.2344e+00,\n",
       "           -1.5338e+00,  3.3912e+00],\n",
       "          [ 1.4076e+01,  7.5436e+00,  2.9390e+00,  ..., -1.3192e+00,\n",
       "           -2.5601e+00,  8.4553e+00]]], grad_fn=<AddBackward0>),\n",
       " torch.Size([1, 6, 50257]),\n",
       " torch.Size([1, 6, 50257]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## old way \n",
    "attn_cache = {}\n",
    "def cache_attn(attn, hook):\n",
    "    attn_cache[hook.name] = attn\n",
    "\n",
    "\n",
    "def freeze_attn(attn, hook):\n",
    "    #print(attn_cache[hook.name])\n",
    "    return attn_cache[hook.name]\n",
    "\n",
    "logits_0 = model.run_with_hooks(tokens, fwd_hooks = [(filter_hook_attn, cache_attn)])\n",
    "print(attn_cache.keys())\n",
    "logits_1 = model.run_with_hooks(tokens_2, fwd_hooks = [(filter_hook_attn, freeze_attn)])\n",
    "\n",
    "logits_0, logits_1, logits_0.shape, logits_1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "### New way: I don't think it matters that you filter the original model, since it will get filtered out when we do it again \n",
    "\n",
    "logits_OG, cache_OG = model.run_with_cache(tokens)\n",
    "\n",
    "def freeze_attn_new(attn, hook):\n",
    "    #print(hook.name)\n",
    "    return cache_OG[hook.name]\n",
    "\n",
    "logits_new = model.run_with_hooks(tokens_2, fwd_hooks = [(filter_hook_attn, freeze_attn_new)])\n",
    "\n",
    "print(all(einops.rearrange((logits_OG - logits_0)==0, \"b s v -> (b s v)\")))\n",
    "print(all(einops.rearrange((logits_1 - logits_new)==0, \"b s v -> (b s v)\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e851e82dedee55c73100bfbe6682b3cabddc188516229e1e8f6342cda6eae37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import torch as t\n",
    "import numpy as np\n",
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "import plotly.express as px\n",
    "import einops\n",
    "import plotly.graph_objects as go \n",
    "from functools import partial\n",
    "import tqdm.auto as tqdm\n",
    "import datasets\n",
    "\n",
    "import transformer_lens\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
    "\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from fancy_einsum import einsum\n",
    "# import random\n",
    "# from pathlib import Path\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# from jaxtyping import Float, Int\n",
    "# from typing import List, Union, Optional\n",
    "# import copy\n",
    "\n",
    "# import itertools\n",
    "# from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "# import dataclasses\n",
    "# from IPython.display import HTML\n",
    "# import transformer_lens\n",
    "# import transformer_lens.utils as utils\n",
    "# from transformer_lens.hook_points import (\n",
    "#     HookedRootModule,\n",
    "#     HookPoint,\n",
    "# )  # Hooking utilities\n",
    "\n",
    "\n",
    "# import circuitsvis as cv\n",
    "# # Testing that the library works\n",
    "# cv.examples.hello(\"Neel\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start here with a clean setup, looking a little deeper at TL's capabilities. Builds on stuff figured out in \"EasyTransformer.ipynb\"\n",
    "This doc relies on https://github.com/neelnanda-io/TransformerLens/blob/99e8a599f244dcdd70a5cf7005b47c7a057f4681/demos/Main_Demo.ipynb\n",
    "which is up-to-date, detailed, and well-annotated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "## turn off AD to save memory, since we're focusing on model inference here \n",
    "t.set_grad_enabled(False)\n",
    "\n",
    "device = 'cuda' if t.cuda.is_available() else 'cpu'\n",
    "model = HookedTransformer.from_pretrained('gpt2-small', device=device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can return the loss (cross-entropy), logits, both, or none (for storing intermediate activations) by specifying \"return_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-entropy losses with increasing context:  [tensor(5.6510), tensor(5.1699), tensor(4.5359), tensor(4.2693)]\n"
     ]
    }
   ],
   "source": [
    "text1 = \"This is my input to gpt2-small\"\n",
    "logits, loss = model(text1, return_type = 'both')\n",
    "\n",
    "## LG experiment: the loss should decrease with more context\n",
    "text2 = text1 + \"The more context I give it, the lower the loss I will achieve\"\n",
    "text3 = text2 + \"Let's see how low we can make it while still only giving it a reasonable number of prompts.\"\n",
    "text4 = text3 + \"It's still not very low but at least it's going down...\"\n",
    "texts = [text1,text2,text3,text4]\n",
    "test_losses = [model(text, return_type = 'loss') for text in texts]\n",
    "print('cross-entropy losses with increasing context: ', test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "## can run on text or tokens \n",
    "gpt2_text = text1\n",
    "gpt2_tokens = model.to_tokens(gpt2_text)\n",
    "print(gpt2_tokens.device) ## should be 'cpu'\n",
    "gpt2_logits, gpt2_cache = model.run_with_cache(gpt2_tokens, remove_batch_dim=True)\n",
    "\n",
    "# check that the loss on tokens is the same as on text\n",
    "assert model(gpt2_tokens, return_type='loss') ==model(gpt2_text, return_type='loss')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IOI demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting functions\n",
    "# This is mostly a bunch of over-engineered mess to hack Plotly into producing \n",
    "# the pretty pictures I want, I recommend not reading too closely unless you \n",
    "# want Plotly hacking practice\n",
    "def to_numpy(tensor, flat=False):\n",
    "    if type(tensor)!=t.Tensor:\n",
    "        return tensor\n",
    "    if flat:\n",
    "        return tensor.flatten().detach().cpu().numpy()\n",
    "    else:\n",
    "        return tensor.detach().cpu().numpy()\n",
    "def imshow(tensor, xaxis=None, yaxis=None, animation_name='Snapshot', **kwargs):\n",
    "    tensor = t.squeeze(tensor)\n",
    "    px.imshow(to_numpy(tensor, flat=False), \n",
    "              labels={'x':xaxis, 'y':yaxis, 'animation_name':animation_name}, \n",
    "              **kwargs).show()\n",
    "# Set default colour scheme\n",
    "# Creates good defaults for showing divergent colour scales (ie with both \n",
    "# positive and negative values, where 0 is white)\n",
    "imshow = partial(imshow, color_continuous_scale='RdBu', color_continuous_midpoint=0.0)\n",
    "\n",
    "def line(x, y=None, hover=None, xaxis='', yaxis='', **kwargs):\n",
    "    if type(y)==t.Tensor:\n",
    "        y = to_numpy(y, flat=True)\n",
    "    if type(x)==t.Tensor:\n",
    "        x=to_numpy(x, flat=True)\n",
    "    fig = px.line(x, y=y, hover_name=hover, **kwargs)\n",
    "    fig.update_layout(xaxis_title=xaxis, yaxis_title=yaxis)\n",
    "    fig.show()\n",
    "def scatter(x, y, **kwargs):\n",
    "    px.scatter(x=to_numpy(x, flat=True), y=to_numpy(y, flat=True), **kwargs).show()\n",
    "def lines(lines_list, x=None, mode='lines', labels=None, xaxis='', yaxis='', title = '', log_y=False, hover=None, **kwargs):\n",
    "    # Helper function to plot multiple lines\n",
    "    if type(lines_list)==t.Tensor:\n",
    "        lines_list = [lines_list[i] for i in range(lines_list.shape[0])]\n",
    "    if x is None:\n",
    "        x=np.arange(len(lines_list[0]))\n",
    "    fig = go.Figure(layout={'title':title})\n",
    "    fig.update_xaxes(title=xaxis)\n",
    "    fig.update_yaxes(title=yaxis)\n",
    "    for c, line in enumerate(lines_list):\n",
    "        if type(line)==t.Tensor:\n",
    "            line = to_numpy(line)\n",
    "        if labels is not None:\n",
    "            label = labels[c]\n",
    "        else:\n",
    "            label = c\n",
    "        fig.add_trace(go.Scatter(x=x, y=line, mode=mode, name=label, hovertext=hover, **kwargs))\n",
    "    if log_y:\n",
    "        fig.update_layout(yaxis_type=\"log\")\n",
    "    fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important points of the IOI problem: \n",
    "- It is nontrivial enough to learn something from (an actual circuit you might care about, from a non toy model)\n",
    "- It's simple enough to have an algorithmic solution\n",
    "- Sees two names at the start, then eliminates the one that appears again to return the second "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Check that this works but giving it 10 examples of the task and check that they work but looking at the logits \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1 = [' John', ' Mary', ' Lori', ' john', ' mary', ' lori']\n",
    "names2 = [' Andres', ' Laurel', ' Mariel', ' andres', ' laurel', ' mariel']\n",
    "places = ['store', 'bar', 'apartment', 'park']\n",
    "things = ['some beer', 'some milk', 'an apple', 'a pencil']\n",
    "\n",
    "import random\n",
    "prompt_dict = {'After John and Mary went to the store, Mary handed a bottle of milk to': ' John'}\n",
    "logits_diff = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    n1 = random.choice(names1)\n",
    "    # get index of first token of name\n",
    "    n1_index = model.tokenizer.encode(n1)[0]\n",
    "    n2 = random.choice(names2)\n",
    "    n2_index = model.tokenizer.encode(n2)[0]\n",
    "    prompt1 = f\"After{n1} and{n2} went to the {random.choice(places)},{n1} handed {random.choice(things)} to\"\n",
    "    answer = n2\n",
    "    prompt_dict[prompt1] = answer\n",
    "    prompt2 = f\"After{n1} and{n2} went to the {random.choice(places)},{n2} handed {random.choice(things)} to\"\n",
    "    answer = n1\n",
    "    prompt_dict[prompt2] = answer\n",
    "    ## get logit difference for each pair of names in prompts1 and prompts2\n",
    "    logits1 = model(prompt1)\n",
    "    logits2 = model(prompt2)\n",
    "    logit1_diff = logits1[0,-1,n1_index] - logits1[0,-1,n2_index]\n",
    "    logits_diff.append(logit1_diff)\n",
    "    logit2_diff = logits2[0,-1,n1_index] - logits2[0,-1,n2_index]\n",
    "    logits_diff.append(logit2_diff)\n",
    "\n",
    "\n",
    "def get_top_preds(prompt, answer, top_n):\n",
    "    prompt_str_toks = model.to_str_tokens(prompt,prepend_bos = True)\n",
    "    answer_str_toks = model.to_str_tokens(answer, prepend_bos = False)\n",
    "    both_str_toks = model.to_str_tokens(prompt + answer,prepend_bos = True)\n",
    "    print('tokenized prompt: ', prompt_str_toks)\n",
    "    print('tokenized answer: ', answer_str_toks)\n",
    "    #print('tokenized total: ', both_str_toks)\n",
    "    prompt_len = len(prompt_str_toks)\n",
    "    answer_len = len(answer_str_toks)\n",
    "    logits = model(prompt + answer) #logits for full sentence \n",
    "    ## loop over the answer tokens\n",
    "    for idx in range(prompt_len, prompt_len + answer_len):\n",
    "        print(\"Logits for token:\", answer_str_toks[idx - prompt_len])\n",
    "        # get prediction of next token from the token index before idx\n",
    "        token_logits = logits[0, idx - 1]\n",
    "        probs = t.nn.functional.softmax(token_logits, dim = -1)\n",
    "        # sort the probabilities in descending order \n",
    "        vals, ids = token_logits.sort(descending = True)\n",
    "        for i in range(top_n):\n",
    "            print(f\"Top {i}th logit. Logit = {vals[i]}, prob = {probs[ids[i]].item():.2%}, token = {model.tokenizer.decode(ids[i])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([13.2429, 13.0791, 11.8180,  ..., -9.4433, -9.7380, -9.7437]),\n",
       "indices=tensor([   13,    12,    11,  ..., 40242, 33434, 45449]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0,10].sort(descending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('After John and Andres went to the apartment, John handed an apple to', ' Andres')\n",
      "tokenized prompt:  ['<|endoftext|>', 'After', ' John', ' and', ' And', 'res', ' went', ' to', ' the', ' apartment', ',', ' John', ' handed', ' an', ' apple', ' to']\n",
      "tokenized answer:  [' And', 'res']\n",
      "Logits for token:  And\n",
      "Top 0th logit. Logit = 17.644664764404297, prob = 72.57%, token =  And\n",
      "Top 1th logit. Logit = 14.795616149902344, prob = 4.20%, token =  John\n",
      "Top 2th logit. Logit = 14.460119247436523, prob = 3.00%, token =  the\n",
      "Top 3th logit. Logit = 14.068599700927734, prob = 2.03%, token =  them\n",
      "Top 4th logit. Logit = 13.848136901855469, prob = 1.63%, token =  his\n",
      "Logits for token: res\n",
      "Top 0th logit. Logit = 27.33884620666504, prob = 99.89%, token = res\n",
      "Top 1th logit. Logit = 19.31625747680664, prob = 0.03%, token = ré\n",
      "Top 2th logit. Logit = 19.03575325012207, prob = 0.02%, token = ros\n",
      "Top 3th logit. Logit = 18.689151763916016, prob = 0.02%, token = r\n",
      "Top 4th logit. Logit = 17.922199249267578, prob = 0.01%, token = rs\n"
     ]
    }
   ],
   "source": [
    "test =list(prompt_dict.items())[1]\n",
    "print(test)\n",
    "get_top_preds(test[0], test[1],5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaway, it seems to do pretty well! The main issues are probably attached to tokenization\n",
    "- For short words (like the example of John, Mary, store, milk), it gives the right answer  high (>80%) prob\n",
    "- For longer names (\"Laurel\"), the probability for the first token is much lower (and sometimes does not work at all), but later tokens in the name are predicted with higher probabilities.\n",
    "- For lower-case names, it also has a harder time, with the top choice usually given as \"her\" or \"the\", though all of the probabilities for the top ~3 logits are around the same. This makes sense \n",
    "- Also for longer names (and sometimes shorter ones too), the tokenization of the names as they appear in the prompt is different than the tokenization in the answer. It usually guesses the tokenization as it's shown in the prompt, but the way we've done things here (continuously prompting from the answer tokens) changes its path a little. We would probably get a better probability estimate if we appended the first guessed token logit to the logits instead of iterating through the answer tokens, but this would only work if the first guess is \"correct\" (which it's not always.)\n",
    "- I think this is further evidence that the IOI circuit is really copying tokens (that are upper case!) from the prompt, and that this isn't always consistent with the tokenization of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11, 50257])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: After John and Andres went to the apartment, John handed an apple to, logit diff = -2.849048614501953\n",
      "Input: After John and Andres went to the apartment, Andres handed some beer to, logit diff = 0.9219741821289062\n",
      "Input: After Mary and Mariel went to the store, Mary handed a pencil to, logit diff = -0.9477148056030273\n",
      "Input: After Mary and Mariel went to the apartment, Mariel handed a pencil to, logit diff = 3.476107597351074\n",
      "Input: After john and Laurel went to the bar, john handed some beer to, logit diff = -3.8186416625976562\n",
      "Input: After john and Laurel went to the bar, Laurel handed some beer to, logit diff = 5.98280143737793\n",
      "Input: After Lori and andres went to the store, Lori handed some milk to, logit diff = -2.0365066528320312\n",
      "Input: After Lori and andres went to the bar, andres handed an apple to, logit diff = 1.2254600524902344\n",
      "Input: After mary and andres went to the bar, mary handed some beer to, logit diff = 0.3899421691894531\n",
      "tokenized prompt:  ['<|endoftext|>', 'After', ' m', 'ary', ' and', ' and', 'res', ' went', ' to', ' the', ' bar', ',', ' m', 'ary', ' handed', ' some', ' beer', ' to']\n",
      "tokenized answer:  [' and', 'res']\n",
      "Logits for token:  and\n",
      "Top 0th logit. Logit = 13.555872917175293, prob = 15.62%, token =  the\n",
      "Logits for token: res\n",
      "Top 0th logit. Logit = 18.705718994140625, prob = 97.35%, token = res\n",
      "Difference Greater than Zero!, Top pred = None\n",
      "Input: After mary and andres went to the store, andres handed some beer to, logit diff = 0.4575920104980469\n",
      "Input: After Lori and Andres went to the store, Lori handed an apple to, logit diff = -4.1228532791137695\n",
      "Input: After Lori and Andres went to the store, Andres handed an apple to, logit diff = 2.7250118255615234\n",
      "Input: After Lori and andres went to the apartment, Lori handed some beer to, logit diff = -2.5691967010498047\n",
      "Input: After Lori and andres went to the store, andres handed some milk to, logit diff = 0.9568290710449219\n",
      "Input: After Lori and Andres went to the apartment, Lori handed some milk to, logit diff = -4.840227127075195\n",
      "Input: After Lori and Andres went to the bar, Andres handed some milk to, logit diff = 1.746011734008789\n",
      "Input: After John and Andres went to the apartment, John handed some milk to, logit diff = -3.5153160095214844\n",
      "Input: After John and Andres went to the bar, Andres handed some beer to, logit diff = 1.0413799285888672\n",
      "Input: After lori and andres went to the apartment, lori handed some milk to, logit diff = -1.2492809295654297\n",
      "Input: After lori and andres went to the park, andres handed a pencil to, logit diff = 0.9965066909790039\n"
     ]
    }
   ],
   "source": [
    "### looking at the logit differences (logits[first name] - logits[second name])\n",
    "\n",
    "assert len(logits_diff) == len(list(prompt_dict.keys())[1:])\n",
    "keys_list = list(prompt_dict.keys())[1:]\n",
    "for ind in range(len(logits_diff)):\n",
    "    print(f\"Input: {keys_list[ind]}, logit diff = {logits_diff[ind]}\")\n",
    "    ## for the first example in the pair, the second name should have higher probability, so the difference should be negative: \n",
    "    if ind%2 ==0 and logits_diff[ind] >0:\n",
    "        test =list(prompt_dict.items())[ind+1]\n",
    "\n",
    "        print(f\"Difference Greater than Zero!, Top pred = {get_top_preds(test[0], test[1],1)}\")\n",
    "       #assert logits_diff[ind] < 0\n",
    "    elif ind%2 !=0 and logits_diff[ind] < 0:\n",
    "        print(f\"Difference Less Than Zero!\")\n",
    "\n",
    "# logit differences make sense unless there are two lower cased names... \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise from notebook (Aside): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized prompt:  ['<|endoftext|>', 'The', ' Big', ' Government', ' Organisation', ' (', 'B', 'GO', ')', ' organised', ' the', ' Compl', 'icated', ' Bureau', 'cr', 'atic', ' D', 'all', 'iance', ' (']\n",
      "tokenized answer:  ['C', 'BD', ').', ' ']\n",
      "Logits for token: C\n",
      "Top 0th logit. Logit = 18.716259002685547, prob = 47.92%, token = C\n",
      "Top 1th logit. Logit = 17.525310516357422, prob = 14.56%, token = CC\n",
      "Logits for token: BD\n",
      "Top 0th logit. Logit = 16.978485107421875, prob = 33.23%, token = BD\n",
      "Top 1th logit. Logit = 15.589770317077637, prob = 8.29%, token = BO\n",
      "Logits for token: ).\n",
      "Top 0th logit. Logit = 17.5432186126709, prob = 77.99%, token = )\n",
      "Top 1th logit. Logit = 15.107534408569336, prob = 6.83%, token = ),\n",
      "Logits for token:  \n",
      "Top 0th logit. Logit = 18.157094955444336, prob = 24.18%, token = \n",
      "\n",
      "Top 1th logit. Logit = 17.881729125976562, prob = 18.36%, token =  The\n",
      "tokenized prompt:  ['<|endoftext|>', 'The', ' Big', ' Government', ' Organisation', ' (', 'B', 'GO', ')', ' organised', ' the', ' Compl', 'icated', ' Bureau', 'cr', 'atic', ' D', 'all', 'iance', ' (', 'C', 'BD', ')']\n",
      "tokenized answer:  ['.', ' ']\n",
      "Logits for token: .\n",
      "Top 0th logit. Logit = 18.157094955444336, prob = 24.18%, token = \n",
      "\n",
      "Top 1th logit. Logit = 17.881729125976562, prob = 18.36%, token =  The\n",
      "Logits for token:  \n",
      "Top 0th logit. Logit = 20.11578941345215, prob = 96.93%, token =  \n",
      "Top 1th logit. Logit = 14.628028869628906, prob = 0.40%, token = Â\n"
     ]
    }
   ],
   "source": [
    "get_top_preds(\"The Big Government Organisation (BGO) organised the Complicated Bureaucratic Dalliance (\", \"CBD). \", 2)\n",
    "get_top_preds(\"The Big Government Organisation (BGO) organised the Complicated Bureaucratic Dalliance (CBD)\", \". \", 2)\n",
    "\n",
    "### Doesn't guess \".\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing Activations: \n",
    "\n",
    "Let's compare the activations for a pair of prompts (where the logit diff is pos/neg). \n",
    "- Naive thing to try: look at the norm of the difference of internal activations within the model on the two inputs, thinking that the activations shouldn't be that similar. \n",
    "Exercise: Flaw in this approach: the norm of the difference is always positive, so won't give the relative importance of the activations. \n",
    "This also only works if the prompts are the same length (depending on the length of the name, and tokenization, this won't be true, and if it's not the approach will be mismatched (you think you are comparing the \"john\" and \"Andres\" tokens since the rest will be similar)). It's also probably not as good a measure as comparing the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"2425b4eb-57a6-4390-80b7-9f248710e257\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2425b4eb-57a6-4390-80b7-9f248710e257\")) {                    Plotly.newPlot(                        \"2425b4eb-57a6-4390-80b7-9f248710e257\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"0.<|endoftext|>\",\"1.After\",\"2. john\",\"3. and\",\"4. Laurel\",\"5. went\",\"6. to\",\"7. the\",\"8. bar\",\"9.,\",\"10. john\",\"11. handed\",\"12. some\",\"13. beer\",\"14. to\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8713212609291077,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8898298144340515,0.09352055937051773,0.04129130020737648,0.02652672305703163,0.030521800741553307],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8713661432266235,0.09360506385564804,0.03828378766775131,0.033378731459379196,0.029110856354236603],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8410515189170837,0.12649765610694885,0.04777342081069946,0.046808186918497086,0.03277924656867981],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8068846464157104,0.18129312992095947,0.0655883327126503,0.04627934843301773,0.039603590965270996],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7951058149337769,0.24841360747814178,0.07366963475942612,0.051196690648794174,0.048908933997154236],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7293565273284912,0.22262319922447205,0.075934499502182,0.05128030106425285,0.055798791348934174],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7169430255889893,0.2303445041179657,0.07139477878808975,0.04892798885703087,0.07205310463905334],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6864693760871887,0.28711313009262085,0.07376087456941605,0.04945250228047371,0.23298411071300507],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6210019588470459,0.35406219959259033,0.0882326066493988,0.05694403126835823,0.4090973734855652],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5477641820907593,0.4611997604370117,0.09066764265298843,0.06116687133908272,0.555313766002655],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4191793203353882,0.29776203632354736,0.07642322778701782,0.07460009306669235,0.3835701048374176]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Norm of Difference in: hook_resid_pre\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2425b4eb-57a6-4390-80b7-9f248710e257');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## choose two examples that are the \"reverse\" of one another AND the same size \n",
    "\n",
    "# example = 'After John and Mary went to the store, Mary handed a bottle of milk to'\n",
    "# reverse = 'After John and Mary went to the store, John handed a bottle of milk to'\n",
    "\n",
    "example = list(prompt_dict.keys())[5]\n",
    "reverse = list(prompt_dict.keys())[6]\n",
    "\n",
    "example_logits, example_cache = model.run_with_cache(example, remove_batch_dim= True)\n",
    "reverse_logits, reverse_cache = model.run_with_cache(reverse, remove_batch_dim= True)\n",
    "\n",
    "example_len = len(model.to_tokens(example, prepend_bos =True)[0])\n",
    "reverse_len = len(model.to_tokens(reverse, prepend_bos =True)[0])\n",
    "\n",
    "assert example_len == reverse_len\n",
    "def get_norm_diff(cache1, cache2, example_len, hook):\n",
    "    # initialize\n",
    "    norm_diff = t.zeros(model.cfg.n_layers, example_len)\n",
    "    model.cfg.n_layers\n",
    "    for layer in range(model.cfg.n_layers):\n",
    "        example_result = cache1[f\"blocks.{layer}.{hook}\"]\n",
    "        reverse_result = cache2[f\"blocks.{layer}.{hook}\"]\n",
    "\n",
    "        result_diff = example_result - reverse_result\n",
    "        #normalize the residual difference by the average size of the original\n",
    "        norm_diff[layer] = result_diff.norm(dim = -1)/ t.sqrt(example_result.norm(dim=-1)*reverse_result.norm(dim=-1))\n",
    "    example_str_toks = model.to_str_tokens(example, prepend_bos =True)\n",
    "    x_labels = [f\"{n}.{tok}\" for n, tok in enumerate(example_str_toks)]\n",
    "    imshow(norm_diff, yaxis = \"Layer\", title = f'Norm of Difference in: {hook}', x = x_labels)\n",
    "## norm in d_model (embedding dimension)\n",
    "get_norm_diff(example_cache, reverse_cache, example_len, 'hook_resid_pre')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15, 3072]) torch.Size([15, 3072]) torch.Size([15, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(example_cache['blocks.0.mlp.hook_pre'].shape,example_cache['blocks.0.mlp.hook_post'].shape,example_cache['blocks.0.hook_mlp_out'].shape)\n",
    "model.cfg.d_mlp / model.cfg.d_model #Why?? \n",
    "#model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"2b289ce9-7827-4f99-9103-b575e3781bdd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2b289ce9-7827-4f99-9103-b575e3781bdd\")) {                    Plotly.newPlot(                        \"2b289ce9-7827-4f99-9103-b575e3781bdd\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"0.<|endoftext|>\",\"1.After\",\"2. john\",\"3. and\",\"4. Laurel\",\"5. went\",\"6. to\",\"7. the\",\"8. bar\",\"9.,\",\"10. john\",\"11. handed\",\"12. some\",\"13. beer\",\"14. to\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5355291962623596,0.1166817918419838,0.07554364204406738,0.04220426455140114,0.06303563714027405],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7378897070884705,0.42958173155784607,0.25477662682533264,0.2001066356897354,0.2162570059299469],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5411847233772278,0.5038331151008606,0.1929885745048523,0.19952580332756042,0.11847727745771408],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7945427298545837,0.7280834317207336,0.3211018443107605,0.2167849838733673,0.16061931848526],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6034904718399048,0.908606231212616,0.23672373592853546,0.1958024650812149,0.16537609696388245],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0030630826950073,0.4047689139842987,0.25032129883766174,0.19971323013305664,0.14716531336307526],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.8299964666366577,0.4770215153694153,0.24862955510616302,0.20358794927597046,0.3238789141178131],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.843867838382721,1.169641375541687,0.37158331274986267,0.26378756761550903,1.0806958675384521],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3935961425304413,0.836976170539856,0.33653345704078674,0.26429152488708496,0.826921820640564],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.16899895668029785,0.9918304681777954,0.34624916315078735,0.24123188853263855,1.1120750904083252],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.1704970896244049,0.8258596062660217,0.15297017991542816,0.47780144214630127,0.910485565662384],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.038730084896087646,0.06105788052082062,0.03554203733801842,0.04511277750134468,0.11184680461883545]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Norm of Difference in: hook_attn_out\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2b289ce9-7827-4f99-9103-b575e3781bdd');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## for the attention layers \n",
    "### Also the residual stream after the attention layer, so summing over embedding dimension (represents features?)\n",
    "get_norm_diff(example_cache, reverse_cache, example_len, 'hook_attn_out')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"fb7b1fb5-3473-4c1e-8f20-176fc8aac4e0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"fb7b1fb5-3473-4c1e-8f20-176fc8aac4e0\")) {                    Plotly.newPlot(                        \"fb7b1fb5-3473-4c1e-8f20-176fc8aac4e0\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"0.<|endoftext|>\",\"1.After\",\"2. john\",\"3. and\",\"4. Laurel\",\"5. went\",\"6. to\",\"7. the\",\"8. bar\",\"9.,\",\"10. john\",\"11. handed\",\"12. some\",\"13. beer\",\"14. to\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7052844166755676,0.10338674485683441,0.060180969536304474,0.03808193653821945,0.04219305142760277],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5533249974250793,0.09059291332960129,0.04812222346663475,0.034639205783605576,0.03407316654920578],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.49223795533180237,0.10908810049295425,0.04757224768400192,0.04041184112429619,0.02890356257557869],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4371338486671448,0.13564932346343994,0.05487988889217377,0.03991467133164406,0.031010473147034645],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.4040193259716034,0.18790891766548157,0.0566706582903862,0.043316736817359924,0.041525185108184814],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.36292603611946106,0.15090607106685638,0.05385352671146393,0.037260789424180984,0.04187820106744766],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.37354207038879395,0.1427665799856186,0.05479517579078674,0.03565811738371849,0.053739190101623535],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.41640710830688477,0.15037211775779724,0.05238104239106178,0.036173637956380844,0.143242746591568],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.38145557045936584,0.20001639425754547,0.06478729099035263,0.04043564572930336,0.23562027513980865],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.35618487000465393,0.26313507556915283,0.06813815236091614,0.04575888067483902,0.3052496314048767],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3439309000968933,0.22762662172317505,0.060193393379449844,0.059720803052186966,0.2592005133628845],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.30586689710617065,0.18821999430656433,0.06428270041942596,0.0681387335062027,0.21732935309410095]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Norm of Difference in: mlp.hook_pre\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('fb7b1fb5-3473-4c1e-8f20-176fc8aac4e0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"6ce717a7-aabc-40f6-9db2-9dde9e4a18c0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6ce717a7-aabc-40f6-9db2-9dde9e4a18c0\")) {                    Plotly.newPlot(                        \"6ce717a7-aabc-40f6-9db2-9dde9e4a18c0\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"0.<|endoftext|>\",\"1.After\",\"2. john\",\"3. and\",\"4. Laurel\",\"5. went\",\"6. to\",\"7. the\",\"8. bar\",\"9.,\",\"10. john\",\"11. handed\",\"12. some\",\"13. beer\",\"14. to\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.1289925575256348,0.1652236431837082,0.06845365464687347,0.05675731971859932,0.06985614448785782],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9717681407928467,0.20718908309936523,0.11532168090343475,0.08350884169340134,0.12663282454013824],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9270557165145874,0.24150125682353973,0.11846956610679626,0.10195604711771011,0.08576960861682892],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7953058481216431,0.3277173936367035,0.13526657223701477,0.09329695999622345,0.08359436690807343],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7861052751541138,0.38380587100982666,0.12673170864582062,0.10390820354223251,0.09436457604169846],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7095386981964111,0.36374497413635254,0.12836232781410217,0.08883216977119446,0.0936671793460846],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.667353093624115,0.3014375865459442,0.11388005316257477,0.08198324590921402,0.11125242710113525],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6908855438232422,0.3454175889492035,0.10408924520015717,0.07311826199293137,0.2688380479812622],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6291698813438416,0.3878535330295563,0.13172970712184906,0.08702471852302551,0.4624309241771698],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5343410968780518,0.5303518176078796,0.13263630867004395,0.09880078583955765,0.5850160121917725],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5350143909454346,0.36923763155937195,0.10881473124027252,0.09816689789295197,0.43578094244003296],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.47958552837371826,0.34114816784858704,0.10122130811214447,0.09565377235412598,0.34227532148361206]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Norm of Difference in: mlp.hook_post\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('6ce717a7-aabc-40f6-9db2-9dde9e4a18c0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"8139b936-81b4-4329-9204-92a9d7c85cef\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8139b936-81b4-4329-9204-92a9d7c85cef\")) {                    Plotly.newPlot(                        \"8139b936-81b4-4329-9204-92a9d7c85cef\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"0.<|endoftext|>\",\"1.After\",\"2. john\",\"3. and\",\"4. Laurel\",\"5. went\",\"6. to\",\"7. the\",\"8. bar\",\"9.,\",\"10. john\",\"11. handed\",\"12. some\",\"13. beer\",\"14. to\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.2149934768676758,0.12747973203659058,0.06061488762497902,0.040787145495414734,0.05843771994113922],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.163710355758667,0.3027070462703705,0.1968359500169754,0.1378823071718216,0.24156002700328827],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.1007829904556274,0.30742931365966797,0.20705965161323547,0.1532467007637024,0.17224033176898956],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.124930739402771,0.4665862023830414,0.2088860720396042,0.1107402816414833,0.12430094182491302],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0782828330993652,0.4628976285457611,0.1846555769443512,0.15949799120426178,0.14921635389328003],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0995272397994995,0.5875737071037292,0.17868253588676453,0.12593263387680054,0.11963611096143723],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0025421380996704,0.4617826044559479,0.14504340291023254,0.10597124695777893,0.18312305212020874],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0906728506088257,0.47143781185150146,0.14849333465099335,0.09266036748886108,0.4039159119129181],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.906861424446106,0.48954102396965027,0.17473994195461273,0.12057715654373169,0.6115706562995911],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7905925512313843,0.517874538898468,0.12595587968826294,0.12539151310920715,0.7189755439758301],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.45286116003990173,0.2542954087257385,0.0817561000585556,0.08681421726942062,0.3337327241897583],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.36654219031333923,0.3999249041080475,0.18210315704345703,0.11617878824472427,0.3481254577636719]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Norm of Difference in: hook_mlp_out\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('8139b936-81b4-4329-9204-92a9d7c85cef');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(model.blocks[0])\n",
    "## hook_pre and hook_post are summing over d_mlp, mlp_out is summing over d_model \n",
    "get_norm_diff(example_cache, reverse_cache, example_len, 'mlp.hook_pre')\n",
    "get_norm_diff(example_cache, reverse_cache, example_len, 'mlp.hook_post')\n",
    "get_norm_diff(example_cache, reverse_cache, example_len, 'hook_mlp_out')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plots, the token with the greatest difference in attention for the two examples is the name token in the second half of the sentence, during the early layers of the network, which makes sense. At later layers, the last token \"to\" also becomes important, and the difference also becomes larger, since each sentence will learn difference names for what comes next. \n",
    "\n",
    "Instead of looking at the difference across layers for each token in the context, next we'll plot the difference of the attention patterns across layers and attention heads. The pattern is not super clear to me, but it seems like the n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 15, 15])\n",
      "torch.Size([15, 768])\n",
      "torch.Size([15, 768])\n"
     ]
    }
   ],
   "source": [
    "print(example_cache[f\"blocks.0.attn.hook_pattern\"].shape) ## (n_heads, n_context, n_context)\n",
    "print(example_cache[f\"blocks.0.hook_attn_out\"].shape) ## (n_heads, d_model)\n",
    "print(example_cache[f\"blocks.0.hook_resid_mid\"].shape) ## (n_heads, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized'])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"c61d7844-227c-4c86-9b58-1910407d070c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c61d7844-227c-4c86-9b58-1910407d070c\")) {                    Plotly.newPlot(                        \"c61d7844-227c-4c86-9b58-1910407d070c\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.09327296167612076,0.18760640919208527,0.05836663395166397,0.01842390187084675,0.07307173311710358,0.2479858547449112,0.09017489105463028,0.1567142754793167,0.05841595679521561,0.04224947467446327,0.14918464422225952,0.047927577048540115],[0.10793641209602356,0.08727995306253433,0.011691163294017315,0.024924149736762047,0.015545269474387169,0.07140392810106277,0.10325879603624344,0.03599489852786064,0.019395871087908745,0.03854145109653473,0.01019721943885088,0.351990282535553],[0.09107498824596405,0.09237571060657501,0.12291600555181503,0.045083437114953995,0.055244386196136475,0.04477180540561676,0.03135034814476967,0.03154187276959419,0.07679128646850586,0.057679809629917145,0.016445405781269073,0.009693874046206474],[0.3021394908428192,0.047786276787519455,0.09479381889104843,0.12079286575317383,0.04121158644556999,0.046443063765764236,0.12835189700126648,0.18002723157405853,0.06475268304347992,0.05631892755627632,0.029271509498357773,0.08457107096910477],[0.06343633681535721,0.10408362746238708,0.028826754540205002,0.04173516109585762,0.05020184814929962,0.052925631403923035,0.05017394945025444,0.045892324298620224,0.06312043219804764,0.057549573481082916,0.029681622982025146,0.00017246474453713745],[0.2212231308221817,0.09140037000179291,0.025924576446413994,0.05308837816119194,0.0492144376039505,0.34503698348999023,0.03805987909436226,0.0389668308198452,0.18766875565052032,0.09253495931625366,0.16419781744480133,0.03836462274193764],[0.07279440760612488,0.03657280281186104,0.024922190234065056,0.027267353609204292,0.06173943728208542,0.0459769032895565,0.038782715797424316,0.042717188596725464,0.03117552399635315,0.22482797503471375,0.03309306502342224,0.06255506724119186],[0.023341039195656776,0.15492033958435059,0.01126917451620102,0.07785408198833466,0.017904343083500862,0.03554602339863777,0.021348273381590843,0.018780408427119255,0.04651198536157608,0.14428411424160004,0.05935421958565712,0.027295464649796486],[0.02639777585864067,0.01700397953391075,0.12686076760292053,0.06042901799082756,0.05819731578230858,0.027538031339645386,0.0485820472240448,0.07037729769945145,0.05328327417373657,0.033521585166454315,0.06351184099912643,0.04120597243309021],[0.15560322999954224,0.05010809004306793,0.08197841793298721,0.06822115182876587,0.04089941084384918,0.018938466906547546,0.2856771945953369,0.042580701410770416,0.062486447393894196,0.3775380551815033,0.022167332470417023,0.05351683869957924],[0.171820268034935,0.11261399835348129,0.09802810102701187,0.02262760140001774,0.06845405697822571,0.03627663850784302,0.21993546187877655,0.4427882134914398,0.021504785865545273,0.08758681267499924,0.15951666235923767,0.10277735441923141],[0.08341683447360992,0.07888507097959518,0.06497733294963837,0.09453488141298294,0.048525866121053696,0.0578204020857811,0.03421765938401222,0.03837556764483452,0.1593049019575119,0.06723321974277496,0.33140361309051514,0.08882700651884079]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Heads: %{x}<br>Layer: %{y}<br>color: %{z}<extra></extra>\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Heads\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Norm of difference of Attention Pattern\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c61d7844-227c-4c86-9b58-1910407d070c');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "norm_diff = t.zeros(model.cfg.n_layers, model.cfg.n_heads)\n",
    "dims = [-2,-1]\n",
    "hook = 'attn.hook_pattern'\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    example_result = example_cache[f\"blocks.{layer}.{hook}\"]\n",
    "    reverse_result = reverse_cache[f\"blocks.{layer}.{hook}\"]\n",
    "    diff = example_result - reverse_result \n",
    "    a = norm_multi_dim(diff, dims)\n",
    "    b = norm_multi_dim(example_result, dims)\n",
    "    c = norm_multi_dim(reverse_result, dims)\n",
    "    #print(a.shape,b.shape, c.shape, example_result.shape)\n",
    "    norm_diff[layer] = a/t.sqrt(b*c)\n",
    "imshow(norm_diff, yaxis = 'Layer', xaxis = 'Heads', title = \"Norm of difference of Attention Pattern\")\n",
    "\n",
    "model.cfg.n_layers, model.cfg.n_heads\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ablating Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablate_layer_hook(layer_out, hook):\n",
    "    layer_out[:] = 0\n",
    "    return layer_out\n",
    "def \n",
    "attn_ablation = []\n",
    "for layer in range(model.cfg.n_layers):\n",
    "    logits = model.run_with_hooks(example_prompt, fwd_hooks = [(f\"blocks.{layer}.hook_attn_out\", ablate_layer_hook)])\n",
    "    ablated_logit_diff = get_logit_diff(logits)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~',\n",
       " '¡',\n",
       " '¢',\n",
       " '£',\n",
       " '¤',\n",
       " '¥',\n",
       " '¦',\n",
       " '§',\n",
       " '¨',\n",
       " '©',\n",
       " 'ª',\n",
       " '«',\n",
       " '¬',\n",
       " '®',\n",
       " '¯',\n",
       " '°',\n",
       " '±',\n",
       " '²',\n",
       " '³',\n",
       " '´',\n",
       " 'µ',\n",
       " '¶',\n",
       " '·',\n",
       " '¸',\n",
       " '¹',\n",
       " 'º',\n",
       " '»',\n",
       " '¼',\n",
       " '½',\n",
       " '¾',\n",
       " '¿',\n",
       " 'À',\n",
       " 'Á',\n",
       " 'Â',\n",
       " 'Ã',\n",
       " 'Ä',\n",
       " 'Å',\n",
       " 'Æ',\n",
       " 'Ç',\n",
       " 'È',\n",
       " 'É',\n",
       " 'Ê',\n",
       " 'Ë',\n",
       " 'Ì',\n",
       " 'Í',\n",
       " 'Î',\n",
       " 'Ï',\n",
       " 'Ð',\n",
       " 'Ñ',\n",
       " 'Ò',\n",
       " 'Ó',\n",
       " 'Ô',\n",
       " 'Õ',\n",
       " 'Ö',\n",
       " '×',\n",
       " 'Ø',\n",
       " 'Ù',\n",
       " 'Ú',\n",
       " 'Û',\n",
       " 'Ü',\n",
       " 'Ý',\n",
       " 'Þ',\n",
       " 'ß',\n",
       " 'à',\n",
       " 'á',\n",
       " 'â',\n",
       " 'ã',\n",
       " 'ä',\n",
       " 'å',\n",
       " 'æ',\n",
       " 'ç',\n",
       " 'è',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'ë',\n",
       " 'ì',\n",
       " 'í',\n",
       " 'î',\n",
       " 'ï',\n",
       " 'ð',\n",
       " 'ñ',\n",
       " 'ò',\n",
       " 'ó',\n",
       " 'ô',\n",
       " 'õ',\n",
       " 'ö',\n",
       " '÷',\n",
       " 'ø',\n",
       " 'ù',\n",
       " 'ú',\n",
       " 'û',\n",
       " 'ü',\n",
       " 'ý',\n",
       " 'þ',\n",
       " 'ÿ',\n",
       " 'Ā',\n",
       " 'ā',\n",
       " 'Ă',\n",
       " 'ă',\n",
       " 'Ą',\n",
       " 'ą',\n",
       " 'Ć',\n",
       " 'ć',\n",
       " 'Ĉ',\n",
       " 'ĉ',\n",
       " 'Ċ',\n",
       " 'ċ',\n",
       " 'Č',\n",
       " 'č',\n",
       " 'Ď',\n",
       " 'ď',\n",
       " 'Đ',\n",
       " 'đ',\n",
       " 'Ē',\n",
       " 'ē',\n",
       " 'Ĕ',\n",
       " 'ĕ',\n",
       " 'Ė',\n",
       " 'ė',\n",
       " 'Ę',\n",
       " 'ę',\n",
       " 'Ě',\n",
       " 'ě',\n",
       " 'Ĝ',\n",
       " 'ĝ',\n",
       " 'Ğ',\n",
       " 'ğ',\n",
       " 'Ġ',\n",
       " 'ġ',\n",
       " 'Ģ',\n",
       " 'ģ',\n",
       " 'Ĥ',\n",
       " 'ĥ',\n",
       " 'Ħ',\n",
       " 'ħ',\n",
       " 'Ĩ',\n",
       " 'ĩ',\n",
       " 'Ī',\n",
       " 'ī',\n",
       " 'Ĭ',\n",
       " 'ĭ',\n",
       " 'Į',\n",
       " 'į',\n",
       " 'İ',\n",
       " 'ı',\n",
       " 'Ĳ',\n",
       " 'ĳ',\n",
       " 'Ĵ',\n",
       " 'ĵ',\n",
       " 'Ķ',\n",
       " 'ķ',\n",
       " 'ĸ',\n",
       " 'Ĺ',\n",
       " 'ĺ',\n",
       " 'Ļ',\n",
       " 'ļ',\n",
       " 'Ľ',\n",
       " 'ľ',\n",
       " 'Ŀ',\n",
       " 'ŀ',\n",
       " 'Ł',\n",
       " 'ł',\n",
       " 'Ń',\n",
       " 'Ġt',\n",
       " 'Ġa',\n",
       " 'he',\n",
       " 'in',\n",
       " 're',\n",
       " 'on',\n",
       " 'Ġthe',\n",
       " 'er',\n",
       " 'Ġs',\n",
       " 'at',\n",
       " 'Ġw',\n",
       " 'Ġo',\n",
       " 'en',\n",
       " 'Ġc',\n",
       " 'it',\n",
       " 'is',\n",
       " 'an',\n",
       " 'or',\n",
       " 'es',\n",
       " 'Ġb',\n",
       " 'ed',\n",
       " 'Ġf',\n",
       " 'ing',\n",
       " 'Ġp',\n",
       " 'ou',\n",
       " 'Ġan',\n",
       " 'al',\n",
       " 'ar',\n",
       " 'Ġto',\n",
       " 'Ġm',\n",
       " 'Ġof',\n",
       " 'Ġin',\n",
       " 'Ġd',\n",
       " 'Ġh',\n",
       " 'Ġand',\n",
       " 'ic',\n",
       " 'as',\n",
       " 'le',\n",
       " 'Ġth',\n",
       " 'ion',\n",
       " 'om',\n",
       " 'll',\n",
       " 'ent',\n",
       " 'Ġn',\n",
       " 'Ġl',\n",
       " 'st',\n",
       " 'Ġre',\n",
       " 've',\n",
       " 'Ġe',\n",
       " 'ro',\n",
       " 'ly',\n",
       " 'Ġbe',\n",
       " 'Ġg',\n",
       " 'ĠT',\n",
       " 'ct',\n",
       " 'ĠS',\n",
       " 'id',\n",
       " 'ot',\n",
       " 'ĠI',\n",
       " 'ut',\n",
       " 'et',\n",
       " 'ĠA',\n",
       " 'Ġis',\n",
       " 'Ġon',\n",
       " 'im',\n",
       " 'am',\n",
       " 'ow',\n",
       " 'ay',\n",
       " 'ad',\n",
       " 'se',\n",
       " 'Ġthat',\n",
       " 'ĠC',\n",
       " 'ig',\n",
       " 'Ġfor',\n",
       " 'ac',\n",
       " 'Ġy',\n",
       " 'ver',\n",
       " 'ur',\n",
       " 'Ġu',\n",
       " 'ld',\n",
       " 'Ġst',\n",
       " 'ĠM',\n",
       " \"'s\",\n",
       " 'Ġhe',\n",
       " 'Ġit',\n",
       " 'ation',\n",
       " 'ith',\n",
       " 'ir',\n",
       " 'ce',\n",
       " 'Ġyou',\n",
       " 'il',\n",
       " 'ĠB',\n",
       " 'Ġwh',\n",
       " 'ol',\n",
       " 'ĠP',\n",
       " 'Ġwith',\n",
       " 'Ġ1',\n",
       " 'ter',\n",
       " 'ch',\n",
       " 'Ġas',\n",
       " 'Ġwe',\n",
       " 'Ġ(',\n",
       " 'nd',\n",
       " 'ill',\n",
       " 'ĠD',\n",
       " 'if',\n",
       " 'Ġ2',\n",
       " 'ag',\n",
       " 'ers',\n",
       " 'ke',\n",
       " 'Ġ\"',\n",
       " 'ĠH',\n",
       " 'em',\n",
       " 'Ġcon',\n",
       " 'ĠW',\n",
       " 'ĠR',\n",
       " 'her',\n",
       " 'Ġwas',\n",
       " 'Ġr',\n",
       " 'od',\n",
       " 'ĠF',\n",
       " 'ul',\n",
       " 'ate',\n",
       " 'Ġat',\n",
       " 'ri',\n",
       " 'pp',\n",
       " 'ore',\n",
       " 'ĠThe',\n",
       " 'Ġse',\n",
       " 'us',\n",
       " 'Ġpro',\n",
       " 'Ġha',\n",
       " 'um',\n",
       " 'Ġare',\n",
       " 'Ġde',\n",
       " 'ain',\n",
       " 'and',\n",
       " 'Ġor',\n",
       " 'igh',\n",
       " 'est',\n",
       " 'ist',\n",
       " 'ab',\n",
       " 'rom',\n",
       " 'ĠN',\n",
       " 'th',\n",
       " 'Ġcom',\n",
       " 'ĠG',\n",
       " 'un',\n",
       " 'op',\n",
       " '00',\n",
       " 'ĠL',\n",
       " 'Ġnot',\n",
       " 'ess',\n",
       " 'Ġex',\n",
       " 'Ġv',\n",
       " 'res',\n",
       " 'ĠE',\n",
       " 'ew',\n",
       " 'ity',\n",
       " 'ant',\n",
       " 'Ġby',\n",
       " 'el',\n",
       " 'os',\n",
       " 'ort',\n",
       " 'oc',\n",
       " 'qu',\n",
       " 'Ġfrom',\n",
       " 'Ġhave',\n",
       " 'Ġsu',\n",
       " 'ive',\n",
       " 'ould',\n",
       " 'Ġsh',\n",
       " 'Ġthis',\n",
       " 'nt',\n",
       " 'ra',\n",
       " 'pe',\n",
       " 'ight',\n",
       " 'art',\n",
       " 'ment',\n",
       " 'Ġal',\n",
       " 'ust',\n",
       " 'end',\n",
       " '--',\n",
       " 'all',\n",
       " 'ĠO',\n",
       " 'ack',\n",
       " 'Ġch',\n",
       " 'Ġle',\n",
       " 'ies',\n",
       " 'red',\n",
       " 'ard',\n",
       " 'âĢ',\n",
       " 'out',\n",
       " 'ĠJ',\n",
       " 'Ġab',\n",
       " 'ear',\n",
       " 'iv',\n",
       " 'ally',\n",
       " 'our',\n",
       " 'ost',\n",
       " 'gh',\n",
       " 'pt',\n",
       " 'Ġpl',\n",
       " 'ast',\n",
       " 'Ġcan',\n",
       " 'ak',\n",
       " 'ome',\n",
       " 'ud',\n",
       " 'The',\n",
       " 'Ġhis',\n",
       " 'Ġdo',\n",
       " 'Ġgo',\n",
       " 'Ġhas',\n",
       " 'ge',\n",
       " \"'t\",\n",
       " 'ĠU',\n",
       " 'rou',\n",
       " 'Ġsa',\n",
       " 'Ġj',\n",
       " 'Ġbut',\n",
       " 'Ġwor',\n",
       " 'Ġall',\n",
       " 'ect',\n",
       " 'Ġk',\n",
       " 'ame',\n",
       " 'Ġwill',\n",
       " 'ok',\n",
       " 'Ġwhe',\n",
       " 'Ġthey',\n",
       " 'ide',\n",
       " '01',\n",
       " 'ff',\n",
       " 'ich',\n",
       " 'pl',\n",
       " 'ther',\n",
       " 'Ġtr',\n",
       " '..',\n",
       " 'Ġint',\n",
       " 'ie',\n",
       " 'ure',\n",
       " 'age',\n",
       " 'Ġne',\n",
       " 'ial',\n",
       " 'ap',\n",
       " 'ine',\n",
       " 'ice',\n",
       " 'Ġme',\n",
       " 'Ġout',\n",
       " 'ans',\n",
       " 'one',\n",
       " 'ong',\n",
       " 'ions',\n",
       " 'Ġwho',\n",
       " 'ĠK',\n",
       " 'Ġup',\n",
       " 'Ġtheir',\n",
       " 'Ġad',\n",
       " 'Ġ3',\n",
       " 'Ġus',\n",
       " 'ated',\n",
       " 'ous',\n",
       " 'Ġmore',\n",
       " 'ue',\n",
       " 'og',\n",
       " 'ĠSt',\n",
       " 'ind',\n",
       " 'ike',\n",
       " 'Ġso',\n",
       " 'ime',\n",
       " 'per',\n",
       " '.\"',\n",
       " 'ber',\n",
       " 'iz',\n",
       " 'act',\n",
       " 'Ġone',\n",
       " 'Ġsaid',\n",
       " 'Ġ-',\n",
       " 'are',\n",
       " 'Ġyour',\n",
       " 'cc',\n",
       " 'ĠTh',\n",
       " 'Ġcl',\n",
       " 'ep',\n",
       " 'ake',\n",
       " 'able',\n",
       " 'ip',\n",
       " 'Ġcont',\n",
       " 'Ġwhich',\n",
       " 'ia',\n",
       " 'Ġim',\n",
       " 'Ġabout',\n",
       " 'Ġwere',\n",
       " 'very',\n",
       " 'ub',\n",
       " 'Ġhad',\n",
       " 'Ġen',\n",
       " 'Ġcomp',\n",
       " ',\"',\n",
       " 'ĠIn',\n",
       " 'Ġun',\n",
       " 'Ġag',\n",
       " 'ire',\n",
       " 'ace',\n",
       " 'au',\n",
       " 'ary',\n",
       " 'Ġwould',\n",
       " 'ass',\n",
       " 'ry',\n",
       " 'ĠâĢ',\n",
       " 'cl',\n",
       " 'ook',\n",
       " 'ere',\n",
       " 'so',\n",
       " 'ĠV',\n",
       " 'ign',\n",
       " 'ib',\n",
       " 'Ġoff',\n",
       " 'Ġte',\n",
       " 'ven',\n",
       " 'ĠY',\n",
       " 'ile',\n",
       " 'ose',\n",
       " 'ite',\n",
       " 'orm',\n",
       " 'Ġ201',\n",
       " 'Ġres',\n",
       " 'Ġman',\n",
       " 'Ġper',\n",
       " 'Ġother',\n",
       " 'ord',\n",
       " 'ult',\n",
       " 'Ġbeen',\n",
       " 'Ġlike',\n",
       " 'ase',\n",
       " 'ance',\n",
       " 'ks',\n",
       " 'ays',\n",
       " 'own',\n",
       " 'ence',\n",
       " 'Ġdis',\n",
       " 'ction',\n",
       " 'Ġany',\n",
       " 'Ġapp',\n",
       " 'Ġsp',\n",
       " 'int',\n",
       " 'ress',\n",
       " 'ations',\n",
       " 'ail',\n",
       " 'Ġ4',\n",
       " 'ical',\n",
       " 'Ġthem',\n",
       " 'Ġher',\n",
       " 'ount',\n",
       " 'ĠCh',\n",
       " 'Ġar',\n",
       " 'Ġif',\n",
       " 'Ġthere',\n",
       " 'Ġpe',\n",
       " 'Ġyear',\n",
       " 'av',\n",
       " 'Ġmy',\n",
       " 'Ġsome',\n",
       " 'Ġwhen',\n",
       " 'ough',\n",
       " 'ach',\n",
       " 'Ġthan',\n",
       " 'ru',\n",
       " 'ond',\n",
       " 'ick',\n",
       " 'Ġover',\n",
       " 'vel',\n",
       " 'Ġqu',\n",
       " 'ĊĊ',\n",
       " 'Ġsc',\n",
       " 'reat',\n",
       " 'ree',\n",
       " 'ĠIt',\n",
       " 'ound',\n",
       " 'port',\n",
       " 'Ġalso',\n",
       " 'Ġpart',\n",
       " 'fter',\n",
       " 'Ġkn',\n",
       " 'Ġbec',\n",
       " 'Ġtime',\n",
       " 'ens',\n",
       " 'Ġ5',\n",
       " 'ople',\n",
       " 'Ġwhat',\n",
       " 'Ġno',\n",
       " 'du',\n",
       " 'mer',\n",
       " 'ang',\n",
       " 'Ġnew',\n",
       " '----',\n",
       " 'Ġget',\n",
       " 'ory',\n",
       " 'ition',\n",
       " 'ings',\n",
       " 'Ġjust',\n",
       " 'Ġinto',\n",
       " 'Ġ0',\n",
       " 'ents',\n",
       " 'ove',\n",
       " 'te',\n",
       " 'Ġpeople',\n",
       " 'Ġpre',\n",
       " 'Ġits',\n",
       " 'Ġrec',\n",
       " 'Ġtw',\n",
       " 'ian',\n",
       " 'irst',\n",
       " 'ark',\n",
       " 'ors',\n",
       " 'Ġwork',\n",
       " 'ade',\n",
       " 'ob',\n",
       " 'Ġshe',\n",
       " 'Ġour',\n",
       " 'wn',\n",
       " 'ink',\n",
       " 'lic',\n",
       " 'Ġ19',\n",
       " 'ĠHe',\n",
       " 'ish',\n",
       " 'nder',\n",
       " 'ause',\n",
       " 'Ġhim',\n",
       " 'ons',\n",
       " 'Ġ[',\n",
       " 'Ġro',\n",
       " 'form',\n",
       " 'ild',\n",
       " 'ates',\n",
       " 'vers',\n",
       " 'Ġonly',\n",
       " 'oll',\n",
       " 'Ġspe',\n",
       " 'ck',\n",
       " 'ell',\n",
       " 'amp',\n",
       " 'Ġacc',\n",
       " 'Ġbl',\n",
       " 'ious',\n",
       " 'urn',\n",
       " 'ft',\n",
       " 'ood',\n",
       " 'Ġhow',\n",
       " 'hed',\n",
       " \"Ġ'\",\n",
       " 'Ġafter',\n",
       " 'aw',\n",
       " 'Ġatt',\n",
       " 'ov',\n",
       " 'ne',\n",
       " 'Ġplay',\n",
       " 'erv',\n",
       " 'ict',\n",
       " 'Ġcould',\n",
       " 'itt',\n",
       " 'Ġam',\n",
       " 'Ġfirst',\n",
       " 'Ġ6',\n",
       " 'Ġact',\n",
       " 'Ġ$',\n",
       " 'ec',\n",
       " 'hing',\n",
       " 'ual',\n",
       " 'ull',\n",
       " 'Ġcomm',\n",
       " 'oy',\n",
       " 'old',\n",
       " 'ces',\n",
       " 'ater',\n",
       " 'Ġfe',\n",
       " 'Ġbet',\n",
       " 'we',\n",
       " 'iff',\n",
       " 'Ġtwo',\n",
       " 'ock',\n",
       " 'Ġback',\n",
       " ').',\n",
       " 'ident',\n",
       " 'Ġunder',\n",
       " 'rough',\n",
       " 'sel',\n",
       " 'xt',\n",
       " 'Ġmay',\n",
       " 'round',\n",
       " 'Ġpo',\n",
       " 'ph',\n",
       " 'iss',\n",
       " 'Ġdes',\n",
       " 'Ġmost',\n",
       " 'Ġdid',\n",
       " 'Ġadd',\n",
       " 'ject',\n",
       " 'Ġinc',\n",
       " 'fore',\n",
       " 'Ġpol',\n",
       " 'ont',\n",
       " 'Ġagain',\n",
       " 'clud',\n",
       " 'tern',\n",
       " 'Ġknow',\n",
       " 'Ġneed',\n",
       " 'Ġcons',\n",
       " 'Ġco',\n",
       " 'Ġ.',\n",
       " 'Ġwant',\n",
       " 'Ġsee',\n",
       " 'Ġ7',\n",
       " 'ning',\n",
       " 'iew',\n",
       " 'ĠThis',\n",
       " 'ced',\n",
       " 'Ġeven',\n",
       " 'Ġind',\n",
       " 'ty',\n",
       " 'ĠWe',\n",
       " 'ath',\n",
       " 'Ġthese',\n",
       " 'Ġpr',\n",
       " 'Ġuse',\n",
       " 'Ġbecause',\n",
       " 'Ġfl',\n",
       " 'ng',\n",
       " 'Ġnow',\n",
       " 'ĠâĢĵ',\n",
       " 'com',\n",
       " 'ise',\n",
       " 'Ġmake',\n",
       " 'Ġthen',\n",
       " 'ower',\n",
       " 'Ġevery',\n",
       " 'ĠUn',\n",
       " 'Ġsec',\n",
       " 'oss',\n",
       " 'uch',\n",
       " 'Ġem',\n",
       " 'Ġ=',\n",
       " 'ĠRe',\n",
       " 'ied',\n",
       " 'rit',\n",
       " 'Ġinv',\n",
       " 'lect',\n",
       " 'Ġsupp',\n",
       " 'ating',\n",
       " 'Ġlook',\n",
       " 'man',\n",
       " 'pect',\n",
       " 'Ġ8',\n",
       " 'row',\n",
       " 'Ġbu',\n",
       " 'Ġwhere',\n",
       " 'ific',\n",
       " 'Ġyears',\n",
       " 'ily',\n",
       " 'Ġdiff',\n",
       " 'Ġshould',\n",
       " 'Ġrem',\n",
       " 'Th',\n",
       " 'In',\n",
       " 'Ġev',\n",
       " 'day',\n",
       " \"'re\",\n",
       " 'rib',\n",
       " 'Ġrel',\n",
       " 'ss',\n",
       " 'Ġdef',\n",
       " 'Ġright',\n",
       " 'Ġsy',\n",
       " '),',\n",
       " 'les',\n",
       " '000',\n",
       " 'hen',\n",
       " 'Ġthrough',\n",
       " 'ĠTr',\n",
       " '__',\n",
       " 'Ġway',\n",
       " 'Ġdon',\n",
       " 'Ġ,',\n",
       " 'Ġ10',\n",
       " 'ased',\n",
       " 'Ġass',\n",
       " 'ublic',\n",
       " 'Ġreg',\n",
       " 'ĠAnd',\n",
       " 'ix',\n",
       " 'Ġvery',\n",
       " 'Ġinclud',\n",
       " 'other',\n",
       " 'Ġimp',\n",
       " 'oth',\n",
       " 'Ġsub',\n",
       " 'ĠâĢĶ',\n",
       " 'Ġbeing',\n",
       " 'arg',\n",
       " 'ĠWh',\n",
       " '==',\n",
       " 'ible',\n",
       " 'Ġdoes',\n",
       " 'ange',\n",
       " 'ram',\n",
       " 'Ġ9',\n",
       " 'ert',\n",
       " 'ps',\n",
       " 'ited',\n",
       " 'ational',\n",
       " 'Ġbr',\n",
       " 'Ġdown',\n",
       " 'Ġmany',\n",
       " 'aking',\n",
       " 'Ġcall',\n",
       " 'uring',\n",
       " 'ities',\n",
       " 'Ġph',\n",
       " 'ics',\n",
       " 'als',\n",
       " 'Ġdec',\n",
       " 'ative',\n",
       " 'ener',\n",
       " 'Ġbefore',\n",
       " 'ility',\n",
       " 'Ġwell',\n",
       " 'Ġmuch',\n",
       " 'erson',\n",
       " 'Ġthose',\n",
       " 'Ġsuch',\n",
       " 'Ġke',\n",
       " 'Ġend',\n",
       " 'ĠBut',\n",
       " 'ason',\n",
       " 'ting',\n",
       " 'Ġlong',\n",
       " 'ef',\n",
       " 'Ġthink',\n",
       " 'ys',\n",
       " 'Ġbel',\n",
       " 'Ġsm',\n",
       " 'its',\n",
       " 'ax',\n",
       " 'Ġown',\n",
       " 'Ġprov',\n",
       " 'Ġset',\n",
       " 'ife',\n",
       " 'ments',\n",
       " 'ble',\n",
       " 'ward',\n",
       " 'Ġshow',\n",
       " 'Ġpres',\n",
       " 'ms',\n",
       " 'omet',\n",
       " 'Ġob',\n",
       " 'Ġsay',\n",
       " 'ĠSh',\n",
       " 'ts',\n",
       " 'ful',\n",
       " 'Ġeff',\n",
       " 'Ġgu',\n",
       " 'Ġinst',\n",
       " 'und',\n",
       " 'ren',\n",
       " 'cess',\n",
       " 'Ġent',\n",
       " 'ĠYou',\n",
       " 'Ġgood',\n",
       " 'Ġstart',\n",
       " 'ince',\n",
       " 'Ġmade',\n",
       " 'tt',\n",
       " 'stem',\n",
       " 'olog',\n",
       " 'up',\n",
       " 'Ġ|',\n",
       " 'ump',\n",
       " 'Ġhel',\n",
       " 'vern',\n",
       " 'ular',\n",
       " 'ually',\n",
       " 'Ġac',\n",
       " 'Ġmon',\n",
       " 'Ġlast',\n",
       " 'Ġ200',\n",
       " '10',\n",
       " 'Ġstud',\n",
       " 'ures',\n",
       " 'ĠAr',\n",
       " 'self',\n",
       " 'ars',\n",
       " 'meric',\n",
       " 'ues',\n",
       " 'cy',\n",
       " 'Ġmin',\n",
       " 'ollow',\n",
       " 'Ġcol',\n",
       " 'io',\n",
       " 'Ġmod',\n",
       " 'Ġcount',\n",
       " 'ĠCom',\n",
       " 'hes',\n",
       " 'Ġfin',\n",
       " 'air',\n",
       " 'ier',\n",
       " 'âĢĶ',\n",
       " 'read',\n",
       " 'ank',\n",
       " 'atch',\n",
       " 'ever',\n",
       " 'Ġstr',\n",
       " 'Ġpoint',\n",
       " 'ork',\n",
       " 'ĠNew',\n",
       " 'Ġsur',\n",
       " 'ool',\n",
       " 'alk',\n",
       " 'ement',\n",
       " 'Ġused',\n",
       " 'ract',\n",
       " 'ween',\n",
       " 'Ġsame',\n",
       " 'oun',\n",
       " 'ĠAl',\n",
       " 'ci',\n",
       " 'Ġdiffere',\n",
       " 'Ġwhile',\n",
       " '--------',\n",
       " 'Ġgame',\n",
       " 'cept',\n",
       " 'Ġsim',\n",
       " '...',\n",
       " 'Ġinter',\n",
       " 'ek',\n",
       " 'Ġreport',\n",
       " 'Ġprodu',\n",
       " 'Ġstill',\n",
       " 'led',\n",
       " 'ah',\n",
       " 'Ġhere',\n",
       " 'Ġworld',\n",
       " 'Ġthough',\n",
       " 'Ġnum',\n",
       " 'arch',\n",
       " 'imes',\n",
       " ...]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "list(tokenizer.encoder.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformer_lens.ActivationCache.ActivationCache'>\n",
      "shape of attention pattern:  torch.Size([12, 11, 11])\n",
      "Layer 0 attention head patterns: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m#Visualize the attention pattern for layer 0 \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLayer 0 attention head patterns: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m cv\u001b[39m.\u001b[39mattention\u001b[39m.\u001b[39mattention_patterns(tokens \u001b[39m=\u001b[39m gpt2_string_tokens, attention \u001b[39m=\u001b[39m attn_pattern)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "# for later\n",
    "model.tokens_to_residual_directions()\n",
    "\n",
    "\n",
    "\n",
    "print(type(gpt2_cache))\n",
    "## get the attention pattern for layer 0 \n",
    "attn_pattern = gpt2_cache['pattern', 0, 'attn']\n",
    "print('shape of attention pattern: ', attn_pattern.shape)\n",
    "# get a list of all the tokens in string form\n",
    "gpt2_string_tokens = model.to_str_tokens(gpt2_text)\n",
    "\n",
    "#Visualize the attention pattern for layer 0 \n",
    "print(\"Layer 0 attention head patterns: \")\n",
    "cv.attention.attention_patterns(tokens = gpt2_string_tokens, attention = attn_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bottom 10 values\n",
      "-11.96 'Gordon'\n",
      "-11.64 ' touchscreen'\n",
      "-11.52 ' pipes'\n",
      "-11.35 ' dental'\n",
      "-11.08 ' ================='\n",
      "-10.99 'waters'\n",
      "-10.96 ' extravag'\n",
      "-10.71 ' Sorce'\n",
      "-10.53 'stores'\n",
      "-10.51 ' pricey'\n",
      "Top 10 values\n",
      "15.98 'ed'\n",
      "15.99 '5'\n",
      "16.07 '4'\n",
      "16.59 '�'\n",
      "16.71 '3'\n",
      "17.22 'b'\n",
      "17.82 '/'\n",
      "17.85 ' of'\n",
      "17.86 '\\x00'\n",
      "18.16 '1'\n"
     ]
    }
   ],
   "source": [
    "## looking at the unembed bias that folding in introduces (default)\n",
    "unembed_bias = model.unembed.b_U\n",
    "bias_vals, bias_idx = unembed_bias.sort()\n",
    "\n",
    "top_k = 10\n",
    "print(f\"Bottom {top_k} values\")\n",
    "for i in range(top_k):\n",
    "    print(f\"{bias_vals[i].item():.2f} {repr(model.to_string(bias_idx[i]))}\")\n",
    "\n",
    "print(f\"Top {top_k} values\")\n",
    "for i in range(top_k,0,-1):\n",
    "    print(f\"{bias_vals[-i].item():.2f} {repr(model.to_string(bias_idx[-i]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6e851e82dedee55c73100bfbe6682b3cabddc188516229e1e8f6342cda6eae37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
